{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a26c46b5",
   "metadata": {},
   "source": [
    "## Cleaner Script\n",
    "\n",
    "This notebook demonstrates how to create mini-scenes from raw drone footage. Mini-scenes are sub-videos centered on each individual animal.\n",
    "\n",
    "#### Inputs: \n",
    "- Drone video footage of animals\n",
    "- Tracklets of each individual animal in CVAT format\n",
    "\n",
    "#### Output:\n",
    "- Mini-scene video clip for each animal in the video\n",
    "\n",
    "#### Purpose \n",
    "Mini-scenes may be used to a train behavior recognition model.\n",
    "The mini-scenes may also be labelled using a pre-trained behavior recognition model, such as KABR, to generate a time-budget analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df5bec",
   "metadata": {},
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2990b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from lxml import etree\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954029e3",
   "metadata": {},
   "source": [
    "### Step 2: Define file locations for inputs and outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd4ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = '20_01_2023_session_3'\n",
    "videos = ['DJI_0142', 'DJI_0143', 'DJI_0144','DJI_0145','DJI_0146','DJI_0147',]\n",
    "video_location = f\"/session_data/{session}/drone/\"\n",
    "annotation_location = \"/cvat_annotations/\"\n",
    "tracks_location = \"/tracks/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11578f5",
   "metadata": {},
   "source": [
    "### Step 3: Generate tracks xml file for each video and save tracks xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb0b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in videos:\n",
    "    video_path = f\"{video_location}/videos/{video}.MP4\"\n",
    "    annotation_path = f\"{annotation_location}{session}-{video}.xml\"\n",
    "\n",
    "    root = etree.parse(annotation_path).getroot()\n",
    "    annotated = dict()\n",
    "    track2end = {}\n",
    "\n",
    "    for track in root.iterfind(\"track\"):\n",
    "        track_id = int(track.attrib[\"id\"])\n",
    "\n",
    "        for box in track.iter(\"box\"):\n",
    "            frame_id = int(box.attrib[\"frame\"])\n",
    "            keyframe = int(box.attrib[\"keyframe\"])\n",
    "\n",
    "            if keyframe == 1:\n",
    "                track2end[track_id] = frame_id\n",
    "\n",
    "    for track in root.iterfind(\"track\"):\n",
    "        track_id = int(track.attrib[\"id\"])\n",
    "\n",
    "        for box in track.iter(\"box\"):\n",
    "            frame_id = int(box.attrib[\"frame\"])\n",
    "            keyframe = int(box.attrib[\"keyframe\"])\n",
    "\n",
    "            if frame_id <= track2end[track_id]:\n",
    "                if annotated.get(track_id) is None:\n",
    "                    annotated[track_id] = OrderedDict()\n",
    "                    \n",
    "                scaling_factor = 3\n",
    "\n",
    "                annotated[track_id][frame_id] = [int(float(box.attrib[\"xtl\"])*scaling_factor),\n",
    "                                                    int(float(box.attrib[\"ytl\"])*scaling_factor),\n",
    "                                                    int(float(box.attrib[\"xbr\"])*scaling_factor),\n",
    "                                                    int(float(box.attrib[\"ybr\"])*scaling_factor), keyframe]\n",
    "                \n",
    "    xml_page = etree.Element(\"annotations\")\n",
    "    etree.SubElement(xml_page, \"version\").text = \"1.1\"\n",
    "\n",
    "    for track_id in annotated.keys():\n",
    "        xml_track = etree.Element(\"track\", id=str(track_id), label=\"Grevy\", source=\"manual\")\n",
    "\n",
    "        for frame_id in annotated[track_id].keys():\n",
    "            if frame_id == sorted(annotated[track_id].keys())[-1]:\n",
    "                outside = \"1\"\n",
    "            else:\n",
    "                outside = \"0\"\n",
    "\n",
    "            xml_box = etree.Element(\"box\", frame=str(frame_id), outside=outside, occluded=\"0\",\n",
    "                                    keyframe=str(annotated[track_id][frame_id][4]),\n",
    "                                    xtl=f\"{annotated[track_id][frame_id][0]:.2f}\",\n",
    "                                    ytl=f\"{annotated[track_id][frame_id][1]:.2f}\",\n",
    "                                    xbr=f\"{annotated[track_id][frame_id][2]:.2f}\",\n",
    "                                    ybr=f\"{annotated[track_id][frame_id][3]:.2f}\", z_order=\"0\")\n",
    "\n",
    "            xml_track.append(xml_box)\n",
    "\n",
    "        if len(annotated[track_id].keys()) > 0:\n",
    "            xml_page.append(xml_track)\n",
    "\n",
    "    xml_document = etree.ElementTree(xml_page)\n",
    "\n",
    "    xml_document.write(f\"{tracks_location}{session}-{video}.xml\", xml_declaration=True, pretty_print=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b6020b",
   "metadata": {},
   "source": [
    "### Step 4: Create mini-scenes of each animal in the original video with the tracks_extractor.py script, using the tracks file generated in the previous step\n",
    "Note: depending on the length of the video, the processing step may take some time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c1be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define location of the tracks_extractor.py script\n",
    "script_location=\"/kabr-tools/tracks_extractor.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the tracks_extractor.py script\n",
    "# inputs: original video, xml file with annotations\n",
    "# outputs: mini-scene for each annotated track\n",
    "\n",
    "os.system(f\"python {script_location} /session_data/{session}/{video}.MP4 {tracks_location}{session}-{video}.xml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
