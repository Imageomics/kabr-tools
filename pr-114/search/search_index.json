{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#kabr-tools-documentation","title":"KABR Tools Documentation","text":""},{"location":"#overview","title":"Overview","text":"<p>This repository contains tools to perform animal behavioral analysis from drone videos.</p> <p>The modular pipeline processes drone video through object detection, individual tracking, and machine learning-based behavioral classification to generate ecological metrics including time budgets, behavioral transitions, land use and habitat, social interactions, and demographic data. Framework design enables integration of novel ML models and adaptation across species and study systems.</p> <p></p> <p>Figure 1: kabr-tools computational framework for automated wildlife behavioral monitoring.</p>"},{"location":"#detailed-description","title":"Detailed Description","text":"<p>Understanding community-level ecological patterns requires scalable methods to process multi-dimensional behavioral data. Traditional field observations are limited in scope, making it difficult to assess behavioral responses across landscapes. To address this, we present Kenyan Animal Behavior Recognition, kabr-tools. This open-source computational ecology framework integrates drone-based video with machine learning to automatically extract behavioral, social, and spatial metrics from wildlife footage.</p> <p>Our pipeline processes multi-species drone data using object detection, tracking, and behavioral classification to generate five key metrics: time budgets, behavioral transitions, social interactions, habitat associations, and group composition dynamics. Validated on three African species, our system achieved 65 - 70% behavioral classification accuracy, with &gt;95% accuracy for certain behaviors.</p>"},{"location":"#installation","title":"Installation","text":"<p>KABR tools requires that torch be installed.</p> <p>The KABR tools used in this process can be installed with:</p> <pre><code>pip install torch torchvision\npip install git+https://github.com/Imageomics/kabr-tools\n</code></pre> <p>PyTorch Installation</p> <p>Refer to pytorch.org to install specific versions of torch/CUDA</p> <p>Each KABR tool can be run through the command line (as described below) or imported as a python module. They each have help information which can be accessed on the command line through <code>&lt;tool-name&gt; -h</code>.</p>"},{"location":"#pipeline-overview","title":"Pipeline Overview","text":"<p>Figure 2: KABR tools pipeline for processing drone videos. The pipeline consists of four main steps: video data collection, data pre-processing, behavior labeling, and ecological analysis. Each step is modular and can be adapted to different species and study systems.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To get started with KABR tools, follow the pipeline steps in order:</p> <ol> <li>Data Collection - Collect drone video data following best practices</li> <li>Pre-processing - Use CVAT to create mini-scenes from your videos  </li> <li>Behavior Labeling - Apply machine learning models to classify behaviors</li> <li>Analysis - Generate ecological insights and visualizations</li> </ol>"},{"location":"#additional-resources","title":"Additional Resources","text":"<ul> <li>KABR Project Page for additional details on the dataset and original paper.</li> <li>KABR Mini-Scene Dataset on Hugging Face</li> <li>Pre-trained Model</li> <li>KABR Collection on Hugging Face: All datasets and models associated to the KABR Project.</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use KABR tools in your research, please follow the citation guidance in the repo.</p>"},{"location":"acknowledgements/","title":"Acknowledgements","text":"<p>This work was supported by the Imageomics Institute, which is funded by the US National Science Foundation's Harnessing the Data Revolution (HDR) program under Award #2118240 (Imageomics: A New Frontier of Biological Information Powered by Knowledge-Guided Machine Learning). Additional support was provided by the AI Institute for Intelligent Cyberinfrastructure with Computational Learning in the Environment (ICICLE), funded by the US National Science Foundation under Award #2112606. \u00a0</p> <p>Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p> <p>The raw data fed into the KABR tools pipeline to produce this worked example was collected at the Mpala Research Centre in Kenya, in accordance with Research License No. NACOSTI/P/22/18214. The data collection protocol adhered strictly to the guidelines set forth by the Institutional Animal Care and Use Committee under permission No. IACUC 1835F.</p>"},{"location":"case_studies/overview/","title":"Overview","text":""},{"location":"case_studies/overview/#case-studies","title":"Case Studies","text":""},{"location":"case_studies/overview/#case-study-1-grevys-landscape-of-fear","title":"Case Study 1: Grevy's Landscape of Fear","text":"<p>Notebook </p> <p>Data \u2014 Raw time-budget summaries (per bout / per individual) for Grevy's landscape case study.</p> <p>This <code>grevystimebudgetcleaned.csv</code> file combines the following dates/sessions published in the KABR Drone Wildlife Monitoring Dataset and KABR Worked Examples datasets: - KABR Drone Wildlife Monitoring Dataset: sourced from <code>data/consolidated_metadata.csv</code>, specifically the sessions on <code>11_01_23</code> , <code>12_01_23</code>, and <code>16_01_23</code>. - KABR Worked Examples: sourced from <code>behavior/</code>, specifically the sessions on <code>18_01_23</code>, <code>20_01_23</code>, and <code>21_02_23</code>.</p> <p>For both datasets, the dates are the prefixes to the relevant videos.</p>"},{"location":"case_studies/overview/#case-study-2-zebra-state-transitions","title":"Case Study 2: Zebra State Transitions","text":"<p>Notebook</p> <p>Data on Hugging Face</p>"},{"location":"case_studies/overview/#case-study-3-mixed-species-social-interactions","title":"Case Study 3: Mixed Species Social Interactions","text":"<p>Notebook</p> <p>Download data used for this case-study from the KABR worked examples dataset on Hugging Face. Use the CSV files starting with '21_01_2023_session_5' from the <code>detections/</code> folder.</p>"},{"location":"case_studies/0_time_budget/time_budget/","title":"0: Time Budget Analysis","text":"In\u00a0[1]: Copied! <pre># import libraries\nimport cv2\nimport pandas as pd\nfrom lxml import etree\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n</pre> # import libraries import cv2 import pandas as pd from lxml import etree from tqdm import tqdm import seaborn as sns import matplotlib.pyplot as plt import os import warnings warnings.filterwarnings('ignore') In\u00a0[2]: Copied! <pre># define directories for input and output\nmini_scene_info = []\nmini_scene_dir = '/mini_scenes'\nmini_scene_behavior = '/behavior'\noutput_path = 'output/time_budgets.csv'\n\n# define behavior label to index mapping\nlabel2number = {\n    \"Walk\": 0,\n    \"Graze\": 1,\n    \"Browse\": 2,\n    \"Head Up\": 3,\n    \"Auto-Groom\": 4,\n    \"Trot\": 5,\n    \"Run\": 6,\n    \"Occluded\": 7\n    }\n\n# select the video files to process\n# list video id\nvideo_names = [\n    \"18_01_2023_session_7-DJI_0068\",\n    \"18_01_2023_session_7-DJI_0069\",\n    \"18_01_2023_session_7-DJI_0070\",\n    \"18_01_2023_session_7-DJI_0071\",\n ]\n</pre>  # define directories for input and output mini_scene_info = [] mini_scene_dir = '/mini_scenes' mini_scene_behavior = '/behavior' output_path = 'output/time_budgets.csv'  # define behavior label to index mapping label2number = {     \"Walk\": 0,     \"Graze\": 1,     \"Browse\": 2,     \"Head Up\": 3,     \"Auto-Groom\": 4,     \"Trot\": 5,     \"Run\": 6,     \"Occluded\": 7     }  # select the video files to process # list video id video_names = [     \"18_01_2023_session_7-DJI_0068\",     \"18_01_2023_session_7-DJI_0069\",     \"18_01_2023_session_7-DJI_0070\",     \"18_01_2023_session_7-DJI_0071\",  ] In\u00a0[3]: Copied! <pre># define methods to process the video files\n\ndef get_tracks_info(track_file: str) -&gt; list[dict]:\n    root = etree.parse(track_file).getroot()\n    tracks = []\n    for track in root.iterfind(\"track\"):\n        track_id = track.attrib[\"id\"]\n        track_species = track.attrib[\"label\"]\n        tracks.append({\n            'id': track_id,\n            'species' : track_species\n            })\n    return tracks\n\ndef get_mini_scene_time(mini_scene_dir: str, vid_name: str, mini_scene_id: str):\n    mini_scene_video = f'{mini_scene_dir}/{vid_name}/{mini_scene_id}.mp4'\n    vid_cap = cv2.VideoCapture(mini_scene_video)\n    fps = vid_cap.get(cv2.CAP_PROP_FPS)\n    frame_count = vid_cap.get(cv2.CAP_PROP_FRAME_COUNT)\n    vid_cap.release()\n    return frame_count / fps\n\ndef get_mini_scene_percent(vid_name: str, scene_id: int):\n    mini_scene = pd.read_csv(f\"mini_scene_behavior_annotations/{vid_name.split('|')[-1]}_annotations.csv\", sep=' ', encoding='utf-8', index_col=False)\n    indiv_data = mini_scene.query(f\"track == {scene_id}\")\n    total = indiv_data.shape[0]\n    walk = indiv_data.query(f\"label == {label2number['Walk']}\").shape[0]\n    head_up = indiv_data.query(f\"label == {label2number['Head Up']}\").shape[0]\n    graze = indiv_data.query(f\"label == {label2number['Graze']}\").shape[0]\n    \n    return {\n        'Walk': walk / total,\n        'Head Up': head_up / total,\n        'Graze': graze / total,\n        'Other': (total - (walk + head_up + graze)) / total\n    }\n\ndef get_mini_scene_info(mini_scene_info: list, track_info: list, mini_scene_dir: str, vid_name: str):\n    for track in track_info:\n        mini_scene_id = track['id']\n        mini_scene_species = track['species']\n        mini_scene_interval = get_mini_scene_time(mini_scene_dir, vid_name, mini_scene_id)\n        mini_scene_percent = get_mini_scene_percent(vid_name, int(mini_scene_id))\n        \n        mini_scene_info.append({\n            'video_id' : vid_name,\n            'mini_scene_id' : f'{vid_name}_{mini_scene_id}',\n            'Walk' : mini_scene_percent['Walk'],\n            'Head Up' : mini_scene_percent['Head Up'],\n            'Graze' : mini_scene_percent['Graze'],\n            'Other' : mini_scene_percent['Other'],\n            'Interval (sec)' : mini_scene_interval,\n            'Habitat' : '0',\n            'Count of Individuals' : -1,\n            'Species' : mini_scene_species\n            })\n</pre> # define methods to process the video files  def get_tracks_info(track_file: str) -&gt; list[dict]:     root = etree.parse(track_file).getroot()     tracks = []     for track in root.iterfind(\"track\"):         track_id = track.attrib[\"id\"]         track_species = track.attrib[\"label\"]         tracks.append({             'id': track_id,             'species' : track_species             })     return tracks  def get_mini_scene_time(mini_scene_dir: str, vid_name: str, mini_scene_id: str):     mini_scene_video = f'{mini_scene_dir}/{vid_name}/{mini_scene_id}.mp4'     vid_cap = cv2.VideoCapture(mini_scene_video)     fps = vid_cap.get(cv2.CAP_PROP_FPS)     frame_count = vid_cap.get(cv2.CAP_PROP_FRAME_COUNT)     vid_cap.release()     return frame_count / fps  def get_mini_scene_percent(vid_name: str, scene_id: int):     mini_scene = pd.read_csv(f\"mini_scene_behavior_annotations/{vid_name.split('|')[-1]}_annotations.csv\", sep=' ', encoding='utf-8', index_col=False)     indiv_data = mini_scene.query(f\"track == {scene_id}\")     total = indiv_data.shape[0]     walk = indiv_data.query(f\"label == {label2number['Walk']}\").shape[0]     head_up = indiv_data.query(f\"label == {label2number['Head Up']}\").shape[0]     graze = indiv_data.query(f\"label == {label2number['Graze']}\").shape[0]          return {         'Walk': walk / total,         'Head Up': head_up / total,         'Graze': graze / total,         'Other': (total - (walk + head_up + graze)) / total     }  def get_mini_scene_info(mini_scene_info: list, track_info: list, mini_scene_dir: str, vid_name: str):     for track in track_info:         mini_scene_id = track['id']         mini_scene_species = track['species']         mini_scene_interval = get_mini_scene_time(mini_scene_dir, vid_name, mini_scene_id)         mini_scene_percent = get_mini_scene_percent(vid_name, int(mini_scene_id))                  mini_scene_info.append({             'video_id' : vid_name,             'mini_scene_id' : f'{vid_name}_{mini_scene_id}',             'Walk' : mini_scene_percent['Walk'],             'Head Up' : mini_scene_percent['Head Up'],             'Graze' : mini_scene_percent['Graze'],             'Other' : mini_scene_percent['Other'],             'Interval (sec)' : mini_scene_interval,             'Habitat' : '0',             'Count of Individuals' : -1,             'Species' : mini_scene_species             }) In\u00a0[\u00a0]: Copied! <pre># process the video files to get mini scene info\nfor vid_name in tqdm(video_names, desc='video'):\n    track_file = f\"{mini_scene_dir}/{vid_name}/metadata/{vid_name.split('-')[-1]}_tracks.xml\"\n    track_info = get_tracks_info(track_file)\n    get_mini_scene_info(mini_scene_info, track_info, mini_scene_behavior, vid_name)\n    \n# save the mini scene info to a csv file\npd.DataFrame(mini_scene_info).to_csv(output_path, index=False)\n</pre> # process the video files to get mini scene info for vid_name in tqdm(video_names, desc='video'):     track_file = f\"{mini_scene_dir}/{vid_name}/metadata/{vid_name.split('-')[-1]}_tracks.xml\"     track_info = get_tracks_info(track_file)     get_mini_scene_info(mini_scene_info, track_info, mini_scene_behavior, vid_name)      # save the mini scene info to a csv file pd.DataFrame(mini_scene_info).to_csv(output_path, index=False) In\u00a0[15]: Copied! <pre># import the csv file containing the time budgets\ntime_budgets = pd.read_csv(output_path)\ntime_budgets.head()\n</pre> # import the csv file containing the time budgets time_budgets = pd.read_csv(output_path) time_budgets.head() Out[15]: video_id mini_scene_id Walk Head Up Graze Other Interval (sec) Habit Count of Individuals Species 0 18_01_2023_session_7|drone|DJI_0068 18_01_2023_session_7|drone|DJI_0068_0 0.860073 0.060114 0.032088 0.047725 162.729396 0 2 Grevy 1 18_01_2023_session_7|drone|DJI_0068 18_01_2023_session_7|drone|DJI_0068_1 0.986596 0.003656 0.000000 0.009748 164.297631 0 2 Grevy 2 18_01_2023_session_7|drone|DJI_0069 18_01_2023_session_7|drone|DJI_0069_0 0.777033 0.165034 0.009971 0.047963 194.094094 0 2 Grevy 3 18_01_2023_session_7|drone|DJI_0069 18_01_2023_session_7|drone|DJI_0069_1 0.726147 0.273509 0.000344 0.000000 194.094094 0 2 Grevy 4 18_01_2023_session_7|drone|DJI_0070 18_01_2023_session_7|drone|DJI_0070_0 0.673375 0.307706 0.000000 0.018920 193.993994 0 2 Grevy In\u00a0[16]: Copied! <pre># create column for each animal id\ntime_budgets['Animal ID'] = time_budgets['mini_scene_id'].str.split('_').str[-1]\ntime_budgets = time_budgets[['Animal ID', 'Walk', 'Head Up', 'Graze', 'Other']]\ntime_budgets.head()\n</pre> # create column for each animal id time_budgets['Animal ID'] = time_budgets['mini_scene_id'].str.split('_').str[-1] time_budgets = time_budgets[['Animal ID', 'Walk', 'Head Up', 'Graze', 'Other']] time_budgets.head() Out[16]: Animal ID Walk Head Up Graze Other 0 0 0.860073 0.060114 0.032088 0.047725 1 1 0.986596 0.003656 0.000000 0.009748 2 0 0.777033 0.165034 0.009971 0.047963 3 1 0.726147 0.273509 0.000344 0.000000 4 0 0.673375 0.307706 0.000000 0.018920 In\u00a0[32]: Copied! <pre># plot the time budgets for each animal\n\n# create dataframe for each animal\nanimal_id = time_budgets['Animal ID'].unique()\nanimal_time_budgets = []\nfor animal in animal_id:\n    animal_data = time_budgets.query(f\"`Animal ID` == '{animal}'\")\n    animal_time_budgets.append({\n        'Animal ID' : animal,\n        'Walk' : animal_data['Walk'].mean(),\n        'Head Up' : animal_data['Head Up'].mean(),\n        'Graze' : animal_data['Graze'].mean(),\n        'Other' : animal_data['Other'].mean()\n    })\n\nanimal_time_budgets = pd.DataFrame(animal_time_budgets)\n\n# print the time budgets color coded by percentage\nplt.figure(figsize=(10, 5))\nsns.heatmap(animal_time_budgets.set_index('Animal ID'), cmap='viridis', annot=True)\nplt.title('Time Budgets')\nplt.show()\n</pre> # plot the time budgets for each animal  # create dataframe for each animal animal_id = time_budgets['Animal ID'].unique() animal_time_budgets = [] for animal in animal_id:     animal_data = time_budgets.query(f\"`Animal ID` == '{animal}'\")     animal_time_budgets.append({         'Animal ID' : animal,         'Walk' : animal_data['Walk'].mean(),         'Head Up' : animal_data['Head Up'].mean(),         'Graze' : animal_data['Graze'].mean(),         'Other' : animal_data['Other'].mean()     })  animal_time_budgets = pd.DataFrame(animal_time_budgets)  # print the time budgets color coded by percentage plt.figure(figsize=(10, 5)) sns.heatmap(animal_time_budgets.set_index('Animal ID'), cmap='viridis', annot=True) plt.title('Time Budgets') plt.show() In\u00a0[49]: Copied! <pre># import the csv file containing behavior data for an individual\nindividual_data = pd.read_csv('mini_scene_behavior_annotations/DJI_0068_annotations.csv', sep=' ', encoding='utf-8', index_col=False)\n\n# get the time budget of an individual, labeled as 0\nindividual_data = individual_data.query('track == 0')\n\n# create column for time from frame number\nindividual_data['time'] = individual_data['frame'] / 30\n\n# create behavior labels with label2number mapping\nindividual_data['behavior'] = individual_data['label'].map({v: k for k, v in label2number.items()})\n\n# create dict of behaviors in focal and drone\nbehaviors = individual_data['behavior'].unique()\nbehaviors = {b: i for i,b in enumerate(behaviors)}\n</pre> # import the csv file containing behavior data for an individual individual_data = pd.read_csv('mini_scene_behavior_annotations/DJI_0068_annotations.csv', sep=' ', encoding='utf-8', index_col=False)  # get the time budget of an individual, labeled as 0 individual_data = individual_data.query('track == 0')  # create column for time from frame number individual_data['time'] = individual_data['frame'] / 30  # create behavior labels with label2number mapping individual_data['behavior'] = individual_data['label'].map({v: k for k, v in label2number.items()})  # create dict of behaviors in focal and drone behaviors = individual_data['behavior'].unique() behaviors = {b: i for i,b in enumerate(behaviors)}  In\u00a0[68]: Copied! <pre># get all the csv files in the directory\ncsv_files = [f for f in os.listdir('data/mini_scene_behavior_annotations/') if f.endswith('.csv')]\ncsv_files = ['DJI_0069_annotations.csv']\n\n# create a dataframe containing all csv files\nall_data = []\nfor f in csv_files:\n    data = pd.read_csv(f'data/mini_scene_behavior_annotations/{f}', sep=' ', encoding='utf-8', index_col=False)\n    data['video'] = f.split('_')[0]\n    all_data.append(data)\n\nall_data = pd.concat(all_data)\n\n# create column for time from frame number\nall_data['time'] = all_data['frame'] / 30\n\n# create behavior labels with label2number mapping\nall_data['behavior'] = all_data['label'].map({v: k for k, v in label2number.items()})\n\n# create dict of behaviors \nbehaviors = all_data['behavior'].unique()\nbehaviors = {b: i for i,b in enumerate(behaviors)}\n\n# create dataframe for each animal\nzebra_0 = all_data.query('track == 0')\nzebra_1 = all_data.query('track == 1')\n\n# drop all columns except time and behavior\nzebra_0 = zebra_0[['time', 'behavior']]\nzebra_1 = zebra_1[['time', 'behavior']]\n</pre> # get all the csv files in the directory csv_files = [f for f in os.listdir('data/mini_scene_behavior_annotations/') if f.endswith('.csv')] csv_files = ['DJI_0069_annotations.csv']  # create a dataframe containing all csv files all_data = [] for f in csv_files:     data = pd.read_csv(f'data/mini_scene_behavior_annotations/{f}', sep=' ', encoding='utf-8', index_col=False)     data['video'] = f.split('_')[0]     all_data.append(data)  all_data = pd.concat(all_data)  # create column for time from frame number all_data['time'] = all_data['frame'] / 30  # create behavior labels with label2number mapping all_data['behavior'] = all_data['label'].map({v: k for k, v in label2number.items()})  # create dict of behaviors  behaviors = all_data['behavior'].unique() behaviors = {b: i for i,b in enumerate(behaviors)}  # create dataframe for each animal zebra_0 = all_data.query('track == 0') zebra_1 = all_data.query('track == 1')  # drop all columns except time and behavior zebra_0 = zebra_0[['time', 'behavior']] zebra_1 = zebra_1[['time', 'behavior']] In\u00a0[70]: Copied! <pre># get the start and end times for each behavior duration\ndef get_start_end_times(df):\n    times = []\n    for i in range(len(df)):\n        if i == 0:\n            start_behavior = df.iloc[i]['behavior']\n            start_times = df.iloc[i]['time']\n            times.append([start_behavior, start_times, 0])\n        elif df.iloc[i]['behavior'] != df.iloc[i-1]['behavior']:\n            end_behavior = df.iloc[i-1]['behavior']\n            end_times = df.iloc[i-1]['time']\n            times[-1][2] = end_times # update end time of previous behavior\n            \n            behavior = df.iloc[i]['behavior'] # start new behavior\n            start_times = df.iloc[i]['time'] # start new behavior\n            times.append([behavior, start_times, 0]) \n        # handle last behavior\n        if i == len(df)-1:\n            end_behavior = df.iloc[i]['behavior']\n            end_times = df.iloc[i]['time']\n            times[-1][2] = end_times\n    return times \n\n# get the start and end times for each behavior duration\nzebra_0_times = get_start_end_times(zebra_0)\nzebra_1_times = get_start_end_times(zebra_1)\n\n# create a dataframe for each behavior duration\nzebra_0_times = pd.DataFrame(zebra_0_times, columns=['behavior', 'start', 'end'])\nzebra_1_times = pd.DataFrame(zebra_1_times, columns=['behavior', 'start', 'end'])\n</pre> # get the start and end times for each behavior duration def get_start_end_times(df):     times = []     for i in range(len(df)):         if i == 0:             start_behavior = df.iloc[i]['behavior']             start_times = df.iloc[i]['time']             times.append([start_behavior, start_times, 0])         elif df.iloc[i]['behavior'] != df.iloc[i-1]['behavior']:             end_behavior = df.iloc[i-1]['behavior']             end_times = df.iloc[i-1]['time']             times[-1][2] = end_times # update end time of previous behavior                          behavior = df.iloc[i]['behavior'] # start new behavior             start_times = df.iloc[i]['time'] # start new behavior             times.append([behavior, start_times, 0])          # handle last behavior         if i == len(df)-1:             end_behavior = df.iloc[i]['behavior']             end_times = df.iloc[i]['time']             times[-1][2] = end_times     return times   # get the start and end times for each behavior duration zebra_0_times = get_start_end_times(zebra_0) zebra_1_times = get_start_end_times(zebra_1)  # create a dataframe for each behavior duration zebra_0_times = pd.DataFrame(zebra_0_times, columns=['behavior', 'start', 'end']) zebra_1_times = pd.DataFrame(zebra_1_times, columns=['behavior', 'start', 'end']) In\u00a0[72]: Copied! <pre># get the start and end times for each behavior duration\ndef get_start_end_times(df):\n    times = []\n    for i in range(len(df)):\n        if i == 0:\n            start_behavior = df.iloc[i]['behavior']\n            start_times = df.iloc[i]['time']\n            times.append([start_behavior, start_times, 0])\n        elif df.iloc[i]['behavior'] != df.iloc[i-1]['behavior']:\n            end_behavior = df.iloc[i-1]['behavior']\n            end_times = df.iloc[i-1]['time']\n            times[-1][2] = end_times # update end time of previous behavior\n            \n            behavior = df.iloc[i]['behavior'] # start new behavior\n            start_times = df.iloc[i]['time'] # start new behavior\n            times.append([behavior, start_times, 0]) \n        # handle last behavior\n        if i == len(df)-1:\n            end_behavior = df.iloc[i]['behavior']\n            end_times = df.iloc[i]['time']\n            times[-1][2] = end_times\n    return times \n\n\ntimes = pd.DataFrame(columns=['behavior','start', 'end'])\nzebra_0_times = get_start_end_times(zebra_0)\nzebra_1_times = get_start_end_times(zebra_1)\n\n# convert to dataframe\nzebra_0_times = pd.DataFrame(zebra_0_times, columns=['behavior','start', 'end'])\nzebra_1_times = pd.DataFrame(zebra_1_times, columns=['behavior','start', 'end'])\n\n# convert to datetime\nzebra_0_times['start'] = pd.to_datetime(zebra_0_times['start'], unit='s')\nzebra_0_times['end'] = pd.to_datetime(zebra_0_times['end'], unit='s')\nzebra_1_times['start'] = pd.to_datetime(zebra_1_times['start'], unit='s')\nzebra_1_times['end'] = pd.to_datetime(zebra_1_times['end'], unit='s')\n\n\n# calculate the duration of each behavior and relative start time\ndef calculate_duration(df):\n    df['duration'] = df['end'] - df['start']\n    # convert to seconds\n    df['duration'] = df['duration'].dt.total_seconds()\n    \n    df['rel_start'] = df['start'] - df['start'].iloc[0]\n    df['rel_start'] = df['rel_start'].dt.total_seconds()\n    return df\n\nzebra_0_times = calculate_duration(zebra_0_times)\nzebra_1_times = calculate_duration(zebra_1_times)\n</pre> # get the start and end times for each behavior duration def get_start_end_times(df):     times = []     for i in range(len(df)):         if i == 0:             start_behavior = df.iloc[i]['behavior']             start_times = df.iloc[i]['time']             times.append([start_behavior, start_times, 0])         elif df.iloc[i]['behavior'] != df.iloc[i-1]['behavior']:             end_behavior = df.iloc[i-1]['behavior']             end_times = df.iloc[i-1]['time']             times[-1][2] = end_times # update end time of previous behavior                          behavior = df.iloc[i]['behavior'] # start new behavior             start_times = df.iloc[i]['time'] # start new behavior             times.append([behavior, start_times, 0])          # handle last behavior         if i == len(df)-1:             end_behavior = df.iloc[i]['behavior']             end_times = df.iloc[i]['time']             times[-1][2] = end_times     return times    times = pd.DataFrame(columns=['behavior','start', 'end']) zebra_0_times = get_start_end_times(zebra_0) zebra_1_times = get_start_end_times(zebra_1)  # convert to dataframe zebra_0_times = pd.DataFrame(zebra_0_times, columns=['behavior','start', 'end']) zebra_1_times = pd.DataFrame(zebra_1_times, columns=['behavior','start', 'end'])  # convert to datetime zebra_0_times['start'] = pd.to_datetime(zebra_0_times['start'], unit='s') zebra_0_times['end'] = pd.to_datetime(zebra_0_times['end'], unit='s') zebra_1_times['start'] = pd.to_datetime(zebra_1_times['start'], unit='s') zebra_1_times['end'] = pd.to_datetime(zebra_1_times['end'], unit='s')   # calculate the duration of each behavior and relative start time def calculate_duration(df):     df['duration'] = df['end'] - df['start']     # convert to seconds     df['duration'] = df['duration'].dt.total_seconds()          df['rel_start'] = df['start'] - df['start'].iloc[0]     df['rel_start'] = df['rel_start'].dt.total_seconds()     return df  zebra_0_times = calculate_duration(zebra_0_times) zebra_1_times = calculate_duration(zebra_1_times) In\u00a0[84]: Copied! <pre>ethogram = ['Head Up','Graze','Walk','Trot', 'Run', 'Defecating','Auto-Groom','Fighting','Sniff','Drink','Mutual Grooming',\n            'Occluded','Out of sight','Out of Focus','Out of Frame', 'No data']\ninvalid_ethogram = ['Occluded','Out of sight','Out of Focus','Out of Frame', 'No data']\ncolors = dict(zip(ethogram, plt.cm.tab20.colors[:len(ethogram)]))\n</pre> ethogram = ['Head Up','Graze','Walk','Trot', 'Run', 'Defecating','Auto-Groom','Fighting','Sniff','Drink','Mutual Grooming',             'Occluded','Out of sight','Out of Focus','Out of Frame', 'No data'] invalid_ethogram = ['Occluded','Out of sight','Out of Focus','Out of Frame', 'No data'] colors = dict(zip(ethogram, plt.cm.tab20.colors[:len(ethogram)])) In\u00a0[87]: Copied! <pre># plot the gantt chart for zebra 0\nfig, ax = plt.subplots(figsize=(20, 5))\nax.barh(zebra_0_times['behavior'], zebra_0_times['duration'], left=zebra_0_times['rel_start'], color=[colors[b] for b in zebra_0_times['behavior']])\nax.set(title='Zebra 0 Behaviors', ylabel='Behavior', xlabel='Time (s)')\nplt.show()\n</pre> # plot the gantt chart for zebra 0 fig, ax = plt.subplots(figsize=(20, 5)) ax.barh(zebra_0_times['behavior'], zebra_0_times['duration'], left=zebra_0_times['rel_start'], color=[colors[b] for b in zebra_0_times['behavior']]) ax.set(title='Zebra 0 Behaviors', ylabel='Behavior', xlabel='Time (s)') plt.show()  In\u00a0[88]: Copied! <pre># plot the gantt chart\nfig, ax = plt.subplots(figsize=(20, 5))\nax.barh(y=zebra_1_times['behavior'], width=zebra_1_times['duration'], left=zebra_1_times['rel_start'], color=zebra_1_times['behavior'].map(colors))\nax.set(title='Zebra 1 Behaviors', ylabel='Behavior', xlabel='Time (s)')\nplt.tight_layout()\n</pre> # plot the gantt chart fig, ax = plt.subplots(figsize=(20, 5)) ax.barh(y=zebra_1_times['behavior'], width=zebra_1_times['duration'], left=zebra_1_times['rel_start'], color=zebra_1_times['behavior'].map(colors)) ax.set(title='Zebra 1 Behaviors', ylabel='Behavior', xlabel='Time (s)') plt.tight_layout()"},{"location":"case_studies/0_time_budget/time_budget/#time-budget-analysis","title":"Time Budget Analysis\u00b6","text":"<p>Script to generate time-budget analysis and visualize results from annotated mini-scenes.</p> <p>Input: CSV file containing mini-scene id, track id, frame, and behavior label for each video</p> <p>Outputs:</p> <ul> <li>CSV file containing time budget analysis for each video</li> <li>Gantt charts visualizing behavior of individual animals overtime</li> </ul>"},{"location":"case_studies/0_time_budget/time_budget/#step-1-create-csv-file-containing-time-budget-analysis-for-selected-mini-scenes","title":"Step 1: Create CSV file containing time-budget analysis for selected mini-scenes\u00b6","text":""},{"location":"case_studies/0_time_budget/time_budget/#step-2-visualize-time-budgets","title":"Step 2: Visualize time-budgets\u00b6","text":""},{"location":"case_studies/0_time_budget/time_budget/#whole-session","title":"Whole Session\u00b6","text":""},{"location":"case_studies/0_time_budget/time_budget/#individual-gantt-chart","title":"Individual Gantt Chart\u00b6","text":""},{"location":"case_studies/0_time_budget/data/","title":"Index","text":"<p>The <code>time_budgets.csv</code> file in this <code>data/</code> directory contains the time budget data used in the time budget case study. This file was compiled from the KABR raw videos collection in HuggingFace, using the videos from <code>18_01_2023_session_7/</code>. This session captured two male Grevy's zebras moving across an open habitat at the Mpala Research Centre in Kenya. See KABR worked examples in HuggingFace for step-by-step data from detections, to mini-scenes, to behaviors.</p>"},{"location":"case_studies/1_grevys_landscape/grevys_landscape_graphs/","title":"Visualizations","text":"In\u00a0[12]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import r2_score\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set publication-quality style\nplt.style.use('default')  # Clean, publication-ready style\nsns.set_palette(\"colorblind\")  # Colorblind-friendly palette\n\n# Custom color palette for consistency\n# COLORS = {\n#     'Walk': '#0173B2',      # Blue\n#     'Head Up': '#DE8F05',   # Orange  \n#     'Graze': '#029E73',     # Green\n#     'Other': '#CC78BC'      # Purple\n# }\n\nethogram = ['Out of Sight', 'Fight','Urinate','Mutual-Groom','Defecate','Auto-Groom','Browse','Trot/Run','Head Up','Walk','Graze', 'Other']\n    \n    # custom_colors = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#d62728','#2ca02c','#8c564b','#e377c2','#7f7f7f','#17becf']\n    # color_map = {behavior: custom_colors[i] for i, behavior in enumerate(ethogram)}\n    \ncolor = sns.color_palette(\"tab20\", len(ethogram))\nCOLORS = {behavior: color[i] for i, behavior in enumerate(ethogram)}\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.linear_model import LinearRegression from sklearn.preprocessing import LabelEncoder from sklearn.metrics import r2_score from scipy import stats import warnings warnings.filterwarnings('ignore')  # Set publication-quality style plt.style.use('default')  # Clean, publication-ready style sns.set_palette(\"colorblind\")  # Colorblind-friendly palette  # Custom color palette for consistency # COLORS = { #     'Walk': '#0173B2',      # Blue #     'Head Up': '#DE8F05',   # Orange   #     'Graze': '#029E73',     # Green #     'Other': '#CC78BC'      # Purple # }  ethogram = ['Out of Sight', 'Fight','Urinate','Mutual-Groom','Defecate','Auto-Groom','Browse','Trot/Run','Head Up','Walk','Graze', 'Other']          # custom_colors = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#d62728','#2ca02c','#8c564b','#e377c2','#7f7f7f','#17becf']     # color_map = {behavior: custom_colors[i] for i, behavior in enumerate(ethogram)}      color = sns.color_palette(\"tab20\", len(ethogram)) COLORS = {behavior: color[i] for i, behavior in enumerate(ethogram)} In\u00a0[4]: Copied! <pre># ============================================================================\n# DATA PREPARATION \n# ============================================================================\n\n# Load and prepare data\ndf = pd.read_csv('data/grevystimebudgetscleaned.csv')\n\n# Encode categorical variables\nle_habitat = LabelEncoder()\nle_herd_size = LabelEncoder()\ndf['Habitat_encoded'] = le_habitat.fit_transform(df['Habitat'])\ndf['HerdSize_encoded'] = le_herd_size.fit_transform(df['Herd Size'])\n\nbehaviors = ['Walk', 'Head Up', 'Graze', 'Other']\nX = df[['Habitat_encoded', 'HerdSize_encoded']]\n\n# Calculate regression results with confidence intervals\ndef calculate_regression_stats(X, y):\n    \"\"\"Calculate regression statistics including confidence intervals\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    y_pred = model.predict(X)\n    \n    n = len(y)\n    k = X.shape[1]\n    \n    # Residuals and MSE\n    residuals = y - y_pred\n    mse = np.sum(residuals**2) / (n - k - 1)\n    \n    # Design matrix with intercept\n    X_with_intercept = np.column_stack([np.ones(n), X])\n    \n    try:\n        # Covariance matrix\n        cov_matrix = mse * np.linalg.inv(X_with_intercept.T @ X_with_intercept)\n        se_coefs = np.sqrt(np.diag(cov_matrix))\n        \n        # t-statistics and p-values\n        coefs_with_intercept = np.append(model.intercept_, model.coef_)\n        t_stats = coefs_with_intercept / se_coefs\n        p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), n - k - 1))\n        \n        # 95% Confidence intervals\n        t_critical = stats.t.ppf(0.975, n - k - 1)\n        ci_lower = coefs_with_intercept - t_critical * se_coefs\n        ci_upper = coefs_with_intercept + t_critical * se_coefs\n        \n        return {\n            'model': model,\n            'r2': r2_score(y, y_pred),\n            'coefficients': model.coef_,\n            'intercept': model.intercept_,\n            'se_coefs': se_coefs[1:],  # Exclude intercept\n            'se_intercept': se_coefs[0],\n            't_stats': t_stats[1:],    # Exclude intercept\n            'p_values': p_values[1:],  # Exclude intercept\n            'ci_lower': ci_lower[1:],  # Exclude intercept\n            'ci_upper': ci_upper[1:],  # Exclude intercept\n            'predictions': y_pred\n        }\n    except:\n        return None\n\n# Calculate stats for all behaviors\nresults = {}\nfor behavior in behaviors:\n    results[behavior] = calculate_regression_stats(X, df[behavior])\n</pre> # ============================================================================ # DATA PREPARATION  # ============================================================================  # Load and prepare data df = pd.read_csv('data/grevystimebudgetscleaned.csv')  # Encode categorical variables le_habitat = LabelEncoder() le_herd_size = LabelEncoder() df['Habitat_encoded'] = le_habitat.fit_transform(df['Habitat']) df['HerdSize_encoded'] = le_herd_size.fit_transform(df['Herd Size'])  behaviors = ['Walk', 'Head Up', 'Graze', 'Other'] X = df[['Habitat_encoded', 'HerdSize_encoded']]  # Calculate regression results with confidence intervals def calculate_regression_stats(X, y):     \"\"\"Calculate regression statistics including confidence intervals\"\"\"     model = LinearRegression()     model.fit(X, y)     y_pred = model.predict(X)          n = len(y)     k = X.shape[1]          # Residuals and MSE     residuals = y - y_pred     mse = np.sum(residuals**2) / (n - k - 1)          # Design matrix with intercept     X_with_intercept = np.column_stack([np.ones(n), X])          try:         # Covariance matrix         cov_matrix = mse * np.linalg.inv(X_with_intercept.T @ X_with_intercept)         se_coefs = np.sqrt(np.diag(cov_matrix))                  # t-statistics and p-values         coefs_with_intercept = np.append(model.intercept_, model.coef_)         t_stats = coefs_with_intercept / se_coefs         p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), n - k - 1))                  # 95% Confidence intervals         t_critical = stats.t.ppf(0.975, n - k - 1)         ci_lower = coefs_with_intercept - t_critical * se_coefs         ci_upper = coefs_with_intercept + t_critical * se_coefs                  return {             'model': model,             'r2': r2_score(y, y_pred),             'coefficients': model.coef_,             'intercept': model.intercept_,             'se_coefs': se_coefs[1:],  # Exclude intercept             'se_intercept': se_coefs[0],             't_stats': t_stats[1:],    # Exclude intercept             'p_values': p_values[1:],  # Exclude intercept             'ci_lower': ci_lower[1:],  # Exclude intercept             'ci_upper': ci_upper[1:],  # Exclude intercept             'predictions': y_pred         }     except:         return None  # Calculate stats for all behaviors results = {} for behavior in behaviors:     results[behavior] = calculate_regression_stats(X, df[behavior]) In\u00a0[69]: Copied! <pre># ============================================================================\n# FIGURE 1: COEFFICIENT PLOT WITH CONFIDENCE INTERVALS\n# ============================================================================\n\ndef create_coefficient_plot():\n    \"\"\"Create coefficient plot with confidence intervals\"\"\"\n    \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n    \n    # Prepare data for plotting\n    coef_data = []\n    for behavior in behaviors:\n        if results[behavior]:\n            # Habitat coefficient\n            coef_data.append({\n                'Behavior': behavior,\n                'Predictor': 'Habitat\\n(Open vs Closed)',\n                'Coefficient': results[behavior]['coefficients'][0],\n                'CI_Lower': results[behavior]['ci_lower'][0],\n                'CI_Upper': results[behavior]['ci_upper'][0],\n                'P_Value': results[behavior]['p_values'][0],\n                'SE': results[behavior]['se_coefs'][0]\n            })\n            \n            # Herd Size coefficient  \n            coef_data.append({\n                'Behavior': behavior,\n                'Predictor': 'Herd Size\\n(Small vs Large)',\n                'Coefficient': results[behavior]['coefficients'][1],\n                'CI_Lower': results[behavior]['ci_lower'][1],\n                'CI_Upper': results[behavior]['ci_upper'][1],\n                'P_Value': results[behavior]['p_values'][1],\n                'SE': results[behavior]['se_coefs'][1]\n            })\n    \n    coef_df = pd.DataFrame(coef_data)\n    \n    # Plot 1: Habitat Effects\n    habitat_data = coef_df[coef_df['Predictor'] == 'Habitat\\n(Open vs Closed)']\n    y_pos = np.arange(len(behaviors))\n    \n    colors_list = [COLORS[behavior] for behavior in behaviors]\n    \n    # Plot coefficients with error bars\n    for i, (behavior, row) in enumerate(zip(behaviors, habitat_data.iterrows())):\n        _, data = row\n        \n        # Plot coefficient (no alpha variation)\n        ax1.barh(i, data['Coefficient'], color=colors_list[i], alpha=0.8, \n                height=0.6, edgecolor='black', linewidth=0.5)\n        \n        # Plot confidence interval\n        ax1.errorbar(data['Coefficient'], i, \n                    xerr=[[data['Coefficient'] - data['CI_Lower']], \n                          [data['CI_Upper'] - data['Coefficient']]], \n                    fmt='none', color='black', capsize=4, capthick=1)\n    \n    \n    ax1.set_yticks(y_pos)\n    ax1.set_yticklabels(behaviors)\n    ax1.set_xlabel('Coefficient (Open - Closed)', fontweight='bold')\n    ax1.set_title('A) Habitat Effects', fontweight='bold', fontsize=14)\n    ax1.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n    ax1.grid(axis='x', alpha=0.3)\n    \n    # print p-values in bottom left corner of each plot\n    for i, (behavior, row) in enumerate(zip(behaviors, habitat_data.iterrows())):\n        _, data = row\n        p_val = data['P_Value']\n        if p_val &lt; 0.001:\n            sig = '***'\n        elif p_val &lt; 0.01:\n            sig = '**'\n        elif p_val &lt; 0.05:\n            sig = '*'\n        else:\n            sig = 'ns'\n    \n    \n    # Plot 2: Herd Size Effects\n    herdsize_data = coef_df[coef_df['Predictor'] == 'Herd Size\\n(Small vs Large)']\n    \n    for i, (behavior, row) in enumerate(zip(behaviors, herdsize_data.iterrows())):\n        _, data = row\n        \n        # Plot coefficient (no alpha variation)\n        ax2.barh(i, data['Coefficient'], color=colors_list[i], alpha=0.8,\n                height=0.6, edgecolor='black', linewidth=0.5)\n        \n        # Plot confidence interval\n        ax2.errorbar(data['Coefficient'], i,\n                    xerr=[[data['Coefficient'] - data['CI_Lower']], \n                          [data['CI_Upper'] - data['Coefficient']]], \n                    fmt='none', color='black', capsize=4, capthick=1)\n        \n    \n    ax2.set_yticks(y_pos)\n    ax2.set_yticklabels(behaviors)\n    ax2.set_xlabel('Coefficient (Small - Large)', fontweight='bold')\n    ax2.set_title('B) Herd Size Effects', fontweight='bold', fontsize=14)\n    ax2.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n    ax2.grid(axis='x', alpha=0.3)\n    \n    \n    plt.tight_layout()\n    plt.subplots_adjust(bottom=0.1, top=0.9)  # Add top padding for title\n    return fig\n</pre>  # ============================================================================ # FIGURE 1: COEFFICIENT PLOT WITH CONFIDENCE INTERVALS # ============================================================================  def create_coefficient_plot():     \"\"\"Create coefficient plot with confidence intervals\"\"\"          fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))          # Prepare data for plotting     coef_data = []     for behavior in behaviors:         if results[behavior]:             # Habitat coefficient             coef_data.append({                 'Behavior': behavior,                 'Predictor': 'Habitat\\n(Open vs Closed)',                 'Coefficient': results[behavior]['coefficients'][0],                 'CI_Lower': results[behavior]['ci_lower'][0],                 'CI_Upper': results[behavior]['ci_upper'][0],                 'P_Value': results[behavior]['p_values'][0],                 'SE': results[behavior]['se_coefs'][0]             })                          # Herd Size coefficient               coef_data.append({                 'Behavior': behavior,                 'Predictor': 'Herd Size\\n(Small vs Large)',                 'Coefficient': results[behavior]['coefficients'][1],                 'CI_Lower': results[behavior]['ci_lower'][1],                 'CI_Upper': results[behavior]['ci_upper'][1],                 'P_Value': results[behavior]['p_values'][1],                 'SE': results[behavior]['se_coefs'][1]             })          coef_df = pd.DataFrame(coef_data)          # Plot 1: Habitat Effects     habitat_data = coef_df[coef_df['Predictor'] == 'Habitat\\n(Open vs Closed)']     y_pos = np.arange(len(behaviors))          colors_list = [COLORS[behavior] for behavior in behaviors]          # Plot coefficients with error bars     for i, (behavior, row) in enumerate(zip(behaviors, habitat_data.iterrows())):         _, data = row                  # Plot coefficient (no alpha variation)         ax1.barh(i, data['Coefficient'], color=colors_list[i], alpha=0.8,                  height=0.6, edgecolor='black', linewidth=0.5)                  # Plot confidence interval         ax1.errorbar(data['Coefficient'], i,                      xerr=[[data['Coefficient'] - data['CI_Lower']],                            [data['CI_Upper'] - data['Coefficient']]],                      fmt='none', color='black', capsize=4, capthick=1)               ax1.set_yticks(y_pos)     ax1.set_yticklabels(behaviors)     ax1.set_xlabel('Coefficient (Open - Closed)', fontweight='bold')     ax1.set_title('A) Habitat Effects', fontweight='bold', fontsize=14)     ax1.axvline(x=0, color='black', linestyle='--', alpha=0.5)     ax1.grid(axis='x', alpha=0.3)          # print p-values in bottom left corner of each plot     for i, (behavior, row) in enumerate(zip(behaviors, habitat_data.iterrows())):         _, data = row         p_val = data['P_Value']         if p_val &lt; 0.001:             sig = '***'         elif p_val &lt; 0.01:             sig = '**'         elif p_val &lt; 0.05:             sig = '*'         else:             sig = 'ns'               # Plot 2: Herd Size Effects     herdsize_data = coef_df[coef_df['Predictor'] == 'Herd Size\\n(Small vs Large)']          for i, (behavior, row) in enumerate(zip(behaviors, herdsize_data.iterrows())):         _, data = row                  # Plot coefficient (no alpha variation)         ax2.barh(i, data['Coefficient'], color=colors_list[i], alpha=0.8,                 height=0.6, edgecolor='black', linewidth=0.5)                  # Plot confidence interval         ax2.errorbar(data['Coefficient'], i,                     xerr=[[data['Coefficient'] - data['CI_Lower']],                            [data['CI_Upper'] - data['Coefficient']]],                      fmt='none', color='black', capsize=4, capthick=1)                   ax2.set_yticks(y_pos)     ax2.set_yticklabels(behaviors)     ax2.set_xlabel('Coefficient (Small - Large)', fontweight='bold')     ax2.set_title('B) Herd Size Effects', fontweight='bold', fontsize=14)     ax2.axvline(x=0, color='black', linestyle='--', alpha=0.5)     ax2.grid(axis='x', alpha=0.3)               plt.tight_layout()     plt.subplots_adjust(bottom=0.1, top=0.9)  # Add top padding for title     return fig In\u00a0[73]: Copied! <pre>fig1 = create_coefficient_plot()\nfig1.suptitle('Linear Regression Coefficients with 95% Confidence Intervals', \n              fontsize=16, fontweight='bold', y=0.98)\nplt.show()\n</pre> fig1 = create_coefficient_plot() fig1.suptitle('Linear Regression Coefficients with 95% Confidence Intervals',                fontsize=16, fontweight='bold', y=0.98) plt.show() In\u00a0[74]: Copied! <pre># ============================================================================\n# FIGURE 2: MODEL PERFORMANCE AND EFFECT SIZES\n# ============================================================================\n\ndef create_performance_plot():\n    \"\"\"Create model performance visualization with R\u00b2 and effect sizes\"\"\"\n    \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n    \n    # Prepare data\n    r2_values = [results[behavior]['r2'] for behavior in behaviors]\n    colors_list = [COLORS[behavior] for behavior in behaviors]\n    \n    # Plot 1: R\u00b2 values with confidence intervals\n    y_pos = np.arange(len(behaviors))\n    bars = ax1.barh(y_pos, r2_values, color=colors_list, alpha=0.8,\n                   height=0.6, edgecolor='black', linewidth=0.5)\n    \n    # Add value labels\n    for i, (bar, r2_val) in enumerate(zip(bars, r2_values)):\n        ax1.text(r2_val + 0.01, bar.get_y() + bar.get_height()/2, \n                f'{r2_val:.3f}', va='center', ha='left', fontweight='bold')\n    \n    ax1.set_yticks(y_pos)\n    ax1.set_yticklabels(behaviors)\n    ax1.set_xlabel('R\u00b2 (Variance Explained)', fontweight='bold')\n    ax1.set_title('A) Model Performance', fontweight='bold', fontsize=14)\n    ax1.set_xlim(0, max(r2_values) * 1.2)\n    ax1.grid(axis='x', alpha=0.3)\n    \n    # Plot 2: Effect Size Comparison (Cohen's f\u00b2)\n    # Calculate Cohen's f\u00b2 = R\u00b2 / (1 - R\u00b2)\n    cohens_f2 = [r2 / (1 - r2) if r2 &lt; 1 else np.inf for r2 in r2_values]\n    \n    bars2 = ax2.barh(y_pos, cohens_f2, color=colors_list, alpha=0.8,\n                    height=0.6, edgecolor='black', linewidth=0.5)\n    \n    # Add value labels and effect size interpretation\n    for i, (bar, f2_val) in enumerate(zip(bars2, cohens_f2)):\n        if f2_val &lt; 0.02:\n            effect_size = \"trivial\"\n        elif f2_val &lt; 0.15:\n            effect_size = \"small\"\n        elif f2_val &lt; 0.35:\n            effect_size = \"medium\"\n        else:\n            effect_size = \"large\"\n        \n        ax2.text(f2_val + 0.01, bar.get_y() + bar.get_height()/2, \n                f'{f2_val:.3f}\\n({effect_size})', va='center', ha='left', fontsize=9)\n    \n    ax2.set_yticks(y_pos)\n    ax2.set_yticklabels(behaviors)\n    ax2.set_xlabel('Cohen\\'s f\u00b2 (Effect Size)', fontweight='bold')\n    ax2.set_title('B) Effect Size', fontweight='bold', fontsize=14)\n    ax2.set_xlim(0, max(cohens_f2) * 1.3)\n    ax2.grid(axis='x', alpha=0.3)\n    \n    # Add effect size reference lines\n    ax2.axvline(x=0.02, color='gray', linestyle=':', alpha=0.7, label='Small (0.02)')\n    ax2.axvline(x=0.15, color='gray', linestyle='--', alpha=0.7, label='Medium (0.15)')\n    ax2.axvline(x=0.35, color='gray', linestyle='-', alpha=0.7, label='Large (0.35)')\n    ax2.legend(loc='lower right', fontsize=8)\n    \n    plt.tight_layout()\n    plt.subplots_adjust(bottom=0.1, top=0.9)\n    return fig\n</pre> # ============================================================================ # FIGURE 2: MODEL PERFORMANCE AND EFFECT SIZES # ============================================================================  def create_performance_plot():     \"\"\"Create model performance visualization with R\u00b2 and effect sizes\"\"\"          fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))          # Prepare data     r2_values = [results[behavior]['r2'] for behavior in behaviors]     colors_list = [COLORS[behavior] for behavior in behaviors]          # Plot 1: R\u00b2 values with confidence intervals     y_pos = np.arange(len(behaviors))     bars = ax1.barh(y_pos, r2_values, color=colors_list, alpha=0.8,                    height=0.6, edgecolor='black', linewidth=0.5)          # Add value labels     for i, (bar, r2_val) in enumerate(zip(bars, r2_values)):         ax1.text(r2_val + 0.01, bar.get_y() + bar.get_height()/2,                  f'{r2_val:.3f}', va='center', ha='left', fontweight='bold')          ax1.set_yticks(y_pos)     ax1.set_yticklabels(behaviors)     ax1.set_xlabel('R\u00b2 (Variance Explained)', fontweight='bold')     ax1.set_title('A) Model Performance', fontweight='bold', fontsize=14)     ax1.set_xlim(0, max(r2_values) * 1.2)     ax1.grid(axis='x', alpha=0.3)          # Plot 2: Effect Size Comparison (Cohen's f\u00b2)     # Calculate Cohen's f\u00b2 = R\u00b2 / (1 - R\u00b2)     cohens_f2 = [r2 / (1 - r2) if r2 &lt; 1 else np.inf for r2 in r2_values]          bars2 = ax2.barh(y_pos, cohens_f2, color=colors_list, alpha=0.8,                     height=0.6, edgecolor='black', linewidth=0.5)          # Add value labels and effect size interpretation     for i, (bar, f2_val) in enumerate(zip(bars2, cohens_f2)):         if f2_val &lt; 0.02:             effect_size = \"trivial\"         elif f2_val &lt; 0.15:             effect_size = \"small\"         elif f2_val &lt; 0.35:             effect_size = \"medium\"         else:             effect_size = \"large\"                  ax2.text(f2_val + 0.01, bar.get_y() + bar.get_height()/2,                  f'{f2_val:.3f}\\n({effect_size})', va='center', ha='left', fontsize=9)          ax2.set_yticks(y_pos)     ax2.set_yticklabels(behaviors)     ax2.set_xlabel('Cohen\\'s f\u00b2 (Effect Size)', fontweight='bold')     ax2.set_title('B) Effect Size', fontweight='bold', fontsize=14)     ax2.set_xlim(0, max(cohens_f2) * 1.3)     ax2.grid(axis='x', alpha=0.3)          # Add effect size reference lines     ax2.axvline(x=0.02, color='gray', linestyle=':', alpha=0.7, label='Small (0.02)')     ax2.axvline(x=0.15, color='gray', linestyle='--', alpha=0.7, label='Medium (0.15)')     ax2.axvline(x=0.35, color='gray', linestyle='-', alpha=0.7, label='Large (0.35)')     ax2.legend(loc='lower right', fontsize=8)          plt.tight_layout()     plt.subplots_adjust(bottom=0.1, top=0.9)     return fig   In\u00a0[75]: Copied! <pre># ============================================================================\n# FIGURE 3: PREDICTED MEANS WITH CONFIDENCE INTERVALS\n# ============================================================================\n\ndef create_predicted_means_plot():\n    \"\"\"Create plot showing predicted means for each combination with CIs\"\"\"\n    \n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    \n    # Calculate predicted means and confidence intervals\n    combinations = [\n        ('Closed', 'Large', 0, 0),   # Baseline\n        ('Open', 'Large', 1, 0),     # Habitat effect only\n        ('Closed', 'Small', 0, 1),   # Herd size effect only\n        ('Open', 'Small', 1, 1)      # Both effects\n    ]\n    \n    for i, behavior in enumerate(behaviors):\n        ax = axes[i//2, i%2]\n        \n        if results[behavior] is None:\n            continue\n            \n        model = results[behavior]['model']\n        intercept = results[behavior]['intercept']\n        habitat_coef = results[behavior]['coefficients'][0]\n        herdsize_coef = results[behavior]['coefficients'][1]\n        \n        # Calculate predictions and standard errors\n        x_positions = []\n        predictions = []\n        ci_lowers = []\n        ci_uppers = []\n        labels = []\n        \n        for j, (habitat, herd_size, h_code, hs_code) in enumerate(combinations):\n            # Predicted value\n            pred = intercept + habitat_coef * h_code + herdsize_coef * hs_code\n            \n            # For simplicity, use pooled SE (could be more sophisticated)\n            # Standard error of prediction\n            X_combo = np.array([[h_code, hs_code]])\n            \n            # Calculate actual observed values for this combination\n            mask = (df['Habitat'] == habitat) &amp; (df['Herd Size'] == herd_size)\n            observed = df[mask][behavior]\n            \n            if len(observed) &gt; 1:\n                se_pred = stats.sem(observed)  # Standard error of the mean\n                ci_lower = pred - 1.96 * se_pred\n                ci_upper = pred + 1.96 * se_pred\n            else:\n                ci_lower = pred\n                ci_upper = pred\n            \n            x_positions.append(j)\n            predictions.append(pred)\n            ci_lowers.append(ci_lower)\n            ci_uppers.append(ci_upper)\n            labels.append(f'{habitat}\\n{herd_size}')\n        \n        # Plot predictions with confidence intervals\n        ax.bar(x_positions, predictions, color=COLORS[behavior], alpha=0.7, \n               width=0.6, edgecolor='black', linewidth=0.5)\n        \n        # Add confidence intervals\n        ax.errorbar(x_positions, predictions, \n                   yerr=[np.array(predictions) - np.array(ci_lowers),\n                         np.array(ci_uppers) - np.array(predictions)],\n                   fmt='none', color='black', capsize=5, capthick=1.5)\n        \n        # Add value labels\n        for j, (x, pred) in enumerate(zip(x_positions, predictions)):\n            ax.text(x, pred + (max(ci_uppers) - min(ci_lowers)) * 0.05, \n                   f'{pred:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n        \n        # Add observed data points as overlay\n        for j, (habitat, herd_size, _, _) in enumerate(combinations):\n            mask = (df['Habitat'] == habitat) &amp; (df['Herd Size'] == herd_size)\n            observed = df[mask][behavior]\n            if len(observed) &gt; 0:\n                jittered_x = j + np.random.normal(0, 0.08, len(observed))\n                ax.scatter(jittered_x, observed, color='red', alpha=0.6, s=20, \n                          edgecolor='darkred', linewidth=0.5, zorder=10)\n        \n        ax.set_xticks(x_positions)\n        ax.set_xticklabels(labels, rotation=0)\n        ax.set_ylabel('Proportion of Time', fontweight='bold')\n        ax.set_title(f'{behavior}\\n(R\u00b2 = {results[behavior][\"r2\"]:.3f})', \n                    fontweight='bold', color=COLORS[behavior])\n        ax.grid(axis='y', alpha=0.3)\n        \n        # Set y-axis to start from 0\n        ax.set_ylim(0, max(ci_uppers) * 1.15)\n    \n    # Add overall legend\n    from matplotlib.lines import Line2D\n    legend_elements = [\n        Line2D([0], [0], marker='o', color='red', linestyle='', markersize=8, \n               alpha=0.6, label='Observed Data'),\n        Line2D([0], [0], color='black', linestyle='-', label='95% Confidence Intervals')\n    ]\n    fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.02), ncol=2)\n    \n    plt.suptitle('Predicted Behavior by Habitat and Herd Size Combinations', \n                fontsize=16, fontweight='bold', y=0.98)\n    plt.tight_layout()\n    plt.subplots_adjust(bottom=0.1, top=0.92)\n    return fig\n</pre> # ============================================================================ # FIGURE 3: PREDICTED MEANS WITH CONFIDENCE INTERVALS # ============================================================================  def create_predicted_means_plot():     \"\"\"Create plot showing predicted means for each combination with CIs\"\"\"          fig, axes = plt.subplots(2, 2, figsize=(16, 12))          # Calculate predicted means and confidence intervals     combinations = [         ('Closed', 'Large', 0, 0),   # Baseline         ('Open', 'Large', 1, 0),     # Habitat effect only         ('Closed', 'Small', 0, 1),   # Herd size effect only         ('Open', 'Small', 1, 1)      # Both effects     ]          for i, behavior in enumerate(behaviors):         ax = axes[i//2, i%2]                  if results[behavior] is None:             continue                      model = results[behavior]['model']         intercept = results[behavior]['intercept']         habitat_coef = results[behavior]['coefficients'][0]         herdsize_coef = results[behavior]['coefficients'][1]                  # Calculate predictions and standard errors         x_positions = []         predictions = []         ci_lowers = []         ci_uppers = []         labels = []                  for j, (habitat, herd_size, h_code, hs_code) in enumerate(combinations):             # Predicted value             pred = intercept + habitat_coef * h_code + herdsize_coef * hs_code                          # For simplicity, use pooled SE (could be more sophisticated)             # Standard error of prediction             X_combo = np.array([[h_code, hs_code]])                          # Calculate actual observed values for this combination             mask = (df['Habitat'] == habitat) &amp; (df['Herd Size'] == herd_size)             observed = df[mask][behavior]                          if len(observed) &gt; 1:                 se_pred = stats.sem(observed)  # Standard error of the mean                 ci_lower = pred - 1.96 * se_pred                 ci_upper = pred + 1.96 * se_pred             else:                 ci_lower = pred                 ci_upper = pred                          x_positions.append(j)             predictions.append(pred)             ci_lowers.append(ci_lower)             ci_uppers.append(ci_upper)             labels.append(f'{habitat}\\n{herd_size}')                  # Plot predictions with confidence intervals         ax.bar(x_positions, predictions, color=COLORS[behavior], alpha=0.7,                 width=0.6, edgecolor='black', linewidth=0.5)                  # Add confidence intervals         ax.errorbar(x_positions, predictions,                     yerr=[np.array(predictions) - np.array(ci_lowers),                          np.array(ci_uppers) - np.array(predictions)],                    fmt='none', color='black', capsize=5, capthick=1.5)                  # Add value labels         for j, (x, pred) in enumerate(zip(x_positions, predictions)):             ax.text(x, pred + (max(ci_uppers) - min(ci_lowers)) * 0.05,                     f'{pred:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)                  # Add observed data points as overlay         for j, (habitat, herd_size, _, _) in enumerate(combinations):             mask = (df['Habitat'] == habitat) &amp; (df['Herd Size'] == herd_size)             observed = df[mask][behavior]             if len(observed) &gt; 0:                 jittered_x = j + np.random.normal(0, 0.08, len(observed))                 ax.scatter(jittered_x, observed, color='red', alpha=0.6, s=20,                            edgecolor='darkred', linewidth=0.5, zorder=10)                  ax.set_xticks(x_positions)         ax.set_xticklabels(labels, rotation=0)         ax.set_ylabel('Proportion of Time', fontweight='bold')         ax.set_title(f'{behavior}\\n(R\u00b2 = {results[behavior][\"r2\"]:.3f})',                      fontweight='bold', color=COLORS[behavior])         ax.grid(axis='y', alpha=0.3)                  # Set y-axis to start from 0         ax.set_ylim(0, max(ci_uppers) * 1.15)          # Add overall legend     from matplotlib.lines import Line2D     legend_elements = [         Line2D([0], [0], marker='o', color='red', linestyle='', markersize=8,                 alpha=0.6, label='Observed Data'),         Line2D([0], [0], color='black', linestyle='-', label='95% Confidence Intervals')     ]     fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.02), ncol=2)          plt.suptitle('Predicted Behavior by Habitat and Herd Size Combinations',                  fontsize=16, fontweight='bold', y=0.98)     plt.tight_layout()     plt.subplots_adjust(bottom=0.1, top=0.92)     return fig In\u00a0[76]: Copied! <pre># ============================================================================\n# GENERATE ALL FIGURES\n# ============================================================================\n\n# Create all figures\nprint(\"Generating figures...\")\n\n\nfig2 = create_performance_plot()\nfig2.suptitle('Model Performance and Effect Sizes', \n              fontsize=16, fontweight='bold', y=0.98)\nplt.show()\n\nfig3 = create_predicted_means_plot()\nplt.show()\n</pre> # ============================================================================ # GENERATE ALL FIGURES # ============================================================================  # Create all figures print(\"Generating figures...\")   fig2 = create_performance_plot() fig2.suptitle('Model Performance and Effect Sizes',                fontsize=16, fontweight='bold', y=0.98) plt.show()  fig3 = create_predicted_means_plot() plt.show()  <pre>Generating figures...\n</pre> In\u00a0[77]: Copied! <pre>print(\"\\nSaving high-resolution figures for publication...\")\n\n# Save as both PNG (for presentations) and PDF (for publication)\nfig1.savefig('figures/Figure1_Coefficients.png', dpi=300, bbox_inches='tight', facecolor='white')\nfig1.savefig('figures/Figure1_Coefficients.pdf', dpi=300, bbox_inches='tight', facecolor='white')\n\nfig2.savefig('figures/Figure2_Performance.png', dpi=300, bbox_inches='tight', facecolor='white')\nfig2.savefig('figures/Figure2_Performance.pdf', dpi=300, bbox_inches='tight', facecolor='white')\n\nfig3.savefig('figures/Figure3_PredictedMeans.png', dpi=300, bbox_inches='tight', facecolor='white')\nfig3.savefig('figures/Figure3_PredictedMeans.pdf', dpi=300, bbox_inches='tight', facecolor='white')\n\nprint(\"figures/Figures saved successfully!\")\nprint(\"\\nFigure descriptions for manuscript:\")\nprint(\"=\"*50)\n\nprint(\"\"\"\nFigure 1: Linear regression coefficients with 95% confidence intervals showing the effect of \nhabitat (Open vs Closed) and herd size (Small vs Large) on four behaviors. Asterisks indicate \nstatistical significance: *** p&lt;0.001, ** p&lt;0.01, * p&lt;0.05, ns = not significant. \nSolid bars indicate significant effects (p&lt;0.05), transparent bars indicate non-significant effects.\n\nFigure 2: Model performance metrics showing (A) proportion of variance explained (R\u00b2) and \n(B) effect sizes (Cohen's f\u00b2) for each behavioral model. Reference lines in panel B indicate \nconventional thresholds for small (0.02), medium (0.15), and large (0.35) effect sizes.\n\nFigure 3: Predicted behavioral proportions for all habitat-herd size combinations with 95% \nconfidence intervals. Red dots show observed individual data points with jittering to reduce \noverlap. Error bars represent confidence intervals around predicted means.\n\"\"\")\n</pre> print(\"\\nSaving high-resolution figures for publication...\")  # Save as both PNG (for presentations) and PDF (for publication) fig1.savefig('figures/Figure1_Coefficients.png', dpi=300, bbox_inches='tight', facecolor='white') fig1.savefig('figures/Figure1_Coefficients.pdf', dpi=300, bbox_inches='tight', facecolor='white')  fig2.savefig('figures/Figure2_Performance.png', dpi=300, bbox_inches='tight', facecolor='white') fig2.savefig('figures/Figure2_Performance.pdf', dpi=300, bbox_inches='tight', facecolor='white')  fig3.savefig('figures/Figure3_PredictedMeans.png', dpi=300, bbox_inches='tight', facecolor='white') fig3.savefig('figures/Figure3_PredictedMeans.pdf', dpi=300, bbox_inches='tight', facecolor='white')  print(\"figures/Figures saved successfully!\") print(\"\\nFigure descriptions for manuscript:\") print(\"=\"*50)  print(\"\"\" Figure 1: Linear regression coefficients with 95% confidence intervals showing the effect of  habitat (Open vs Closed) and herd size (Small vs Large) on four behaviors. Asterisks indicate  statistical significance: *** p&lt;0.001, ** p&lt;0.01, * p&lt;0.05, ns = not significant.  Solid bars indicate significant effects (p&lt;0.05), transparent bars indicate non-significant effects.  Figure 2: Model performance metrics showing (A) proportion of variance explained (R\u00b2) and  (B) effect sizes (Cohen's f\u00b2) for each behavioral model. Reference lines in panel B indicate  conventional thresholds for small (0.02), medium (0.15), and large (0.35) effect sizes.  Figure 3: Predicted behavioral proportions for all habitat-herd size combinations with 95%  confidence intervals. Red dots show observed individual data points with jittering to reduce  overlap. Error bars represent confidence intervals around predicted means. \"\"\") <pre>Saving high-resolution figures for publication...\nfigures/Figures saved successfully!\n\nFigure descriptions for manuscript:\n==================================================\n\nFigure 1: Linear regression coefficients with 95% confidence intervals showing the effect of \nhabitat (Open vs Closed) and herd size (Small vs Large) on four behaviors. Asterisks indicate \nstatistical significance: *** p&lt;0.001, ** p&lt;0.01, * p&lt;0.05, ns = not significant. \nSolid bars indicate significant effects (p&lt;0.05), transparent bars indicate non-significant effects.\n\nFigure 2: Model performance metrics showing (A) proportion of variance explained (R\u00b2) and \n(B) effect sizes (Cohen's f\u00b2) for each behavioral model. Reference lines in panel B indicate \nconventional thresholds for small (0.02), medium (0.15), and large (0.35) effect sizes.\n\nFigure 3: Predicted behavioral proportions for all habitat-herd size combinations with 95% \nconfidence intervals. Red dots show observed individual data points with jittering to reduce \noverlap. Error bars represent confidence intervals around predicted means.\n\n</pre>"},{"location":"case_studies/1_grevys_landscape/grevys_landscape_graphs/#visualizations-for-grevys-zebra-behavioral-analysis","title":"Visualizations for Grevy's Zebra Behavioral Analysis\u00b6","text":"<p>includes confidence intervals, p-values, and effect sizes</p>"},{"location":"case_studies/1_grevys_landscape/grevys_landscape_lr/","title":"Linear Regression","text":"In\u00a0[2]: Copied! <pre>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import r2_score\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set style for better plots\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n</pre> import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.linear_model import LinearRegression from sklearn.preprocessing import LabelEncoder from sklearn.metrics import r2_score from scipy import stats import warnings warnings.filterwarnings('ignore')  # Set style for better plots plt.style.use('seaborn-v0_8') sns.set_palette(\"husl\") In\u00a0[3]: Copied! <pre># ============================================================================\n# 1. DATA LOADING AND PREPROCESSING\n# ============================================================================\n\n# Load the dataset\ndf = pd.read_csv('data/grevystimebudgetscleaned.csv')\n\nprint(\"Dataset Overview:\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\nColumns: {list(df.columns)}\")\nprint(f\"\\nFirst few rows:\")\nprint(df.head())\n\n# Check data types and missing values\nprint(f\"\\nData Types:\")\nprint(df.dtypes)\nprint(f\"\\nMissing Values:\")\nprint(df.isnull().sum())\n\n# Examine categorical variables\nprint(f\"\\nUnique Habitats: {df['Habitat'].unique()}\")\nprint(f\"Unique Herd Sizes: {df['Herd Size'].unique()}\")\n</pre> # ============================================================================ # 1. DATA LOADING AND PREPROCESSING # ============================================================================  # Load the dataset df = pd.read_csv('data/grevystimebudgetscleaned.csv')  print(\"Dataset Overview:\") print(f\"Shape: {df.shape}\") print(f\"\\nColumns: {list(df.columns)}\") print(f\"\\nFirst few rows:\") print(df.head())  # Check data types and missing values print(f\"\\nData Types:\") print(df.dtypes) print(f\"\\nMissing Values:\") print(df.isnull().sum())  # Examine categorical variables print(f\"\\nUnique Habitats: {df['Habitat'].unique()}\") print(f\"Unique Herd Sizes: {df['Herd Size'].unique()}\") <pre>Dataset Overview:\nShape: (82, 9)\n\nColumns: ['Sesssion', 'mini_scene_id', 'Walk', 'Head Up', 'Graze', 'Other', 'Interval(sec)', 'Habitat', 'Herd Size']\n\nFirst few rows:\n   Sesssion         mini_scene_id      Walk   Head Up     Graze     Other  \\\n0         1   11_01_23-DJI_0977_2  0.442609  0.417140  0.096197  0.044054   \n1         1   11_01_23-DJI_0977_3  0.513430  0.371257  0.066039  0.049273   \n2         1   11_01_23-DJI_0977_1  0.557903  0.358236  0.032945  0.050915   \n3         2   11_01_23-DJI_0488_9  0.016229  0.983771  0.000000  0.000000   \n4         2  11_01_23-DJI_0488_45  0.000000  0.745382  0.000000  0.254618   \n\n   Interval(sec) Habitat Herd Size  \n0     193.700000  Closed     Small  \n1     194.833333  Closed     Small  \n2     200.333333  Closed     Small  \n3     112.966667    Open     Small  \n4     108.266667    Open     Small  \n\nData Types:\nSesssion           int64\nmini_scene_id     object\nWalk             float64\nHead Up          float64\nGraze            float64\nOther            float64\nInterval(sec)    float64\nHabitat           object\nHerd Size         object\ndtype: object\n\nMissing Values:\nSesssion         0\nmini_scene_id    0\nWalk             0\nHead Up          0\nGraze            0\nOther            0\nInterval(sec)    0\nHabitat          0\nHerd Size        0\ndtype: int64\n\nUnique Habitats: ['Closed' 'Open']\nUnique Herd Sizes: ['Small' 'Large']\n</pre> In\u00a0[4]: Copied! <pre># ============================================================================\n# 2. EXPLORATORY DATA ANALYSIS\n# ============================================================================\n\n# Behavior variables (dependent variables)\nbehaviors = ['Walk', 'Head Up', 'Graze', 'Other']\n\n# Summary statistics for behaviors by habitat and herd size\nprint(\"\\n\" + \"=\"*60)\nprint(\"SUMMARY STATISTICS BY HABITAT AND HERD SIZE\")\nprint(\"=\"*60)\n\nfor behavior in behaviors:\n    print(f\"\\n{behavior}:\")\n    print(\"By Habitat:\")\n    print(df.groupby('Habitat')[behavior].agg(['count', 'mean', 'std']).round(4))\n    print(\"\\nBy Herd Size:\")\n    print(df.groupby('Herd Size')[behavior].agg(['count', 'mean', 'std']).round(4))\n\n# Create visualization of behavior patterns\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\nfig.suptitle('Grevy\\'s Zebra Behavior Patterns by Habitat and Herd Size', fontsize=16, y=0.98)\n\nfor i, behavior in enumerate(behaviors):\n    row, col = i // 2, i % 2\n    \n    # Create subplot with both habitat and herd size\n    ax = axes[row, col]\n    \n    # Box plot showing distribution by habitat and herd size\n    df_plot = df.melt(id_vars=['Habitat', 'Herd Size'], \n                      value_vars=[behavior], \n                      var_name='Behavior', \n                      value_name='Proportion')\n    \n    sns.boxplot(data=df_plot, x='Habitat', y='Proportion', hue='Herd Size', ax=ax)\n    ax.set_title(f'{behavior} by Habitat and Herd Size')\n    ax.set_ylabel('Proportion of Time')\n\nplt.tight_layout()\nplt.show()\n</pre> # ============================================================================ # 2. EXPLORATORY DATA ANALYSIS # ============================================================================  # Behavior variables (dependent variables) behaviors = ['Walk', 'Head Up', 'Graze', 'Other']  # Summary statistics for behaviors by habitat and herd size print(\"\\n\" + \"=\"*60) print(\"SUMMARY STATISTICS BY HABITAT AND HERD SIZE\") print(\"=\"*60)  for behavior in behaviors:     print(f\"\\n{behavior}:\")     print(\"By Habitat:\")     print(df.groupby('Habitat')[behavior].agg(['count', 'mean', 'std']).round(4))     print(\"\\nBy Herd Size:\")     print(df.groupby('Herd Size')[behavior].agg(['count', 'mean', 'std']).round(4))  # Create visualization of behavior patterns fig, axes = plt.subplots(2, 2, figsize=(15, 12)) fig.suptitle('Grevy\\'s Zebra Behavior Patterns by Habitat and Herd Size', fontsize=16, y=0.98)  for i, behavior in enumerate(behaviors):     row, col = i // 2, i % 2          # Create subplot with both habitat and herd size     ax = axes[row, col]          # Box plot showing distribution by habitat and herd size     df_plot = df.melt(id_vars=['Habitat', 'Herd Size'],                        value_vars=[behavior],                        var_name='Behavior',                        value_name='Proportion')          sns.boxplot(data=df_plot, x='Habitat', y='Proportion', hue='Herd Size', ax=ax)     ax.set_title(f'{behavior} by Habitat and Herd Size')     ax.set_ylabel('Proportion of Time')  plt.tight_layout() plt.show() <pre>============================================================\nSUMMARY STATISTICS BY HABITAT AND HERD SIZE\n============================================================\n\nWalk:\nBy Habitat:\n         count    mean     std\nHabitat                       \nClosed      32  0.1000  0.1557\nOpen        50  0.2493  0.2701\n\nBy Herd Size:\n           count    mean     std\nHerd Size                       \nLarge         59  0.0992  0.1370\nSmall         23  0.4266  0.2936\n\nHead Up:\nBy Habitat:\n         count    mean     std\nHabitat                       \nClosed      32  0.2086  0.2867\nOpen        50  0.2657  0.2907\n\nBy Herd Size:\n           count    mean     std\nHerd Size                       \nLarge         59  0.1539  0.2281\nSmall         23  0.4731  0.3050\n\nGraze:\nBy Habitat:\n         count    mean     std\nHabitat                       \nClosed      32  0.6148  0.3936\nOpen        50  0.4085  0.3871\n\nBy Herd Size:\n           count    mean     std\nHerd Size                       \nLarge         59  0.6739  0.3153\nSmall         23  0.0149  0.0314\n\nOther:\nBy Habitat:\n         count    mean     std\nHabitat                       \nClosed      32  0.0765  0.1507\nOpen        50  0.0765  0.1391\n\nBy Herd Size:\n           count    mean     std\nHerd Size                       \nLarge         59  0.0731  0.1540\nSmall         23  0.0854  0.1114\n</pre> In\u00a0[11]: Copied! <pre># ============================================================================\n# 3. LINEAR REGRESSION ANALYSIS\n# ============================================================================\n\n# Encode categorical variables\nle_habitat = LabelEncoder()\nle_herd_size = LabelEncoder()\n\ndf['Habitat_encoded'] = le_habitat.fit_transform(df['Habitat'])\ndf['HerdSize_encoded'] = le_herd_size.fit_transform(df['Herd Size'])\n\n# Create mapping for interpretation\nhabitat_mapping = dict(zip(le_habitat.transform(le_habitat.classes_), le_habitat.classes_))\nherdsize_mapping = dict(zip(le_herd_size.transform(le_herd_size.classes_), le_herd_size.classes_))\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ENCODING MAPPINGS\")\nprint(\"=\"*60)\nprint(f\"Habitat encoding: {habitat_mapping}\")\nprint(f\"Herd Size encoding: {herdsize_mapping}\")\n\n# Prepare predictors\nX = df[['Habitat_encoded', 'HerdSize_encoded']]\nfeature_names = ['Habitat', 'Herd Size']\n\n# Store results for comparison\nregression_results = {}\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LINEAR REGRESSION RESULTS\")\nprint(\"=\"*60)\n\n# save significance levels\nsignificance_levels = []\n\nfor behavior in behaviors:\n    print(f\"\\n{'-'*40}\")\n    print(f\"BEHAVIOR: {behavior}\")\n    print(f\"{'-'*40}\")\n    \n    # Fit linear regression\n    y = df[behavior]\n    model = LinearRegression()\n    model.fit(X, y)\n    \n    # Predictions and R\u00b2\n    y_pred = model.predict(X)\n    r2 = r2_score(y, y_pred)\n    \n    # Store results\n    regression_results[behavior] = {\n        'coefficients': model.coef_,\n        'intercept': model.intercept_,\n        'r2': r2,\n        'model': model\n    }\n    \n    print(f\"R\u00b2 Score: {r2:.4f}\")\n    print(f\"Intercept: {model.intercept_:.4f}\")\n    print(\"Coefficients:\")\n    for i, (coef, feature) in enumerate(zip(model.coef_, feature_names)):\n        print(f\"  {feature}: {coef:.4f}\")\n    \n    # Statistical significance testing\n    # Calculate t-statistics and p-values\n    n = len(y)\n    k = len(model.coef_)\n    \n    # Residual sum of squares\n    y_pred = model.predict(X)\n    residuals = y - y_pred\n    rss = np.sum(residuals**2)\n    \n    # Mean squared error\n    mse = rss / (n - k - 1)\n    \n    # Standard errors of coefficients\n    X_with_intercept = np.column_stack([np.ones(n), X])\n    try:\n        cov_matrix = mse * np.linalg.inv(X_with_intercept.T @ X_with_intercept)\n        se_coefs = np.sqrt(np.diag(cov_matrix))[1:]  # Exclude intercept\n        \n        # t-statistics and p-values\n        t_stats = model.coef_ / se_coefs\n        p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), n - k - 1))\n        \n        print(\"Statistical Significance:\")\n        for i, (feature, t_stat, p_val) in enumerate(zip(feature_names, t_stats, p_values)):\n            significance = \"***\" if p_val &lt; 0.001 else \"**\" if p_val &lt; 0.01 else \"*\" if p_val &lt; 0.05 else \"\"\n            print(f\"  {feature}: t={t_stat:.3f}, p={p_val:.4f} {significance}\")\n            \n        # save t_stats and p_values for later use\n        significance_levels.append((behavior, feature_names, t_stats, p_values))\n    \n    except np.linalg.LinAlgError:\n        print(\"Could not calculate statistical significance (singular matrix)\")\n</pre> # ============================================================================ # 3. LINEAR REGRESSION ANALYSIS # ============================================================================  # Encode categorical variables le_habitat = LabelEncoder() le_herd_size = LabelEncoder()  df['Habitat_encoded'] = le_habitat.fit_transform(df['Habitat']) df['HerdSize_encoded'] = le_herd_size.fit_transform(df['Herd Size'])  # Create mapping for interpretation habitat_mapping = dict(zip(le_habitat.transform(le_habitat.classes_), le_habitat.classes_)) herdsize_mapping = dict(zip(le_herd_size.transform(le_herd_size.classes_), le_herd_size.classes_))  print(\"\\n\" + \"=\"*60) print(\"ENCODING MAPPINGS\") print(\"=\"*60) print(f\"Habitat encoding: {habitat_mapping}\") print(f\"Herd Size encoding: {herdsize_mapping}\")  # Prepare predictors X = df[['Habitat_encoded', 'HerdSize_encoded']] feature_names = ['Habitat', 'Herd Size']  # Store results for comparison regression_results = {}  print(\"\\n\" + \"=\"*60) print(\"LINEAR REGRESSION RESULTS\") print(\"=\"*60)  # save significance levels significance_levels = []  for behavior in behaviors:     print(f\"\\n{'-'*40}\")     print(f\"BEHAVIOR: {behavior}\")     print(f\"{'-'*40}\")          # Fit linear regression     y = df[behavior]     model = LinearRegression()     model.fit(X, y)          # Predictions and R\u00b2     y_pred = model.predict(X)     r2 = r2_score(y, y_pred)          # Store results     regression_results[behavior] = {         'coefficients': model.coef_,         'intercept': model.intercept_,         'r2': r2,         'model': model     }          print(f\"R\u00b2 Score: {r2:.4f}\")     print(f\"Intercept: {model.intercept_:.4f}\")     print(\"Coefficients:\")     for i, (coef, feature) in enumerate(zip(model.coef_, feature_names)):         print(f\"  {feature}: {coef:.4f}\")          # Statistical significance testing     # Calculate t-statistics and p-values     n = len(y)     k = len(model.coef_)          # Residual sum of squares     y_pred = model.predict(X)     residuals = y - y_pred     rss = np.sum(residuals**2)          # Mean squared error     mse = rss / (n - k - 1)          # Standard errors of coefficients     X_with_intercept = np.column_stack([np.ones(n), X])     try:         cov_matrix = mse * np.linalg.inv(X_with_intercept.T @ X_with_intercept)         se_coefs = np.sqrt(np.diag(cov_matrix))[1:]  # Exclude intercept                  # t-statistics and p-values         t_stats = model.coef_ / se_coefs         p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), n - k - 1))                  print(\"Statistical Significance:\")         for i, (feature, t_stat, p_val) in enumerate(zip(feature_names, t_stats, p_values)):             significance = \"***\" if p_val &lt; 0.001 else \"**\" if p_val &lt; 0.01 else \"*\" if p_val &lt; 0.05 else \"\"             print(f\"  {feature}: t={t_stat:.3f}, p={p_val:.4f} {significance}\")                      # save t_stats and p_values for later use         significance_levels.append((behavior, feature_names, t_stats, p_values))          except np.linalg.LinAlgError:         print(\"Could not calculate statistical significance (singular matrix)\") <pre>============================================================\nENCODING MAPPINGS\n============================================================\nHabitat encoding: {0: 'Closed', 1: 'Open'}\nHerd Size encoding: {0: 'Large', 1: 'Small'}\n\n============================================================\nLINEAR REGRESSION RESULTS\n============================================================\n\n----------------------------------------\nBEHAVIOR: Walk\n----------------------------------------\nR\u00b2 Score: 0.4022\nIntercept: 0.0521\nCoefficients:\n  Habitat: 0.0868\n  Herd Size: 0.3066\nStatistical Significance:\n  Habitat: t=1.971, p=0.0523 \n  Herd Size: t=6.409, p=0.0000 ***\n\n----------------------------------------\nBEHAVIOR: Head Up\n----------------------------------------\nR\u00b2 Score: 0.2500\nIntercept: 0.1584\nCoefficients:\n  Habitat: -0.0084\n  Herd Size: 0.3213\nStatistical Significance:\n  Habitat: t=-0.143, p=0.8864 \n  Herd Size: t=5.034, p=0.0000 ***\n\n----------------------------------------\nBEHAVIOR: Graze\n----------------------------------------\nR\u00b2 Score: 0.5621\nIntercept: 0.7150\nCoefficients:\n  Habitat: -0.0757\n  Herd Size: -0.6408\nStatistical Significance:\n  Habitat: t=-1.216, p=0.2275 \n  Herd Size: t=-9.479, p=0.0000 ***\n\n----------------------------------------\nBEHAVIOR: Other\n----------------------------------------\nR\u00b2 Score: 0.0016\nIntercept: 0.0745\nCoefficients:\n  Habitat: -0.0027\n  Herd Size: 0.0129\nStatistical Significance:\n  Habitat: t=-0.080, p=0.9368 \n  Herd Size: t=0.355, p=0.7232 \n</pre> In\u00a0[12]: Copied! <pre>significance_levels\n</pre> significance_levels Out[12]: <pre>[('Walk',\n  ['Habitat', 'Herd Size'],\n  array([1.9706704 , 6.40901791]),\n  array([5.22644921e-02, 9.83405646e-09])),\n ('Head Up',\n  ['Habitat', 'Herd Size'],\n  array([-0.14331907,  5.03400118]),\n  array([8.86403135e-01, 2.95772428e-06])),\n ('Graze',\n  ['Habitat', 'Herd Size'],\n  array([-1.21636233, -9.47907617]),\n  array([2.27468742e-01, 1.13242749e-14])),\n ('Other',\n  ['Habitat', 'Herd Size'],\n  array([-0.07960377,  0.35540207]),\n  array([0.9367537 , 0.72323558]))]</pre> In\u00a0[14]: Copied! <pre># print the regression results, coefficients, and statistical significance in table for manuscript\nprint(\"\\n\" + \"=\"*60)\nprint(\"REGRESSION SUMMARY TABLE\")\nprint(\"=\"*60)\nsummary_table = []\nfor behavior, results in regression_results.items():\n    row = {\n        'Behavior': behavior,\n        'R\u00b2': results['r2'],\n        'Intercept': results['intercept']\n    }\n    for i, feature in enumerate(feature_names):\n        row[f'Coef_{feature}'] = results['coefficients'][i]\n    summary_table.append(row)\n    \n    for sig in significance_levels:\n        if sig[0] == behavior:\n            for i, feature in enumerate(sig[1]):\n                row[f't_{feature}'] = sig[2][i]\n                row[f'p_{feature}'] = sig[3][i]\n    \n    # add checkmark for significant or not\n    for feature in feature_names:\n        p_val = row.get(f'p_{feature}', 1)\n        row[f'Significant_{feature}'] = '\u2713' if p_val &lt; 0.05 else ''\n        \n        \n    \n    \nsummary_df = pd.DataFrame(summary_table)\nprint(summary_df.round(4))\n\n# Save summary table to CSV\nsummary_df.to_csv('regression_summary.csv', index=False)\nprint(\"\\nRegression summary saved to 'regression_summary.csv'\")\n# ============================================================================\n</pre> # print the regression results, coefficients, and statistical significance in table for manuscript print(\"\\n\" + \"=\"*60) print(\"REGRESSION SUMMARY TABLE\") print(\"=\"*60) summary_table = [] for behavior, results in regression_results.items():     row = {         'Behavior': behavior,         'R\u00b2': results['r2'],         'Intercept': results['intercept']     }     for i, feature in enumerate(feature_names):         row[f'Coef_{feature}'] = results['coefficients'][i]     summary_table.append(row)          for sig in significance_levels:         if sig[0] == behavior:             for i, feature in enumerate(sig[1]):                 row[f't_{feature}'] = sig[2][i]                 row[f'p_{feature}'] = sig[3][i]          # add checkmark for significant or not     for feature in feature_names:         p_val = row.get(f'p_{feature}', 1)         row[f'Significant_{feature}'] = '\u2713' if p_val &lt; 0.05 else ''                             summary_df = pd.DataFrame(summary_table) print(summary_df.round(4))  # Save summary table to CSV summary_df.to_csv('regression_summary.csv', index=False) print(\"\\nRegression summary saved to 'regression_summary.csv'\") # ============================================================================  <pre>============================================================\nREGRESSION SUMMARY TABLE\n============================================================\n  Behavior      R\u00b2  Intercept  Coef_Habitat  Coef_Herd Size  t_Habitat  \\\n0     Walk  0.4022     0.0521        0.0868          0.3066     1.9707   \n1  Head Up  0.2500     0.1584       -0.0084          0.3213    -0.1433   \n2    Graze  0.5621     0.7150       -0.0757         -0.6408    -1.2164   \n3    Other  0.0016     0.0745       -0.0027          0.0129    -0.0796   \n\n   p_Habitat  t_Herd Size  p_Herd Size Significant_Habitat  \\\n0     0.0523       6.4090       0.0000                       \n1     0.8864       5.0340       0.0000                       \n2     0.2275      -9.4791       0.0000                       \n3     0.9368       0.3554       0.7232                       \n\n  Significant_Herd Size  \n0                     \u2713  \n1                     \u2713  \n2                     \u2713  \n3                        \n\nRegression summary saved to 'regression_summary.csv'\n</pre> In\u00a0[6]: Copied! <pre># ============================================================================\n# 4. COEFFICIENT COMPARISON VISUALIZATION\n# ============================================================================\n\n# Create coefficient comparison plots\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\nfig.suptitle('Linear Regression Coefficients: Habitat and Herd Size Effects on Behaviors', \n             fontsize=16, y=0.98)\n\n# Prepare data for plotting\ncoef_data = []\nfor behavior in behaviors:\n    for i, feature in enumerate(feature_names):\n        coef_data.append({\n            'Behavior': behavior,\n            'Predictor': feature,\n            'Coefficient': regression_results[behavior]['coefficients'][i],\n            'R\u00b2': regression_results[behavior]['r2']\n        })\n\ncoef_df = pd.DataFrame(coef_data)\n\n# Plot 1: Habitat coefficients\nax1 = axes[0, 0]\nhabitat_coefs = coef_df[coef_df['Predictor'] == 'Habitat']\nbars1 = ax1.bar(habitat_coefs['Behavior'], habitat_coefs['Coefficient'], \n                color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\nax1.set_title('Habitat Effect on Behaviors\\n(Closed=0, Open=1)')\nax1.set_ylabel('Coefficient Value')\nax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)\nax1.tick_params(axis='x', rotation=45)\n\n# Add value labels on bars\nfor bar, value in zip(bars1, habitat_coefs['Coefficient']):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height + (0.01 if height &gt; 0 else -0.02),\n             f'{value:.3f}', ha='center', va='bottom' if height &gt; 0 else 'top')\n\n# Plot 2: Herd Size coefficients\nax2 = axes[0, 1]\nherdsize_coefs = coef_df[coef_df['Predictor'] == 'Herd Size']\nbars2 = ax2.bar(herdsize_coefs['Behavior'], herdsize_coefs['Coefficient'],\n                color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\nax2.set_title('Herd Size Effect on Behaviors\\n(Large=0, Small=1)')\nax2.set_ylabel('Coefficient Value')\nax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\nax2.tick_params(axis='x', rotation=45)\n\n# Add value labels on bars\nfor bar, value in zip(bars2, herdsize_coefs['Coefficient']):\n    height = bar.get_height()\n    ax2.text(bar.get_x() + bar.get_width()/2., height + (0.01 if height &gt; 0 else -0.02),\n             f'{value:.3f}', ha='center', va='bottom' if height &gt; 0 else 'top')\n\n# Plot 3: R\u00b2 values comparison\nax3 = axes[1, 0]\nr2_values = [regression_results[behavior]['r2'] for behavior in behaviors]\nbars3 = ax3.bar(behaviors, r2_values, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\nax3.set_title('Model Performance (R\u00b2 values)')\nax3.set_ylabel('R\u00b2 Score')\nax3.set_ylim(0, max(r2_values) * 1.1)\nax3.tick_params(axis='x', rotation=45)\n\n# Add value labels on bars\nfor bar, value in zip(bars3, r2_values):\n    height = bar.get_height()\n    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n             f'{value:.3f}', ha='center', va='bottom')\n\n# Plot 4: Coefficient comparison heatmap\nax4 = axes[1, 1]\npivot_coefs = coef_df.pivot(index='Behavior', columns='Predictor', values='Coefficient')\nsns.heatmap(pivot_coefs, annot=True, cmap='RdBu_r', center=0, ax=ax4, \n            fmt='.3f', cbar_kws={'label': 'Coefficient Value'})\nax4.set_title('Coefficient Heatmap')\n\nplt.tight_layout()\nplt.show()\n</pre> # ============================================================================ # 4. COEFFICIENT COMPARISON VISUALIZATION # ============================================================================  # Create coefficient comparison plots fig, axes = plt.subplots(2, 2, figsize=(15, 12)) fig.suptitle('Linear Regression Coefficients: Habitat and Herd Size Effects on Behaviors',               fontsize=16, y=0.98)  # Prepare data for plotting coef_data = [] for behavior in behaviors:     for i, feature in enumerate(feature_names):         coef_data.append({             'Behavior': behavior,             'Predictor': feature,             'Coefficient': regression_results[behavior]['coefficients'][i],             'R\u00b2': regression_results[behavior]['r2']         })  coef_df = pd.DataFrame(coef_data)  # Plot 1: Habitat coefficients ax1 = axes[0, 0] habitat_coefs = coef_df[coef_df['Predictor'] == 'Habitat'] bars1 = ax1.bar(habitat_coefs['Behavior'], habitat_coefs['Coefficient'],                  color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']) ax1.set_title('Habitat Effect on Behaviors\\n(Closed=0, Open=1)') ax1.set_ylabel('Coefficient Value') ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3) ax1.tick_params(axis='x', rotation=45)  # Add value labels on bars for bar, value in zip(bars1, habitat_coefs['Coefficient']):     height = bar.get_height()     ax1.text(bar.get_x() + bar.get_width()/2., height + (0.01 if height &gt; 0 else -0.02),              f'{value:.3f}', ha='center', va='bottom' if height &gt; 0 else 'top')  # Plot 2: Herd Size coefficients ax2 = axes[0, 1] herdsize_coefs = coef_df[coef_df['Predictor'] == 'Herd Size'] bars2 = ax2.bar(herdsize_coefs['Behavior'], herdsize_coefs['Coefficient'],                 color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']) ax2.set_title('Herd Size Effect on Behaviors\\n(Large=0, Small=1)') ax2.set_ylabel('Coefficient Value') ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3) ax2.tick_params(axis='x', rotation=45)  # Add value labels on bars for bar, value in zip(bars2, herdsize_coefs['Coefficient']):     height = bar.get_height()     ax2.text(bar.get_x() + bar.get_width()/2., height + (0.01 if height &gt; 0 else -0.02),              f'{value:.3f}', ha='center', va='bottom' if height &gt; 0 else 'top')  # Plot 3: R\u00b2 values comparison ax3 = axes[1, 0] r2_values = [regression_results[behavior]['r2'] for behavior in behaviors] bars3 = ax3.bar(behaviors, r2_values, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']) ax3.set_title('Model Performance (R\u00b2 values)') ax3.set_ylabel('R\u00b2 Score') ax3.set_ylim(0, max(r2_values) * 1.1) ax3.tick_params(axis='x', rotation=45)  # Add value labels on bars for bar, value in zip(bars3, r2_values):     height = bar.get_height()     ax3.text(bar.get_x() + bar.get_width()/2., height + 0.005,              f'{value:.3f}', ha='center', va='bottom')  # Plot 4: Coefficient comparison heatmap ax4 = axes[1, 1] pivot_coefs = coef_df.pivot(index='Behavior', columns='Predictor', values='Coefficient') sns.heatmap(pivot_coefs, annot=True, cmap='RdBu_r', center=0, ax=ax4,              fmt='.3f', cbar_kws={'label': 'Coefficient Value'}) ax4.set_title('Coefficient Heatmap')  plt.tight_layout() plt.show()  In\u00a0[7]: Copied! <pre># ============================================================================\n# 5. DETAILED INTERPRETATION\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"INTERPRETATION OF RESULTS\")\nprint(\"=\"*60)\n\nprint(\"\\nCOEFFICIENT INTERPRETATION:\")\nprint(\"-\" * 30)\nprint(\"Habitat coefficients (Closed=0, Open=1):\")\nprint(\"  Positive coefficient = behavior increases in Open habitat\")\nprint(\"  Negative coefficient = behavior decreases in Open habitat\")\nprint(\"\\nHerd Size coefficients (Large=0, Small=1):\")\nprint(\"  Positive coefficient = behavior increases in Small herds\")\nprint(\"  Negative coefficient = behavior decreases in Small herds\")\n\nprint(\"\\nKEY FINDINGS:\")\nprint(\"-\" * 15)\nfor behavior in behaviors:\n    habitat_coef = regression_results[behavior]['coefficients'][0]\n    herdsize_coef = regression_results[behavior]['coefficients'][1]\n    r2 = regression_results[behavior]['r2']\n    \n    print(f\"\\n{behavior}:\")\n    print(f\"  Model explains {r2*100:.1f}% of variance\")\n    \n    # Habitat effect\n    if abs(habitat_coef) &gt; 0.01:  # Threshold for meaningful effect\n        direction = \"higher\" if habitat_coef &gt; 0 else \"lower\"\n        print(f\"  Habitat: {direction} in Open vs Closed ({habitat_coef:+.3f})\")\n    else:\n        print(f\"  Habitat: minimal effect ({habitat_coef:+.3f})\")\n    \n    # Herd size effect\n    if abs(herdsize_coef) &gt; 0.01:\n        direction = \"higher\" if herdsize_coef &gt; 0 else \"lower\"\n        print(f\"  Herd Size: {direction} in Small vs Large herds ({herdsize_coef:+.3f})\")\n    else:\n        print(f\"  Herd Size: minimal effect ({herdsize_coef:+.3f})\")\n</pre> # ============================================================================ # 5. DETAILED INTERPRETATION # ============================================================================  print(\"\\n\" + \"=\"*60) print(\"INTERPRETATION OF RESULTS\") print(\"=\"*60)  print(\"\\nCOEFFICIENT INTERPRETATION:\") print(\"-\" * 30) print(\"Habitat coefficients (Closed=0, Open=1):\") print(\"  Positive coefficient = behavior increases in Open habitat\") print(\"  Negative coefficient = behavior decreases in Open habitat\") print(\"\\nHerd Size coefficients (Large=0, Small=1):\") print(\"  Positive coefficient = behavior increases in Small herds\") print(\"  Negative coefficient = behavior decreases in Small herds\")  print(\"\\nKEY FINDINGS:\") print(\"-\" * 15) for behavior in behaviors:     habitat_coef = regression_results[behavior]['coefficients'][0]     herdsize_coef = regression_results[behavior]['coefficients'][1]     r2 = regression_results[behavior]['r2']          print(f\"\\n{behavior}:\")     print(f\"  Model explains {r2*100:.1f}% of variance\")          # Habitat effect     if abs(habitat_coef) &gt; 0.01:  # Threshold for meaningful effect         direction = \"higher\" if habitat_coef &gt; 0 else \"lower\"         print(f\"  Habitat: {direction} in Open vs Closed ({habitat_coef:+.3f})\")     else:         print(f\"  Habitat: minimal effect ({habitat_coef:+.3f})\")          # Herd size effect     if abs(herdsize_coef) &gt; 0.01:         direction = \"higher\" if herdsize_coef &gt; 0 else \"lower\"         print(f\"  Herd Size: {direction} in Small vs Large herds ({herdsize_coef:+.3f})\")     else:         print(f\"  Herd Size: minimal effect ({herdsize_coef:+.3f})\") <pre>============================================================\nINTERPRETATION OF RESULTS\n============================================================\n\nCOEFFICIENT INTERPRETATION:\n------------------------------\nHabitat coefficients (Closed=0, Open=1):\n  Positive coefficient = behavior increases in Open habitat\n  Negative coefficient = behavior decreases in Open habitat\n\nHerd Size coefficients (Large=0, Small=1):\n  Positive coefficient = behavior increases in Small herds\n  Negative coefficient = behavior decreases in Small herds\n\nKEY FINDINGS:\n---------------\n\nWalk:\n  Model explains 40.2% of variance\n  Habitat: higher in Open vs Closed (+0.087)\n  Herd Size: higher in Small vs Large herds (+0.307)\n\nHead Up:\n  Model explains 25.0% of variance\n  Habitat: minimal effect (-0.008)\n  Herd Size: higher in Small vs Large herds (+0.321)\n\nGraze:\n  Model explains 56.2% of variance\n  Habitat: lower in Open vs Closed (-0.076)\n  Herd Size: lower in Small vs Large herds (-0.641)\n\nOther:\n  Model explains 0.2% of variance\n  Habitat: minimal effect (-0.003)\n  Herd Size: higher in Small vs Large herds (+0.013)\n</pre> In\u00a0[8]: Copied! <pre># ============================================================================\n# 6. RESIDUAL ANALYSIS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"RESIDUAL ANALYSIS\")\nprint(\"=\"*60)\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\nfig.suptitle('Residual Analysis for Linear Regression Models', fontsize=16, y=0.98)\n\nfor i, behavior in enumerate(behaviors):\n    ax = axes[i//2, i%2]\n    \n    # Get predictions and residuals\n    model = regression_results[behavior]['model']\n    y_true = df[behavior]\n    y_pred = model.predict(X)\n    residuals = y_true - y_pred\n    \n    # Residuals vs Predicted plot\n    ax.scatter(y_pred, residuals, alpha=0.6)\n    ax.axhline(y=0, color='red', linestyle='--')\n    ax.set_xlabel('Predicted Values')\n    ax.set_ylabel('Residuals')\n    ax.set_title(f'{behavior} - Residuals vs Predicted')\n    \n    # Add trend line\n    z = np.polyfit(y_pred, residuals, 1)\n    p = np.poly1d(z)\n    ax.plot(sorted(y_pred), p(sorted(y_pred)), \"r--\", alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nModel assumptions check:\")\nprint(\"- Look for random scatter around y=0 in residual plots\")\nprint(\"- Non-random patterns may indicate model inadequacy\")\nprint(\"- Consider transformations if patterns are evident\")\n</pre> # ============================================================================ # 6. RESIDUAL ANALYSIS # ============================================================================  print(\"\\n\" + \"=\"*60) print(\"RESIDUAL ANALYSIS\") print(\"=\"*60)  fig, axes = plt.subplots(2, 2, figsize=(15, 12)) fig.suptitle('Residual Analysis for Linear Regression Models', fontsize=16, y=0.98)  for i, behavior in enumerate(behaviors):     ax = axes[i//2, i%2]          # Get predictions and residuals     model = regression_results[behavior]['model']     y_true = df[behavior]     y_pred = model.predict(X)     residuals = y_true - y_pred          # Residuals vs Predicted plot     ax.scatter(y_pred, residuals, alpha=0.6)     ax.axhline(y=0, color='red', linestyle='--')     ax.set_xlabel('Predicted Values')     ax.set_ylabel('Residuals')     ax.set_title(f'{behavior} - Residuals vs Predicted')          # Add trend line     z = np.polyfit(y_pred, residuals, 1)     p = np.poly1d(z)     ax.plot(sorted(y_pred), p(sorted(y_pred)), \"r--\", alpha=0.3)  plt.tight_layout() plt.show()  print(\"\\nModel assumptions check:\") print(\"- Look for random scatter around y=0 in residual plots\") print(\"- Non-random patterns may indicate model inadequacy\") print(\"- Consider transformations if patterns are evident\") <pre>============================================================\nRESIDUAL ANALYSIS\n============================================================\n</pre> <pre>Model assumptions check:\n- Look for random scatter around y=0 in residual plots\n- Non-random patterns may indicate model inadequacy\n- Consider transformations if patterns are evident\n</pre> In\u00a0[9]: Copied! <pre># ============================================================================\n# 7. SUMMARY TABLE\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SUMMARY TABLE\")\nprint(\"=\"*60)\n\nsummary_df = pd.DataFrame({\n    'Behavior': behaviors,\n    'R\u00b2': [regression_results[b]['r2'] for b in behaviors],\n    'Habitat_Coef': [regression_results[b]['coefficients'][0] for b in behaviors],\n    'HerdSize_Coef': [regression_results[b]['coefficients'][1] for b in behaviors],\n    'Intercept': [regression_results[b]['intercept'] for b in behaviors]\n})\n\nprint(summary_df.round(4).to_string(index=False))\n\n# Save results to CSV\nsummary_df.to_csv('regression_results_summary.csv', index=False)\nprint(f\"\\nResults saved to 'regression_results_summary.csv'\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ANALYSIS COMPLETE\")\nprint(\"=\"*60)\n</pre> # ============================================================================ # 7. SUMMARY TABLE # ============================================================================  print(\"\\n\" + \"=\"*60) print(\"SUMMARY TABLE\") print(\"=\"*60)  summary_df = pd.DataFrame({     'Behavior': behaviors,     'R\u00b2': [regression_results[b]['r2'] for b in behaviors],     'Habitat_Coef': [regression_results[b]['coefficients'][0] for b in behaviors],     'HerdSize_Coef': [regression_results[b]['coefficients'][1] for b in behaviors],     'Intercept': [regression_results[b]['intercept'] for b in behaviors] })  print(summary_df.round(4).to_string(index=False))  # Save results to CSV summary_df.to_csv('regression_results_summary.csv', index=False) print(f\"\\nResults saved to 'regression_results_summary.csv'\")  print(\"\\n\" + \"=\"*60) print(\"ANALYSIS COMPLETE\") print(\"=\"*60) <pre>============================================================\nSUMMARY TABLE\n============================================================\nBehavior     R\u00b2  Habitat_Coef  HerdSize_Coef  Intercept\n    Walk 0.4022        0.0868         0.3066     0.0521\n Head Up 0.2500       -0.0084         0.3213     0.1584\n   Graze 0.5621       -0.0757        -0.6408     0.7150\n   Other 0.0016       -0.0027         0.0129     0.0745\n\nResults saved to 'regression_results_summary.csv'\n\n============================================================\nANALYSIS COMPLETE\n============================================================\n</pre> In\u00a0[10]: Copied! <pre># Encode categorical variables\nle_habitat = LabelEncoder()\nle_herd_size = LabelEncoder()\n\ndf['Habitat_encoded'] = le_habitat.fit_transform(df['Habitat'])\ndf['HerdSize_encoded'] = le_herd_size.fit_transform(df['Herd Size'])\n\n# Create interaction term\ndf['Habitat_HerdSize_interaction'] = df['Habitat_encoded'] * df['HerdSize_encoded']\n\n# Create mapping for interpretation\nhabitat_mapping = dict(zip(le_habitat.transform(le_habitat.classes_), le_habitat.classes_))\nherdsize_mapping = dict(zip(le_herd_size.transform(le_herd_size.classes_), le_herd_size.classes_))\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ENCODING AND INTERACTION SETUP\")\nprint(\"=\"*60)\nprint(f\"Habitat encoding: {habitat_mapping}\")\nprint(f\"Herd Size encoding: {herdsize_mapping}\")\nprint(\"\\nInteraction term interpretation:\")\nprint(\"  0: Closed + Large (baseline)\")\nprint(\"  0: Open + Large (habitat effect only)\")\nprint(\"  0: Closed + Small (herd size effect only)\")\nprint(\"  1: Open + Small (habitat + herd size + interaction)\")\n\n# Check distribution of combinations\nprint(\"\\nDistribution of combinations:\")\ncombo_counts = df.groupby(['Habitat', 'Herd Size']).size()\nprint(combo_counts)\n</pre>  # Encode categorical variables le_habitat = LabelEncoder() le_herd_size = LabelEncoder()  df['Habitat_encoded'] = le_habitat.fit_transform(df['Habitat']) df['HerdSize_encoded'] = le_herd_size.fit_transform(df['Herd Size'])  # Create interaction term df['Habitat_HerdSize_interaction'] = df['Habitat_encoded'] * df['HerdSize_encoded']  # Create mapping for interpretation habitat_mapping = dict(zip(le_habitat.transform(le_habitat.classes_), le_habitat.classes_)) herdsize_mapping = dict(zip(le_herd_size.transform(le_herd_size.classes_), le_herd_size.classes_))  print(\"\\n\" + \"=\"*60) print(\"ENCODING AND INTERACTION SETUP\") print(\"=\"*60) print(f\"Habitat encoding: {habitat_mapping}\") print(f\"Herd Size encoding: {herdsize_mapping}\") print(\"\\nInteraction term interpretation:\") print(\"  0: Closed + Large (baseline)\") print(\"  0: Open + Large (habitat effect only)\") print(\"  0: Closed + Small (herd size effect only)\") print(\"  1: Open + Small (habitat + herd size + interaction)\")  # Check distribution of combinations print(\"\\nDistribution of combinations:\") combo_counts = df.groupby(['Habitat', 'Herd Size']).size() print(combo_counts)   <pre>============================================================\nENCODING AND INTERACTION SETUP\n============================================================\nHabitat encoding: {0: 'Closed', 1: 'Open'}\nHerd Size encoding: {0: 'Large', 1: 'Small'}\n\nInteraction term interpretation:\n  0: Closed + Large (baseline)\n  0: Open + Large (habitat effect only)\n  0: Closed + Small (herd size effect only)\n  1: Open + Small (habitat + herd size + interaction)\n\nDistribution of combinations:\nHabitat  Herd Size\nClosed   Large        27\n         Small         5\nOpen     Large        32\n         Small        18\ndtype: int64\n</pre> In\u00a0[11]: Copied! <pre># ============================================================================\n# 2. MODEL COMPARISON: MAIN EFFECTS vs INTERACTION MODELS\n# ============================================================================\n\nbehaviors = ['Walk', 'Head Up', 'Graze', 'Other']\n\n# Prepare predictors for both models\nX_main = df[['Habitat_encoded', 'HerdSize_encoded']]  # Main effects only\nX_interaction = df[['Habitat_encoded', 'HerdSize_encoded', 'Habitat_HerdSize_interaction']]  # With interaction\n\n# Store results for comparison\nmain_effects_results = {}\ninteraction_results = {}\nmodel_comparison = {}\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"MODEL COMPARISON: MAIN EFFECTS vs INTERACTION MODELS\")\nprint(\"=\"*60)\n\nfor behavior in behaviors:\n    print(f\"\\n{'-'*50}\")\n    print(f\"BEHAVIOR: {behavior}\")\n    print(f\"{'-'*50}\")\n    \n    y = df[behavior]\n    \n    # ===================\n    # MAIN EFFECTS MODEL\n    # ===================\n    model_main = LinearRegression()\n    model_main.fit(X_main, y)\n    y_pred_main = model_main.predict(X_main)\n    r2_main = r2_score(y, y_pred_main)\n    \n    main_effects_results[behavior] = {\n        'model': model_main,\n        'r2': r2_main,\n        'coefficients': model_main.coef_,\n        'intercept': model_main.intercept_,\n        'predictions': y_pred_main\n    }\n    \n    # ===================\n    # INTERACTION MODEL\n    # ===================\n    model_interaction = LinearRegression()\n    model_interaction.fit(X_interaction, y)\n    y_pred_interaction = model_interaction.predict(X_interaction)\n    r2_interaction = r2_score(y, y_pred_interaction)\n    \n    interaction_results[behavior] = {\n        'model': model_interaction,\n        'r2': r2_interaction,\n        'coefficients': model_interaction.coef_,\n        'intercept': model_interaction.intercept_,\n        'predictions': y_pred_interaction\n    }\n    \n    # ===================\n    # F-TEST FOR INTERACTION SIGNIFICANCE\n    # ===================\n    # Calculate F-statistic to test if interaction model is significantly better\n    n = len(y)\n    \n    # Residual Sum of Squares\n    rss_main = np.sum((y - y_pred_main)**2)\n    rss_interaction = np.sum((y - y_pred_interaction)**2)\n    \n    # Degrees of freedom\n    df_main = n - X_main.shape[1] - 1  # n - p - 1\n    df_interaction = n - X_interaction.shape[1] - 1\n    \n    # F-statistic for interaction term\n    f_stat = ((rss_main - rss_interaction) / 1) / (rss_interaction / df_interaction)\n    p_value = 1 - stats.f.cdf(f_stat, 1, df_interaction)\n    \n    # Store comparison results\n    model_comparison[behavior] = {\n        'r2_improvement': r2_interaction - r2_main,\n        'f_statistic': f_stat,\n        'p_value': p_value,\n        'interaction_significant': p_value &lt; 0.05\n    }\n    \n    # ===================\n    # DISPLAY RESULTS\n    # ===================\n    print(f\"\\nMAIN EFFECTS MODEL:\")\n    print(f\"  R\u00b2 = {r2_main:.4f}\")\n    print(f\"  Intercept: {model_main.intercept_:.4f}\")\n    print(f\"  Habitat coef: {model_main.coef_[0]:.4f}\")\n    print(f\"  Herd Size coef: {model_main.coef_[1]:.4f}\")\n    \n    print(f\"\\nINTERACTION MODEL:\")\n    print(f\"  R\u00b2 = {r2_interaction:.4f}\")\n    print(f\"  Intercept: {model_interaction.intercept_:.4f}\")\n    print(f\"  Habitat coef: {model_interaction.coef_[0]:.4f}\")\n    print(f\"  Herd Size coef: {model_interaction.coef_[1]:.4f}\")\n    print(f\"  Interaction coef: {model_interaction.coef_[2]:.4f}\")\n    \n    print(f\"\\nMODEL COMPARISON:\")\n    print(f\"  R\u00b2 improvement: {r2_interaction - r2_main:.4f}\")\n    print(f\"  F-statistic: {f_stat:.3f}\")\n    print(f\"  p-value: {p_value:.4f}\")\n    \n    significance = \"\"\n    if p_value &lt; 0.001:\n        significance = \"*** (highly significant)\"\n    elif p_value &lt; 0.01:\n        significance = \"** (very significant)\"\n    elif p_value &lt; 0.05:\n        significance = \"* (significant)\"\n    else:\n        significance = \"(not significant)\"\n    \n    print(f\"  Interaction effect: {significance}\")\n</pre> # ============================================================================ # 2. MODEL COMPARISON: MAIN EFFECTS vs INTERACTION MODELS # ============================================================================  behaviors = ['Walk', 'Head Up', 'Graze', 'Other']  # Prepare predictors for both models X_main = df[['Habitat_encoded', 'HerdSize_encoded']]  # Main effects only X_interaction = df[['Habitat_encoded', 'HerdSize_encoded', 'Habitat_HerdSize_interaction']]  # With interaction  # Store results for comparison main_effects_results = {} interaction_results = {} model_comparison = {}  print(\"\\n\" + \"=\"*60) print(\"MODEL COMPARISON: MAIN EFFECTS vs INTERACTION MODELS\") print(\"=\"*60)  for behavior in behaviors:     print(f\"\\n{'-'*50}\")     print(f\"BEHAVIOR: {behavior}\")     print(f\"{'-'*50}\")          y = df[behavior]          # ===================     # MAIN EFFECTS MODEL     # ===================     model_main = LinearRegression()     model_main.fit(X_main, y)     y_pred_main = model_main.predict(X_main)     r2_main = r2_score(y, y_pred_main)          main_effects_results[behavior] = {         'model': model_main,         'r2': r2_main,         'coefficients': model_main.coef_,         'intercept': model_main.intercept_,         'predictions': y_pred_main     }          # ===================     # INTERACTION MODEL     # ===================     model_interaction = LinearRegression()     model_interaction.fit(X_interaction, y)     y_pred_interaction = model_interaction.predict(X_interaction)     r2_interaction = r2_score(y, y_pred_interaction)          interaction_results[behavior] = {         'model': model_interaction,         'r2': r2_interaction,         'coefficients': model_interaction.coef_,         'intercept': model_interaction.intercept_,         'predictions': y_pred_interaction     }          # ===================     # F-TEST FOR INTERACTION SIGNIFICANCE     # ===================     # Calculate F-statistic to test if interaction model is significantly better     n = len(y)          # Residual Sum of Squares     rss_main = np.sum((y - y_pred_main)**2)     rss_interaction = np.sum((y - y_pred_interaction)**2)          # Degrees of freedom     df_main = n - X_main.shape[1] - 1  # n - p - 1     df_interaction = n - X_interaction.shape[1] - 1          # F-statistic for interaction term     f_stat = ((rss_main - rss_interaction) / 1) / (rss_interaction / df_interaction)     p_value = 1 - stats.f.cdf(f_stat, 1, df_interaction)          # Store comparison results     model_comparison[behavior] = {         'r2_improvement': r2_interaction - r2_main,         'f_statistic': f_stat,         'p_value': p_value,         'interaction_significant': p_value &lt; 0.05     }          # ===================     # DISPLAY RESULTS     # ===================     print(f\"\\nMAIN EFFECTS MODEL:\")     print(f\"  R\u00b2 = {r2_main:.4f}\")     print(f\"  Intercept: {model_main.intercept_:.4f}\")     print(f\"  Habitat coef: {model_main.coef_[0]:.4f}\")     print(f\"  Herd Size coef: {model_main.coef_[1]:.4f}\")          print(f\"\\nINTERACTION MODEL:\")     print(f\"  R\u00b2 = {r2_interaction:.4f}\")     print(f\"  Intercept: {model_interaction.intercept_:.4f}\")     print(f\"  Habitat coef: {model_interaction.coef_[0]:.4f}\")     print(f\"  Herd Size coef: {model_interaction.coef_[1]:.4f}\")     print(f\"  Interaction coef: {model_interaction.coef_[2]:.4f}\")          print(f\"\\nMODEL COMPARISON:\")     print(f\"  R\u00b2 improvement: {r2_interaction - r2_main:.4f}\")     print(f\"  F-statistic: {f_stat:.3f}\")     print(f\"  p-value: {p_value:.4f}\")          significance = \"\"     if p_value &lt; 0.001:         significance = \"*** (highly significant)\"     elif p_value &lt; 0.01:         significance = \"** (very significant)\"     elif p_value &lt; 0.05:         significance = \"* (significant)\"     else:         significance = \"(not significant)\"          print(f\"  Interaction effect: {significance}\") <pre>============================================================\nMODEL COMPARISON: MAIN EFFECTS vs INTERACTION MODELS\n============================================================\n\n--------------------------------------------------\nBEHAVIOR: Walk\n--------------------------------------------------\n\nMAIN EFFECTS MODEL:\n  R\u00b2 = 0.4022\n  Intercept: 0.0521\n  Habitat coef: 0.0868\n  Herd Size coef: 0.3066\n\nINTERACTION MODEL:\n  R\u00b2 = 0.4084\n  Intercept: 0.0409\n  Habitat coef: 0.1074\n  Herd Size coef: 0.3782\n  Interaction coef: -0.0978\n\nMODEL COMPARISON:\n  R\u00b2 improvement: 0.0062\n  F-statistic: 0.818\n  p-value: 0.3685\n  Interaction effect: (not significant)\n\n--------------------------------------------------\nBEHAVIOR: Head Up\n--------------------------------------------------\n\nMAIN EFFECTS MODEL:\n  R\u00b2 = 0.2500\n  Intercept: 0.1584\n  Habitat coef: -0.0084\n  Herd Size coef: 0.3213\n\nINTERACTION MODEL:\n  R\u00b2 = 0.2546\n  Intercept: 0.1699\n  Habitat coef: -0.0296\n  Herd Size coef: 0.2478\n  Interaction coef: 0.1004\n\nMODEL COMPARISON:\n  R\u00b2 improvement: 0.0046\n  F-statistic: 0.482\n  p-value: 0.4894\n  Interaction effect: (not significant)\n\n--------------------------------------------------\nBEHAVIOR: Graze\n--------------------------------------------------\n\nMAIN EFFECTS MODEL:\n  R\u00b2 = 0.5621\n  Intercept: 0.7150\n  Habitat coef: -0.0757\n  Herd Size coef: -0.6408\n\nINTERACTION MODEL:\n  R\u00b2 = 0.5628\n  Intercept: 0.7215\n  Habitat coef: -0.0877\n  Herd Size coef: -0.6824\n  Interaction coef: 0.0569\n\nMODEL COMPARISON:\n  R\u00b2 improvement: 0.0008\n  F-statistic: 0.137\n  p-value: 0.7120\n  Interaction effect: (not significant)\n\n--------------------------------------------------\nBEHAVIOR: Other\n--------------------------------------------------\n\nMAIN EFFECTS MODEL:\n  R\u00b2 = 0.0016\n  Intercept: 0.0745\n  Habitat coef: -0.0027\n  Herd Size coef: 0.0129\n\nINTERACTION MODEL:\n  R\u00b2 = 0.0082\n  Intercept: 0.0677\n  Habitat coef: 0.0099\n  Herd Size coef: 0.0565\n  Interaction coef: -0.0595\n\nMODEL COMPARISON:\n  R\u00b2 improvement: 0.0066\n  F-statistic: 0.520\n  p-value: 0.4730\n  Interaction effect: (not significant)\n</pre> In\u00a0[12]: Copied! <pre># ============================================================================\n# 3. VISUALIZATION OF INTERACTION EFFECTS\n# ============================================================================\n\n# Create comprehensive interaction plots\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\nfig.suptitle('Interaction Effects: Predicted vs Observed Behavior by Habitat and Herd Size', \n             fontsize=16, y=0.98)\n\nfor i, behavior in enumerate(behaviors):\n    ax = axes[i//2, i%2]\n    \n    # Create separate data for each combination\n    combinations = [\n        ('Closed', 'Large'), ('Closed', 'Small'), \n        ('Open', 'Large'), ('Open', 'Small')\n    ]\n    \n    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n    \n    # Plot observed data points\n    for j, (habitat, herd_size) in enumerate(combinations):\n        mask = (df['Habitat'] == habitat) &amp; (df['Herd Size'] == herd_size)\n        if mask.any():\n            observed_values = df[mask][behavior]\n            x_pos = j + np.random.normal(0, 0.05, size=len(observed_values))  # Add jitter\n            ax.scatter(x_pos, observed_values, alpha=0.6, color=colors[j], \n                      s=30, label=f'{habitat}+{herd_size} (observed)')\n    \n    # Plot model predictions\n    for j, (habitat, herd_size) in enumerate(combinations):\n        mask = (df['Habitat'] == habitat) &amp; (df['Herd Size'] == herd_size)\n        if mask.any():\n            # Main effects prediction\n            main_pred = main_effects_results[behavior]['predictions'][mask].mean()\n            # Interaction model prediction\n            interaction_pred = interaction_results[behavior]['predictions'][mask].mean()\n            \n            # Plot predictions as horizontal lines\n            ax.hlines(main_pred, j-0.3, j+0.3, colors='red', linestyles='--', \n                     linewidth=2, alpha=0.8)\n            ax.hlines(interaction_pred, j-0.2, j+0.2, colors='blue', linestyles='-', \n                     linewidth=3, alpha=0.8)\n    \n    ax.set_title(f'{behavior}\\nInteraction p-value: {model_comparison[behavior][\"p_value\"]:.4f}')\n    ax.set_ylabel('Proportion of Time')\n    ax.set_xticks(range(4))\n    ax.set_xticklabels([f'{h}\\n{hs}' for h, hs in combinations], rotation=0)\n    \n    # Add legend for first subplot only\n    if i == 0:\n        from matplotlib.lines import Line2D\n        legend_elements = [\n            Line2D([0], [0], linestyle='--', color='red', label='Main Effects Model'),\n            Line2D([0], [0], linestyle='-', color='blue', label='Interaction Model'),\n            Line2D([0], [0], marker='o', color='gray', linestyle='', label='Observed Data')\n        ]\n        ax.legend(handles=legend_elements, loc='upper right', fontsize=8)\n\nplt.tight_layout()\nplt.show()\n</pre> # ============================================================================ # 3. VISUALIZATION OF INTERACTION EFFECTS # ============================================================================  # Create comprehensive interaction plots fig, axes = plt.subplots(2, 2, figsize=(16, 12)) fig.suptitle('Interaction Effects: Predicted vs Observed Behavior by Habitat and Herd Size',               fontsize=16, y=0.98)  for i, behavior in enumerate(behaviors):     ax = axes[i//2, i%2]          # Create separate data for each combination     combinations = [         ('Closed', 'Large'), ('Closed', 'Small'),          ('Open', 'Large'), ('Open', 'Small')     ]          colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']          # Plot observed data points     for j, (habitat, herd_size) in enumerate(combinations):         mask = (df['Habitat'] == habitat) &amp; (df['Herd Size'] == herd_size)         if mask.any():             observed_values = df[mask][behavior]             x_pos = j + np.random.normal(0, 0.05, size=len(observed_values))  # Add jitter             ax.scatter(x_pos, observed_values, alpha=0.6, color=colors[j],                        s=30, label=f'{habitat}+{herd_size} (observed)')          # Plot model predictions     for j, (habitat, herd_size) in enumerate(combinations):         mask = (df['Habitat'] == habitat) &amp; (df['Herd Size'] == herd_size)         if mask.any():             # Main effects prediction             main_pred = main_effects_results[behavior]['predictions'][mask].mean()             # Interaction model prediction             interaction_pred = interaction_results[behavior]['predictions'][mask].mean()                          # Plot predictions as horizontal lines             ax.hlines(main_pred, j-0.3, j+0.3, colors='red', linestyles='--',                       linewidth=2, alpha=0.8)             ax.hlines(interaction_pred, j-0.2, j+0.2, colors='blue', linestyles='-',                       linewidth=3, alpha=0.8)          ax.set_title(f'{behavior}\\nInteraction p-value: {model_comparison[behavior][\"p_value\"]:.4f}')     ax.set_ylabel('Proportion of Time')     ax.set_xticks(range(4))     ax.set_xticklabels([f'{h}\\n{hs}' for h, hs in combinations], rotation=0)          # Add legend for first subplot only     if i == 0:         from matplotlib.lines import Line2D         legend_elements = [             Line2D([0], [0], linestyle='--', color='red', label='Main Effects Model'),             Line2D([0], [0], linestyle='-', color='blue', label='Interaction Model'),             Line2D([0], [0], marker='o', color='gray', linestyle='', label='Observed Data')         ]         ax.legend(handles=legend_elements, loc='upper right', fontsize=8)  plt.tight_layout() plt.show()  In\u00a0[13]: Copied! <pre># ============================================================================\n# 4. DETAILED INTERACTION INTERPRETATION\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"INTERACTION EFFECTS INTERPRETATION\")\nprint(\"=\"*60)\n\n# Calculate predicted values for each combination using interaction model\nprint(\"\\nPredicted values for each combination (Interaction Model):\")\nprint(\"-\" * 55)\n\ncombination_predictions = {}\n\nfor behavior in behaviors:\n    print(f\"\\n{behavior}:\")\n    model = interaction_results[behavior]['model']\n    intercept = model.intercept_\n    habitat_coef = model.coef_[0]\n    herdsize_coef = model.coef_[1]\n    interaction_coef = model.coef_[2]\n    \n    # Calculate predictions for each combination\n    closed_large = intercept  # 0 + 0 + 0\n    open_large = intercept + habitat_coef  # 1 + 0 + 0\n    closed_small = intercept + herdsize_coef  # 0 + 1 + 0\n    open_small = intercept + habitat_coef + herdsize_coef + interaction_coef  # 1 + 1 + 1\n    \n    combination_predictions[behavior] = {\n        'Closed+Large': closed_large,\n        'Open+Large': open_large,\n        'Closed+Small': closed_small,\n        'Open+Small': open_small\n    }\n    \n    print(f\"  Closed + Large:  {closed_large:.4f}\")\n    print(f\"  Open + Large:    {open_large:.4f}\")\n    print(f\"  Closed + Small:  {closed_small:.4f}\")\n    print(f\"  Open + Small:    {open_small:.4f}\")\n    \n    # Calculate the interaction effect\n    # Interaction = (Open+Small) - (Open+Large) - (Closed+Small) + (Closed+Large)\n    interaction_effect = open_small - open_large - closed_small + closed_large\n    print(f\"  Interaction effect: {interaction_effect:.4f}\")\n    \n    if abs(interaction_effect) &gt; 0.01 and model_comparison[behavior]['interaction_significant']:\n        if interaction_effect &gt; 0:\n            print(\"  \u2192 Open habitat effect is STRONGER in small herds\")\n        else:\n            print(\"  \u2192 Open habitat effect is WEAKER in small herds\")\n</pre> # ============================================================================ # 4. DETAILED INTERACTION INTERPRETATION # ============================================================================  print(\"\\n\" + \"=\"*60) print(\"INTERACTION EFFECTS INTERPRETATION\") print(\"=\"*60)  # Calculate predicted values for each combination using interaction model print(\"\\nPredicted values for each combination (Interaction Model):\") print(\"-\" * 55)  combination_predictions = {}  for behavior in behaviors:     print(f\"\\n{behavior}:\")     model = interaction_results[behavior]['model']     intercept = model.intercept_     habitat_coef = model.coef_[0]     herdsize_coef = model.coef_[1]     interaction_coef = model.coef_[2]          # Calculate predictions for each combination     closed_large = intercept  # 0 + 0 + 0     open_large = intercept + habitat_coef  # 1 + 0 + 0     closed_small = intercept + herdsize_coef  # 0 + 1 + 0     open_small = intercept + habitat_coef + herdsize_coef + interaction_coef  # 1 + 1 + 1          combination_predictions[behavior] = {         'Closed+Large': closed_large,         'Open+Large': open_large,         'Closed+Small': closed_small,         'Open+Small': open_small     }          print(f\"  Closed + Large:  {closed_large:.4f}\")     print(f\"  Open + Large:    {open_large:.4f}\")     print(f\"  Closed + Small:  {closed_small:.4f}\")     print(f\"  Open + Small:    {open_small:.4f}\")          # Calculate the interaction effect     # Interaction = (Open+Small) - (Open+Large) - (Closed+Small) + (Closed+Large)     interaction_effect = open_small - open_large - closed_small + closed_large     print(f\"  Interaction effect: {interaction_effect:.4f}\")          if abs(interaction_effect) &gt; 0.01 and model_comparison[behavior]['interaction_significant']:         if interaction_effect &gt; 0:             print(\"  \u2192 Open habitat effect is STRONGER in small herds\")         else:             print(\"  \u2192 Open habitat effect is WEAKER in small herds\")  <pre>============================================================\nINTERACTION EFFECTS INTERPRETATION\n============================================================\n\nPredicted values for each combination (Interaction Model):\n-------------------------------------------------------\n\nWalk:\n  Closed + Large:  0.0409\n  Open + Large:    0.1483\n  Closed + Small:  0.4191\n  Open + Small:    0.4287\n  Interaction effect: -0.0978\n\nHead Up:\n  Closed + Large:  0.1699\n  Open + Large:    0.1403\n  Closed + Small:  0.4177\n  Open + Small:    0.4885\n  Interaction effect: 0.1004\n\nGraze:\n  Closed + Large:  0.7215\n  Open + Large:    0.6337\n  Closed + Small:  0.0390\n  Open + Small:    0.0082\n  Interaction effect: 0.0569\n\nOther:\n  Closed + Large:  0.0677\n  Open + Large:    0.0776\n  Closed + Small:  0.1242\n  Open + Small:    0.0746\n  Interaction effect: -0.0595\n</pre> In\u00a0[14]: Copied! <pre># ============================================================================\n# 5. SUMMARY COMPARISON TABLE\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"MODEL COMPARISON SUMMARY\")\nprint(\"=\"*60)\n\nsummary_comparison = pd.DataFrame({\n    'Behavior': behaviors,\n    'Main_R2': [main_effects_results[b]['r2'] for b in behaviors],\n    'Interaction_R2': [interaction_results[b]['r2'] for b in behaviors],\n    'R2_Improvement': [model_comparison[b]['r2_improvement'] for b in behaviors],\n    'F_Statistic': [model_comparison[b]['f_statistic'] for b in behaviors],\n    'P_Value': [model_comparison[b]['p_value'] for b in behaviors],\n    'Interaction_Significant': [model_comparison[b]['interaction_significant'] for b in behaviors]\n})\n\nprint(summary_comparison.round(4))\n\n# Count significant interactions\nsignificant_count = sum(summary_comparison['Interaction_Significant'])\nprint(f\"\\nNumber of behaviors with significant interactions: {significant_count}/4\")\n\nif significant_count &gt; 0:\n    print(\"\\nBehaviors with significant interactions:\")\n    significant_behaviors = summary_comparison[summary_comparison['Interaction_Significant']]['Behavior'].tolist()\n    for behavior in significant_behaviors:\n        p_val = model_comparison[behavior]['p_value']\n        r2_imp = model_comparison[behavior]['r2_improvement']\n        print(f\"  - {behavior}: p = {p_val:.4f}, R\u00b2 improvement = {r2_imp:.4f}\")\n\n# ============================================================================\n# 6. RECOMMENDATION\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"RECOMMENDATION\")\nprint(\"=\"*60)\n\nif significant_count &gt; 0:\n    print(\"\u2705 INTERACTION EFFECTS DETECTED!\")\n    print(\"\\nRecommendation: Use the interaction model for behaviors with significant\")\n    print(\"interaction terms. The habitat and herd size effects are not simply additive\")\n    print(\"- their combined effect differs from what you'd expect by just adding them up.\")\n    print(\"\\nThis suggests that:\")\n    print(\"- The effect of habitat depends on herd size (or vice versa)\")\n    print(\"- Certain combinations have unique behavioral responses\")\nelse:\n    print(\"\u274c NO SIGNIFICANT INTERACTIONS DETECTED\")\n    print(\"\\nRecommendation: Stick with the main effects model. The habitat and\")\n    print(\"herd size effects appear to be additive - you can predict the combined\")\n    print(\"effect by simply adding the individual effects together.\")\n\n# Save detailed results\nsummary_comparison.to_csv('interaction_model_comparison.csv', index=False)\nprint(f\"\\nDetailed results saved to 'interaction_model_comparison.csv'\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"INTERACTION ANALYSIS COMPLETE\")\nprint(\"=\"*60)\n</pre> # ============================================================================ # 5. SUMMARY COMPARISON TABLE # ============================================================================  print(\"\\n\" + \"=\"*60) print(\"MODEL COMPARISON SUMMARY\") print(\"=\"*60)  summary_comparison = pd.DataFrame({     'Behavior': behaviors,     'Main_R2': [main_effects_results[b]['r2'] for b in behaviors],     'Interaction_R2': [interaction_results[b]['r2'] for b in behaviors],     'R2_Improvement': [model_comparison[b]['r2_improvement'] for b in behaviors],     'F_Statistic': [model_comparison[b]['f_statistic'] for b in behaviors],     'P_Value': [model_comparison[b]['p_value'] for b in behaviors],     'Interaction_Significant': [model_comparison[b]['interaction_significant'] for b in behaviors] })  print(summary_comparison.round(4))  # Count significant interactions significant_count = sum(summary_comparison['Interaction_Significant']) print(f\"\\nNumber of behaviors with significant interactions: {significant_count}/4\")  if significant_count &gt; 0:     print(\"\\nBehaviors with significant interactions:\")     significant_behaviors = summary_comparison[summary_comparison['Interaction_Significant']]['Behavior'].tolist()     for behavior in significant_behaviors:         p_val = model_comparison[behavior]['p_value']         r2_imp = model_comparison[behavior]['r2_improvement']         print(f\"  - {behavior}: p = {p_val:.4f}, R\u00b2 improvement = {r2_imp:.4f}\")  # ============================================================================ # 6. RECOMMENDATION # ============================================================================  print(\"\\n\" + \"=\"*60) print(\"RECOMMENDATION\") print(\"=\"*60)  if significant_count &gt; 0:     print(\"\u2705 INTERACTION EFFECTS DETECTED!\")     print(\"\\nRecommendation: Use the interaction model for behaviors with significant\")     print(\"interaction terms. The habitat and herd size effects are not simply additive\")     print(\"- their combined effect differs from what you'd expect by just adding them up.\")     print(\"\\nThis suggests that:\")     print(\"- The effect of habitat depends on herd size (or vice versa)\")     print(\"- Certain combinations have unique behavioral responses\") else:     print(\"\u274c NO SIGNIFICANT INTERACTIONS DETECTED\")     print(\"\\nRecommendation: Stick with the main effects model. The habitat and\")     print(\"herd size effects appear to be additive - you can predict the combined\")     print(\"effect by simply adding the individual effects together.\")  # Save detailed results summary_comparison.to_csv('interaction_model_comparison.csv', index=False) print(f\"\\nDetailed results saved to 'interaction_model_comparison.csv'\")  print(\"\\n\" + \"=\"*60) print(\"INTERACTION ANALYSIS COMPLETE\") print(\"=\"*60) <pre>============================================================\nMODEL COMPARISON SUMMARY\n============================================================\n  Behavior  Main_R2  Interaction_R2  R2_Improvement  F_Statistic  P_Value  \\\n0     Walk   0.4022          0.4084          0.0062       0.8181   0.3685   \n1  Head Up   0.2500          0.2546          0.0046       0.4824   0.4894   \n2    Graze   0.5621          0.5628          0.0008       0.1373   0.7120   \n3    Other   0.0016          0.0082          0.0066       0.5200   0.4730   \n\n   Interaction_Significant  \n0                    False  \n1                    False  \n2                    False  \n3                    False  \n\nNumber of behaviors with significant interactions: 0/4\n\n============================================================\nRECOMMENDATION\n============================================================\n\u274c NO SIGNIFICANT INTERACTIONS DETECTED\n\nRecommendation: Stick with the main effects model. The habitat and\nherd size effects appear to be additive - you can predict the combined\neffect by simply adding the individual effects together.\n\nDetailed results saved to 'interaction_model_comparison.csv'\n\n============================================================\nINTERACTION ANALYSIS COMPLETE\n============================================================\n</pre>"},{"location":"case_studies/1_grevys_landscape/grevys_landscape_lr/#grevys-zebra-time-budget-analysis-linear-regression","title":"Grevy's Zebra Time Budget Analysis: Linear Regression\u00b6","text":"<p>Comparing Habitat and Herd Size Effects on Behavior</p>"},{"location":"case_studies/1_grevys_landscape/grevys_landscape_lr/#analysis-of-interactions-between-habitat-and-herd-size","title":"Analysis of interactions between habitat and herd size\u00b6","text":""},{"location":"case_studies/1_grevys_landscape/data/","title":"Index","text":"<p><code>grevystimebudgetscleaned.csv</code> \u2014 Raw time-budget summaries (per bout / per individual) for Grevy's landscape case study.</p> <p>The <code>grevystimebudgetcleaned.csv</code> file in <code>data/</code> combines the following dates/session published in the KABR Drone Wildlife Monitoring Dataset and KABR Worked Examples datasets: - KABR Drone Wildlife Monitoring Dataset: sourced from <code>data/consolidated_metadata.csv</code>, specifically the sessions on <code>11_01_23</code> , <code>12_01_23</code>, and <code>16_01_23</code>. - KABR Worked Examples: sourced from <code>behavior/</code>, specifically the sessions on <code>18_01_23</code>, <code>20_01_23</code>, and <code>21_02_23</code>.</p> <p>For both datasets, the dates are the prefixes to the relevant videos.</p>"},{"location":"case_studies/2_zebra_transition/behaviortransitionsheatmap/","title":"2: Zebra Behavior Transitions","text":"<p>This script calculates the transition probabilities for zebra behaviors (Grevy's and Plains) from the subset of KABR sessions originally included in the initial mini-scene release.</p> In\u00a0[2]: Copied! <pre>import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n</pre> import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import warnings warnings.filterwarnings('ignore') In\u00a0[3]: Copied! <pre>data = pd.read_csv('data/consolidated_metadata.csv')\n</pre> data = pd.read_csv('data/consolidated_metadata.csv') In\u00a0[4]: Copied! <pre>zebras = data[data['label'] == 'Zebra']\nzebras = zebras[['frame', 'id', 'behaviour', 'video']]\nzebras['time'] = pd.to_datetime(zebras['frame'], unit='s') - pd.to_datetime(zebras['frame'], unit='s').min()\n</pre> zebras = data[data['label'] == 'Zebra'] zebras = zebras[['frame', 'id', 'behaviour', 'video']] zebras['time'] = pd.to_datetime(zebras['frame'], unit='s') - pd.to_datetime(zebras['frame'], unit='s').min() In\u00a0[5]: Copied! <pre>zebras['behaviour'].unique()\n</pre> zebras['behaviour'].unique() Out[5]: <pre>array(['Walk', 'Head Up', 'Out of Frame', 'Graze', 'Occluded',\n       'Out of Focus', 'Auto-Groom', 'Defecating', 'Trotting', 'Running',\n       'Sniff', 'Mutual Grooming', 'Urinating', 'Fighting'], dtype=object)</pre> In\u00a0[7]: Copied! <pre>zebras.head(12)\n</pre> zebras.head(12) Out[7]: frame id behaviour video time 0 0 2.0 Walk 12_01_23-DJI_0994 0 days 00:00:00 1 0 1.0 Walk 12_01_23-DJI_0994 0 days 00:00:00 2 1 2.0 Walk 12_01_23-DJI_0994 0 days 00:00:01 3 1 1.0 Walk 12_01_23-DJI_0994 0 days 00:00:01 4 2 2.0 Walk 12_01_23-DJI_0994 0 days 00:00:02 5 2 1.0 Walk 12_01_23-DJI_0994 0 days 00:00:02 6 3 2.0 Walk 12_01_23-DJI_0994 0 days 00:00:03 7 3 1.0 Walk 12_01_23-DJI_0994 0 days 00:00:03 8 4 2.0 Walk 12_01_23-DJI_0994 0 days 00:00:04 9 4 1.0 Walk 12_01_23-DJI_0994 0 days 00:00:04 10 5 1.0 Walk 12_01_23-DJI_0994 0 days 00:00:05 11 5 2.0 Walk 12_01_23-DJI_0994 0 days 00:00:05 In\u00a0[9]: Copied! <pre># zebras_sorted = zebras_sorted[zebras_sorted['behaviour'] != 'Out of Frame']\n\nzebras = zebras[zebras['behaviour'] != 'Out of Frame']\nzebras = zebras[zebras['behaviour']!= 'Occluded']\nzebras = zebras[zebras['behaviour'] != 'Out of Focus']\n</pre> # zebras_sorted = zebras_sorted[zebras_sorted['behaviour'] != 'Out of Frame']  zebras = zebras[zebras['behaviour'] != 'Out of Frame'] zebras = zebras[zebras['behaviour']!= 'Occluded'] zebras = zebras[zebras['behaviour'] != 'Out of Focus'] In\u00a0[10]: Copied! <pre>len(zebras)\n</pre> len(zebras) Out[10]: <pre>933190</pre> In\u00a0[11]: Copied! <pre>zebras['time'].max()\n</pre> zebras['time'].max()  Out[11]: <pre>Timedelta('0 days 02:25:22')</pre> In\u00a0[8]: Copied! <pre># combine behavior categories into stand-graze, walk, trot, and run\nzebras['behaviour'] = zebras['behaviour'].replace('Graze', 'Graze')\nzebras['behaviour'] = zebras['behaviour'].replace('Walk', 'Walk')\nzebras['behaviour'] = zebras['behaviour'].replace('Trotting', 'Trot')\nzebras['behaviour'] = zebras['behaviour'].replace('Running', 'Run')\n\n# drop all other categories of behavior\nzebras = zebras[zebras['behaviour'].isin(['Graze', 'Walk', 'Trot', 'Run'])]\n</pre> # combine behavior categories into stand-graze, walk, trot, and run zebras['behaviour'] = zebras['behaviour'].replace('Graze', 'Graze') zebras['behaviour'] = zebras['behaviour'].replace('Walk', 'Walk') zebras['behaviour'] = zebras['behaviour'].replace('Trotting', 'Trot') zebras['behaviour'] = zebras['behaviour'].replace('Running', 'Run')  # drop all other categories of behavior zebras = zebras[zebras['behaviour'].isin(['Graze', 'Walk', 'Trot', 'Run'])] In\u00a0[15]: Copied! <pre># downsample to 10 sec (30 fps)\nzebras = zebras[zebras['time'].dt.seconds % (300) == 0]\n</pre> # downsample to 10 sec (30 fps) zebras = zebras[zebras['time'].dt.seconds % (300) == 0] In\u00a0[16]: Copied! <pre># count each occurance of transitions between behaviours\n# create dataframe to store the counts of transitions from one behaviour to another\nbehaviors = zebras['behaviour'].unique()\ntransition_counts = pd.DataFrame(index=behaviors, columns=behaviors)\ntransition_counts = transition_counts.fillna(0)\n</pre> # count each occurance of transitions between behaviours # create dataframe to store the counts of transitions from one behaviour to another behaviors = zebras['behaviour'].unique() transition_counts = pd.DataFrame(index=behaviors, columns=behaviors) transition_counts = transition_counts.fillna(0) In\u00a0[17]: Copied! <pre># count the occurance of each transition for each unique zebra (id)\nfor video in zebras['video'].unique():\n    for zebra in zebras[zebras['video'] == video]['id'].unique():\n        zebra_data = zebras[(zebras['video'] == video) &amp; (zebras['id'] == zebra)]\n        for i in range(1, len(zebra_data)):\n            transition_counts.loc[zebra_data.iloc[i-1]['behaviour'], zebra_data.iloc[i]['behaviour']] += 1\n</pre> # count the occurance of each transition for each unique zebra (id) for video in zebras['video'].unique():     for zebra in zebras[zebras['video'] == video]['id'].unique():         zebra_data = zebras[(zebras['video'] == video) &amp; (zebras['id'] == zebra)]         for i in range(1, len(zebra_data)):             transition_counts.loc[zebra_data.iloc[i-1]['behaviour'], zebra_data.iloc[i]['behaviour']] += 1 In\u00a0[16]: Copied! <pre>transition_counts\n</pre> transition_counts Out[16]: Walk Graze Run Trot Walk 650 97 16 20 Graze 95 1004 0 2 Run 8 0 26 4 Trot 15 3 4 6 In\u00a0[17]: Copied! <pre># normalize transitions by the total number of transitions\ntransition_counts_normalized = transition_counts.div(transition_counts.sum(axis=1), axis=0)\ntransition_counts_normalized\n</pre> # normalize transitions by the total number of transitions transition_counts_normalized = transition_counts.div(transition_counts.sum(axis=1), axis=0) transition_counts_normalized Out[17]: Walk Graze Run Trot Walk 0.830140 0.123883 0.020434 0.025543 Graze 0.086285 0.911898 0.000000 0.001817 Run 0.210526 0.000000 0.684211 0.105263 Trot 0.535714 0.107143 0.142857 0.214286 In\u00a0[20]: Copied! <pre># convert to percentages and rounds to 2 decimal places\ntransition_counts_normalized =round(transition_counts_normalized * 100, 2)\n</pre> # convert to percentages and rounds to 2 decimal places transition_counts_normalized =round(transition_counts_normalized * 100, 2) In\u00a0[21]: Copied! <pre>transition_counts_normalized\n# switch order of walk and stand-graze in the table\ntransition_counts_normalized = transition_counts_normalized[['Graze', 'Walk', 'Trot', 'Run']]\n#transition_counts_normalized = transition_counts_normalized.reindex(['Graze', 'Walk', 'Trot', 'Run'])\n</pre> transition_counts_normalized # switch order of walk and stand-graze in the table transition_counts_normalized = transition_counts_normalized[['Graze', 'Walk', 'Trot', 'Run']] #transition_counts_normalized = transition_counts_normalized.reindex(['Graze', 'Walk', 'Trot', 'Run'])  In\u00a0[22]: Copied! <pre># calculate the percentages row-wise for transitions\ntransition_percentages = transition_counts.div(transition_counts.sum(axis=1), axis=0)\n# sort rows and columns by the order of the behaviors\nbehaviors = transition_percentages.columns\ntransition_percentages = transition_percentages.reindex(behaviors, axis=0)\ntransition_percentages = transition_percentages.reindex(behaviors, axis=1)\ntransition_percentages = round(transition_percentages*100, 2)\n</pre> # calculate the percentages row-wise for transitions transition_percentages = transition_counts.div(transition_counts.sum(axis=1), axis=0) # sort rows and columns by the order of the behaviors behaviors = transition_percentages.columns transition_percentages = transition_percentages.reindex(behaviors, axis=0) transition_percentages = transition_percentages.reindex(behaviors, axis=1) transition_percentages = round(transition_percentages*100, 2) In\u00a0[24]: Copied! <pre># Reorder rows and columns to switch \"Walk\" and \"Graze\"\nreordered_behaviors = ['Graze', 'Walk', 'Trot', 'Run']\ntransition_percentages = transition_percentages.reindex(reordered_behaviors, axis=0)\ntransition_percentages = transition_percentages.reindex(reordered_behaviors, axis=1)\n\n# Plot the heatmap with the updated order\nplt.figure(figsize=(10, 8))\nsns.heatmap(transition_percentages, cmap='rocket', annot=True, fmt='g')\n\n# Add numbers on each cell\nfor i in range(len(reordered_behaviors)):\n    for j in range(len(reordered_behaviors)):\n        plt.text(j + 0.5, i + 0.5, transition_percentages.iloc[i, j],\n                 horizontalalignment='center',\n                 verticalalignment='center')\n\nplt.title('Transition Percentages Between Behaviors')\nplt.xlabel('Current Behavior')\nplt.ylabel('Previous Behavior')\nplt.show()\n</pre> # Reorder rows and columns to switch \"Walk\" and \"Graze\" reordered_behaviors = ['Graze', 'Walk', 'Trot', 'Run'] transition_percentages = transition_percentages.reindex(reordered_behaviors, axis=0) transition_percentages = transition_percentages.reindex(reordered_behaviors, axis=1)  # Plot the heatmap with the updated order plt.figure(figsize=(10, 8)) sns.heatmap(transition_percentages, cmap='rocket', annot=True, fmt='g')  # Add numbers on each cell for i in range(len(reordered_behaviors)):     for j in range(len(reordered_behaviors)):         plt.text(j + 0.5, i + 0.5, transition_percentages.iloc[i, j],                  horizontalalignment='center',                  verticalalignment='center')  plt.title('Transition Percentages Between Behaviors') plt.xlabel('Current Behavior') plt.ylabel('Previous Behavior') plt.show() In\u00a0[27]: Copied! <pre># heatmap of transition percentages\nplt.figure(figsize=(10, 8))\nsns.heatmap(transition_percentages, cmap='cividis', fmt='g')\nplt.title('Transitions Between Locomotion Behavior Categories (1 second intervals)')\nplt.xticks(rotation=45, fontsize=15)\nplt.yticks(rotation=0, fontsize=15)\nplt.title('Transitions Between Zebra Locomotion Behaviors', fontsize=20)\nplt.xlabel('Current Behavior', fontsize=20)\nplt.ylabel('Previous Behavior', fontsize=20)\nplt.show()\n</pre> # heatmap of transition percentages plt.figure(figsize=(10, 8)) sns.heatmap(transition_percentages, cmap='cividis', fmt='g') plt.title('Transitions Between Locomotion Behavior Categories (1 second intervals)') plt.xticks(rotation=45, fontsize=15) plt.yticks(rotation=0, fontsize=15) plt.title('Transitions Between Zebra Locomotion Behaviors', fontsize=20) plt.xlabel('Current Behavior', fontsize=20) plt.ylabel('Previous Behavior', fontsize=20) plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"case_studies/2_zebra_transition/behaviortransitionsheatmap/#behavior-transition-probabilities","title":"Behavior transition probabilities\u00b6","text":""},{"location":"case_studies/2_zebra_transition/behaviortransitionsheatmap/#download-dataset-from-huggingface","title":"Download dataset from HuggingFace\u00b6","text":"<p>Use 'consolidated_metadata.csv' file from KABR Drone Wildlife Monitoring Dataset for data used in this case study.</p>"},{"location":"case_studies/2_zebra_transition/data/","title":"Index","text":"<p>See previously released <code>consolidated_metadata.csv</code> file on Hugging Face, in the Imageomics/kabr-behavior-telemetry repository, for data used in this case study.</p>"},{"location":"case_studies/3_mixed_species_social/mixed_species_overlap/","title":"3: Mixed Species Social","text":"In\u00a0[1]: Copied! <pre>import xml.etree.ElementTree as ET\nfrom shapely.geometry import box\nfrom itertools import combinations\nfrom collections import defaultdict, Counter\nimport os\nimport pandas as pd\nwarnings.filterwarnings('ignore')\n</pre> import xml.etree.ElementTree as ET from shapely.geometry import box from itertools import combinations from collections import defaultdict, Counter import os import pandas as pd warnings.filterwarnings('ignore') <pre>/users/PAS2136/kline377/.conda/envs/auto_drone/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n  from pandas.core import (\n</pre> In\u00a0[11]: Copied! <pre>from collections import Counter\nimport xml.etree.ElementTree as ET\nfrom pathlib import Path\nimport csv   # only needed if you want CSV output\n\n# ---------------------------------------------------------------------\n# 1.  CONFIGURE THESE TWO LINES\n# ---------------------------------------------------------------------\ninput_dir = \"detections\"\ndata_root = Path(input_dir)  # top\u2011level directory\nxml_pattern = \"**/*.xml\"                             # recursive search\n\n# ---------------------------------------------------------------------\n# 2.  GATHER COUNTS ACROSS ALL FILES\n# ---------------------------------------------------------------------\nspecies_totals = Counter()\n\nfor xml_file in data_root.glob(xml_pattern):\n    try:\n        root = ET.parse(xml_file).getroot()\n        species_totals.update(\n            track.attrib[\"label\"]\n            for track in root.findall(\".//track\")\n        )\n    except ET.ParseError as e:\n        print(f\"\u26a0\ufe0f  Skipped {xml_file.name} \u2192 parse error: {e}\")\n\n# ---------------------------------------------------------------------\n# 3.  DISPLAY RESULTS\n# ---------------------------------------------------------------------\nprint(\"\\n=== Total track counts across all files ===\")\nfor label, n in species_totals.most_common():\n    print(f\"{label:&lt;20} : {n}\")\n\n# \n</pre> from collections import Counter import xml.etree.ElementTree as ET from pathlib import Path import csv   # only needed if you want CSV output  # --------------------------------------------------------------------- # 1.  CONFIGURE THESE TWO LINES # --------------------------------------------------------------------- input_dir = \"detections\" data_root = Path(input_dir)  # top\u2011level directory xml_pattern = \"**/*.xml\"                             # recursive search  # --------------------------------------------------------------------- # 2.  GATHER COUNTS ACROSS ALL FILES # --------------------------------------------------------------------- species_totals = Counter()  for xml_file in data_root.glob(xml_pattern):     try:         root = ET.parse(xml_file).getroot()         species_totals.update(             track.attrib[\"label\"]             for track in root.findall(\".//track\")         )     except ET.ParseError as e:         print(f\"\u26a0\ufe0f  Skipped {xml_file.name} \u2192 parse error: {e}\")  # --------------------------------------------------------------------- # 3.  DISPLAY RESULTS # --------------------------------------------------------------------- print(\"\\n=== Total track counts across all files ===\") for label, n in species_totals.most_common():     print(f\"{label:&lt;20} : {n}\")  #  <pre>=== Total track counts across all files ===\nGrevys Zebra         : 101\nGiraffe              : 56\nPlains Zebra         : 5\n</pre> In\u00a0[2]: Copied! <pre># --- CONFIGURATION ---\niou_threshold = 0.5  # Minimum intersection threshold (non-zero for robustness)\nspecies_of_interest = [\"Grevys Zebra\", \"Plains Zebra\", \"Giraffe\"]\ninput_dir = \"detections\"  # &lt;-- update this\n\n# --- PARSE XML ---\ndef parse_xml(filepath):\n    tree = ET.parse(filepath)\n    root = tree.getroot()\n    frame_data = defaultdict(list)\n\n    for track in root.findall(\"track\"):\n        species = track.attrib[\"label\"]\n        if species not in species_of_interest:\n            continue\n        for box_elem in track.findall(\"box\"):\n            if box_elem.attrib[\"outside\"] == \"1\":\n                continue  # Skip invisible boxes\n            frame = int(box_elem.attrib[\"frame\"])\n            xtl = float(box_elem.attrib[\"xtl\"])\n            ytl = float(box_elem.attrib[\"ytl\"])\n            xbr = float(box_elem.attrib[\"xbr\"])\n            ybr = float(box_elem.attrib[\"ybr\"])\n            shape = box(xtl, ytl, xbr, ybr)\n            frame_data[frame].append({\"species\": species, \"bbox\": shape})\n    return frame_data\n\n# --- COMPUTE OVERLAPS ---\ndef compute_overlaps(frame_data):\n    overlap_counts = Counter()\n    for frame, objects in frame_data.items():\n        for a, b in combinations(objects, 2):\n            if a[\"bbox\"].intersects(b[\"bbox\"]):\n                inter_area = a[\"bbox\"].intersection(b[\"bbox\"]).area\n                union_area = a[\"bbox\"].union(b[\"bbox\"]).area\n                iou = inter_area / union_area\n                if iou &gt;= iou_threshold:\n                    sp_a = a[\"species\"]\n                    sp_b = b[\"species\"]\n                    pair = tuple(sorted([sp_a, sp_b]))\n                    overlap_counts[pair] += 1\n    return overlap_counts\n\n# --- MAIN LOOP ---\ntotal_counts = Counter()\n\nfor filename in os.listdir(input_dir):\n    if filename.endswith(\".xml\"):\n        path = os.path.join(input_dir, filename)\n        frame_data = parse_xml(path)\n        overlap_counts = compute_overlaps(frame_data)\n        total_counts.update(overlap_counts)\n\n# --- FORMAT RESULTS ---\ndf = pd.DataFrame(\n    [{\"Species Pair\": f\"{a}\u2013{b}\", \"Overlap Count\": count} for (a, b), count in total_counts.items()]\n)\ndf = df.sort_values(by=\"Overlap Count\", ascending=False).reset_index(drop=True)\n\n# --- DISPLAY OR SAVE ---\nprint(df)\n# Optionally save:\n# df.to_csv(\"overlap_summary.csv\", index=False)\n</pre>  # --- CONFIGURATION --- iou_threshold = 0.5  # Minimum intersection threshold (non-zero for robustness) species_of_interest = [\"Grevys Zebra\", \"Plains Zebra\", \"Giraffe\"] input_dir = \"detections\"  # &lt;-- update this  # --- PARSE XML --- def parse_xml(filepath):     tree = ET.parse(filepath)     root = tree.getroot()     frame_data = defaultdict(list)      for track in root.findall(\"track\"):         species = track.attrib[\"label\"]         if species not in species_of_interest:             continue         for box_elem in track.findall(\"box\"):             if box_elem.attrib[\"outside\"] == \"1\":                 continue  # Skip invisible boxes             frame = int(box_elem.attrib[\"frame\"])             xtl = float(box_elem.attrib[\"xtl\"])             ytl = float(box_elem.attrib[\"ytl\"])             xbr = float(box_elem.attrib[\"xbr\"])             ybr = float(box_elem.attrib[\"ybr\"])             shape = box(xtl, ytl, xbr, ybr)             frame_data[frame].append({\"species\": species, \"bbox\": shape})     return frame_data  # --- COMPUTE OVERLAPS --- def compute_overlaps(frame_data):     overlap_counts = Counter()     for frame, objects in frame_data.items():         for a, b in combinations(objects, 2):             if a[\"bbox\"].intersects(b[\"bbox\"]):                 inter_area = a[\"bbox\"].intersection(b[\"bbox\"]).area                 union_area = a[\"bbox\"].union(b[\"bbox\"]).area                 iou = inter_area / union_area                 if iou &gt;= iou_threshold:                     sp_a = a[\"species\"]                     sp_b = b[\"species\"]                     pair = tuple(sorted([sp_a, sp_b]))                     overlap_counts[pair] += 1     return overlap_counts  # --- MAIN LOOP --- total_counts = Counter()  for filename in os.listdir(input_dir):     if filename.endswith(\".xml\"):         path = os.path.join(input_dir, filename)         frame_data = parse_xml(path)         overlap_counts = compute_overlaps(frame_data)         total_counts.update(overlap_counts)  # --- FORMAT RESULTS --- df = pd.DataFrame(     [{\"Species Pair\": f\"{a}\u2013{b}\", \"Overlap Count\": count} for (a, b), count in total_counts.items()] ) df = df.sort_values(by=\"Overlap Count\", ascending=False).reset_index(drop=True)  # --- DISPLAY OR SAVE --- print(df) # Optionally save: # df.to_csv(\"overlap_summary.csv\", index=False)  <pre>/users/PAS2136/kline377/.conda/envs/auto_drone/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n  from pandas.core import (\n</pre> <pre>                Species Pair  Overlap Count\n0  Grevys Zebra\u2013Grevys Zebra           4836\n1  Plains Zebra\u2013Plains Zebra             93\n2            Giraffe\u2013Giraffe             78\n3  Grevys Zebra\u2013Plains Zebra             28\n</pre> In\u00a0[4]: Copied! <pre>total_interactions = sum(total_counts.values())\nprint(f\"\\nTotal interactions across all files: {total_interactions}\")\n</pre> total_interactions = sum(total_counts.values()) print(f\"\\nTotal interactions across all files: {total_interactions}\") <pre>Total interactions across all files: 5035\n</pre>"},{"location":"case_studies/3_mixed_species_social/mixed_species_overlap/#use-bounding-boxes-to-detect-inter-and-intra-species-interactions","title":"Use bounding boxes to detect inter- and intra-species interactions\u00b6","text":""},{"location":"case_studies/3_mixed_species_social/mixed_species_overlap/#first-count-the-number-of-mini-scenes-for-each-species","title":"First, count the number of mini-scenes for each species\u00b6","text":""},{"location":"case_studies/3_mixed_species_social/mixed_species_overlap/#parse-the-files-to-find-where-species-overlap","title":"Parse the files to find where species overlap\u00b6","text":""},{"location":"case_studies/3_mixed_species_social/data/","title":"Index","text":"<p>Download data used for this case-study from the KABR worked examples dataset on Hugging Face. Use the CSV files starting with '21_01_2023_session_5' from the <code>detections/</code> folder.</p>"},{"location":"cvat/cvat-data-management/","title":"Data Management","text":""},{"location":"cvat/cvat-data-management/#cvat-data-management-recommendations","title":"CVAT Data Management Recommendations","text":"<p>Working with large video datasets can be challenging. We have compiled some tools and suggestions to make this easier.</p>"},{"location":"cvat/cvat-data-management/#organizing-metadata","title":"Organizing metadata","text":"<p>We recommend naming video files with metadata.</p> <ul> <li> <p>This helps keep videos organized, especially if the SRT files are stored elsewhere. </p> </li> <li> <p>Keeping naming conventions consistent across the dataset makes it easier to query specific videos. </p> </li> <li> <p>For example, a video file name could be something like \"YYYYMMDD-species-location-videoidXX.mp4\", where YYYMMDD is the date the video was collected, \"species\" is the animal type in the video, and \"location\" is the geographical location the footage was collected at. The \"videoidXX\" is the ID label automatically generated by the camera, we highly recommend retaining this information as it can be used to reference other automatically generated metadata, such the SRT file associated with the video, or telemetry data.</p> </li> <li> <p>Labelling videos with metadata is also helpful when the video files need to be moved around different systems for storage or analysis, as discussed below.</p> </li> <li> <p>See rename.sh for an example of renaming all video files in a directory. Note: this script was written for a collection of videos where the metadata (species and date) was stored in the video file path.</p> </li> </ul>"},{"location":"cvat/cvat-data-management/#dealing-with-large-video-files-in-cvat","title":"Dealing with large video files in CVAT","text":"<p>We recommend downgrading the raw video files to a lower resolution before uploading them to CVAT.</p> <ul> <li> <p>Analyzing long or high-resolution videos in CVAT can be challenging. Larger files may buffer, creating delays in the manual annotation process. Some instances of CVAT may not allow 4K or 5K videos to be uploaded. </p> </li> <li> <p>We downgraded the raw videos from 5K to 1080p and then uploaded the 1080p version to CVAT.  These lower-resolution videos ran much faster than the original raw videos while still having sufficient resolution to detect the animals manually. </p> </li> <li> <p>See downgrade.sh for the script.</p> </li> </ul> <p>Important Note</p> <ul> <li>If videos are downgraded in Step 2A (performing detections to create tracks) they must be upscaled for Step 2B (creating mini-scenes).</li> <li>If the detections are done on a lower-resolution video, these annotations must be scaled back to match the original size before creating mini-scenes. Preserving the highest-resolution videos possible for the mini-scenes is essential. This ensures the behavior detection model has a higher success rate in detecting behavior in the video. </li> </ul>"},{"location":"cvat/cvat-data-management/#transferring-video-files-between-servers","title":"Transferring video files between servers","text":"<p>We recommend using a tool like Globus to transfer large datasets across systems.</p> <ul> <li> <p>You may want to keep some of your data on a different server than you use to run CVAT. </p> </li> <li> <p>The CVAT instance must have at least 20% memory free to operate</p> </li> <li> <p>To prevent out-of-memory issues, we kept our raw video data on a different server and moved the data back and forth to the server with our CVAT instance using Globus</p> </li> <li> <p>To adopt this workflow, you should install Globus Connect Personal onto your server and provide it access to the directory for the host volume mounted to CVAT.</p> </li> <li> <p>If you are comfortable working with command-line tools, rsync will also work. For details, see the rsync tutorial.</p> </li> </ul>"},{"location":"cvat/cvat-guide/","title":"Setup and Usage","text":""},{"location":"cvat/cvat-guide/#cvat-setup-and-usage-guide","title":"CVAT Setup and Usage Guide","text":"<p>This guide provides comprehensive instructions for setting up and using CVAT (Computer Vision Annotation Tool) for video annotation tasks in the KABR tools pipeline.</p>"},{"location":"cvat/cvat-guide/#overview","title":"Overview","text":"<p>We chose to set up a self-hosted instance of CVAT on a remote server. We chose this option so we could manage our data more easily, and every person on our team could access the server remotely to complete their annotations.</p> <p>We set up our instance of CVAT on a server with a AMD EPYC 7513 32-Core Processor, running Ubuntu 20.04.6 LTS (GNU/Linux 5.4.0-190-generic x86_64).</p> <p>Alternative Installation Options</p> <p>CVAT may also be accessed online using CVAT Cloud or installed locally on Microsoft, Apple, and Linux computers. See the CVAT Getting Started documentation for instructions.</p>"},{"location":"cvat/cvat-guide/#setting-up-cvat","title":"Setting up CVAT","text":"<p>Please have a look at the CVAT Installation Guide for instructions to set up the tool using Docker on a computer running Ubuntu OS.</p> <p>See CVAT's Manuals for further information.</p>"},{"location":"cvat/cvat-guide/#detailed-installation-instructions","title":"Detailed Installation Instructions","text":"<p>Step 1: Retrieve the CVAT source code</p> <p>As of writing, the latest release of CVAT is v2.17.0. CVAT is updated frequently with new features and bug fixes. You may retrieve this (or any) specific version using <code>wget</code>:</p> <pre><code>CVAT_VERSION=\"v2.17.0\" &amp;&amp; CVAT_V=\"${CVAT_VERSION#v}\"\nwget https://github.com/cvat-ai/cvat/archive/refs/tags/${CVAT_VERSION}.zip &amp;&amp; unzip ${CVAT_VERSION}.zip &amp;&amp; mv cvat-${CVAT_V} cvat &amp;&amp; rm ${CVAT_VERSION}.zip &amp;&amp; cd cvat\n</code></pre> <p>Step 2: Set the CVAT_HOST environment variable</p> <p>One-time Setup</p> <p>This should only be done once. Skip this if upgrading.</p> <pre><code>echo \"export CVAT_HOST=localhost\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <p>Step 3: Optionally mount a host volume</p> <p>To access data within CVAT from the host machine (rather than needing to upload through the browser), create the file <code>docker-compose.override.yml</code> in the same directory as <code>docker-compose.yml</code>. Add the following to the <code>docker-compose.override.yml</code> file:</p> <pre><code>services:\n  cvat_server:\n    volumes:\n      - cvat_share:/home/django/share:ro\n  cvat_worker_import:\n    volumes:\n      - cvat_share:/home/django/share:ro\n  cvat_worker_export:\n    volumes:\n      - cvat_share:/home/django/share:ro\n  cvat_worker_annotation:\n    volumes:\n      - cvat_share:/home/django/share:ro\n\nvolumes:\n  cvat_share:\n    driver_opts:\n      type: none\n      device: /abs/path/to/host/data/directory # Edit this line\n      o: bind\n</code></pre> <p>Step 4: Build CVAT</p> <p>Host Volume</p> <p>Exclude the <code>-f docker-compose.override.yml</code> below if not mounting a host volume.</p> <pre><code>docker compose -f docker-compose.yml -f docker-compose.override.yml up --build -d\n</code></pre>"},{"location":"cvat/cvat-guide/#accessing-cvat","title":"Accessing CVAT","text":"<p>After CVAT was set up on our remote server, users ran the following commands in their terminal to use the CVAT web interface:</p> <pre><code>ssh username@servername -N -L 8080:localhost:8080\n</code></pre> <p>Next, users navigated to Chrome, and entered <code>http://localhost:8080/</code> into their browser to open the CVAT GUI.</p> <p></p>"},{"location":"cvat/cvat-guide/#creating-tasks-in-cvat","title":"Creating Tasks in CVAT","text":"<ol> <li> <p>Open CVAT web GUI by navigating to <code>http://localhost:8080/</code> in Chrome.</p> </li> <li> <p>Login to CVAT.</p> </li> <li> <p>Navigate to Projects and click on your project.</p> </li> <li> <p>Click on 'Create multi tasks'</p> <p></p> </li> <li> <p>Select files - Navigate to 'Connected file share' and select the files you want to upload to create tasks.</p> <p>Processing Time</p> <p>This may take some time if the files are large.</p> <p></p> </li> <li> <p>Clean up - Once a task is created for the video, you may delete the original video file from the server since CVAT will save the data in a different location.</p> </li> </ol>"},{"location":"cvat/cvat-guide/#detections-in-cvat","title":"Detections in CVAT","text":""},{"location":"cvat/cvat-guide/#manual-bounding-box-detection","title":"Manual Bounding Box Detection","text":"<ol> <li> <p>Access your task - Once you login to CVAT, navigate to the Projects tab where you should see your assigned tasks. Click on the task to open it.</p> </li> <li> <p>Assign and open task - Choose a task to work and assign it to yourself under 'Assignee'. Click on 'Job #' to open task.</p> <p></p> </li> <li> <p>Optional: Select region of interest - Select a region of interest to zoom in on the scene.</p> <p></p> </li> <li> <p>Set up detection tool - Click on the rectangle and select the correct species. Check the filename if you aren't sure. Make sure to select \"Track\".</p> <p></p> </li> <li> <p>Draw bounding boxes - Draw a box around each animal in view.</p> <p></p> </li> <li> <p>Track through frames - Use the &gt;&gt; button, or press 'V' on your keyboard to advance 10 frames. Update the bounding boxes by dragging them to the correct positions as required.</p> <p>Save Frequently</p> <p>Make sure to save frequently! You can stop, save, and start working on the video later at any time.</p> <p></p> </li> <li> <p>Complete annotation - Continue until all the frames have been annotated. Save your results.</p> </li> <li> <p>Mark as complete - Once you are done, select \"Validation\" so the project lead knows the task is complete.</p> <p></p> </li> </ol>"},{"location":"cvat/cvat-guide/#behavior-labeling-in-cvat","title":"Behavior Labeling in CVAT","text":"<ol> <li> <p>Access your task - Once you login to CVAT, navigate to the Projects tab where you should see your assigned tasks. Click on the task to open it.</p> <p></p> </li> <li> <p>Set up point annotation - Click on \"Draw new points\" (1) then select the appropriate animal (2). Next, select \"Track\".</p> <p> </p> </li> <li> <p>Annotate behavior - Place your dot anywhere on the screen and select the appropriate behavior. Here, the zebra is \"Head Up\".</p> <p></p> </li> <li> <p>Continue annotation - Continue annotating the video, updating the object label as the animal changes behavior. See the Updated Ethogram for explanations of the different behavior categories. Pay particular attention to the caveats on any \"out of sight\" sub-categories.</p> <p>Save Frequently</p> <p>Make sure to save current changes frequently. You can annotate part of a video and come back to complete it later.</p> </li> <li> <p>Complete the job - Once you are done annotating, save the annotations for a final time, change the job status to \"completed\" and then select \"Finish the job.\"</p> <p></p> </li> </ol>"},{"location":"cvat/cvat-guide/#downloading-annotations","title":"Downloading Annotations","text":"<p>You may download annotations for individual tasks, or the entire project.</p> <ol> <li> <p>Access export options - Click on the 3 vertical dots in the lower right corner of the project or task.</p> </li> <li> <p>Select export type - Select \"Export dataset\" to export a project, or \"Export task dataset\" to export a task.</p> <p> </p> </li> <li> <p>Configure export - Export in \"CVAT for video 1.1\" format, deselect the option to \"Save images\", and click \"Ok\".</p> <p></p> </li> <li> <p>Download dataset - Once the export request is complete, navigate to the \"Requests\" tab and download the dataset.</p> <p></p> </li> </ol>"},{"location":"cvat/cvat-guide/#using-your-annotations","title":"Using Your Annotations","text":"<p>For detections: You may use your detections to create mini-scenes using tracks_extractor. These mini-scenes can be automatically annotated with behavior labels using the KABR model.</p> <p>For behaviors: You may use your annotated behaviors to fine-tune a behavior recognition model, such as X3D, or create time-budgets with the time budget notebook.</p>"},{"location":"methodology_comparison/overview/","title":"Overview","text":""},{"location":"methodology_comparison/overview/#scripts-for-methodology-comparison","title":"Scripts for methodology comparison","text":""},{"location":"methodology_comparison/overview/#scan-versus-focal-sampling","title":"Scan versus Focal Sampling","text":"<p>Download <code>scan vs focal</code> files from the KABR Methodology Hugging Face dataset and place them in the <code>scanvsfocal/data/</code> directory.</p> <p>See the scan vs focal notebook for analysis of the scan versus focal sampling methodology.</p> <p></p>"},{"location":"methodology_comparison/overview/#focal-versus-drone-sampling","title":"Focal versus Drone Sampling","text":"<p>Download <code>focal vs drone</code> files from the KABR Methodology Hugging Face dataset and place them in the <code>focalvsdrone/data/</code> directory.</p> <p>See the focal vs drone notebook for analysis of the focal versus drone sampling methodology.</p> <p></p>"},{"location":"methodology_comparison/overview/#manual-versus-automated-behavior-labelling-for-drone-videos","title":"Manual versus Automated Behavior Labelling for Drone Videos","text":"<p>See the KABR summary notebook for analysis of the manual versus automated behavior labelling for drone videos.</p> <p></p>"},{"location":"methodology_comparison/focalvsdrone/analysis/cm-focal-vs-drone/","title":"Comparison","text":"<p>Download <code> focalvsdrone</code>  files used in this analysis from kabr-methodology collection in Hugging Face.</p> In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nYou need numpy, polars, scikit-learn and matplotlib to run this script:\n\npip install --upgrade numpy polars scikit-learn matplotlib\n\nThen run python confusion_matrix_sam.py. \nIt will save two files: confusion.pdf and confusion-with-out-of-sight.pdf.\n\"\"\"\n\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport polars as pl\nimport sklearn.metrics\nimport re\n\ndata_root = \"/focalvsdrone\"\n</pre> \"\"\" You need numpy, polars, scikit-learn and matplotlib to run this script:  pip install --upgrade numpy polars scikit-learn matplotlib  Then run python confusion_matrix_sam.py.  It will save two files: confusion.pdf and confusion-with-out-of-sight.pdf. \"\"\"  import os  import matplotlib.pyplot as plt import numpy as np import polars as pl import sklearn.metrics import re  data_root = \"/focalvsdrone\" <p>Notes on labels: Browse excluded since only zebra data used to compare drone vs field focal sampling. Run and Trot combined for readibility since behaviors are similar (locomotion). Labels arrange in descending order of occurance frequency in dataset. (See distribution plot.)</p> In\u00a0[2]: Copied! <pre># labels = [\n#     \"Graze\", \"Walk\", \"Head Up\", \"Trot/Run\", \"Auto-Groom\",\n#      \"Defecate\", \"Fight\", \"Out of Sight\"\n#     ]\n\nlabels = [\n    \"Graze\", \"Walk\", \"Head Up\", \"Run\", \n    \"Browse\", \"Trot\", \"Auto-Groom\", \"Out of Sight\"]\n</pre> # labels = [ #     \"Graze\", \"Walk\", \"Head Up\", \"Trot/Run\", \"Auto-Groom\", #      \"Defecate\", \"Fight\", \"Out of Sight\" #     ]  labels = [     \"Graze\", \"Walk\", \"Head Up\", \"Run\",      \"Browse\", \"Trot\", \"Auto-Groom\", \"Out of Sight\"] In\u00a0[41]: Copied! <pre># Regex patterns (case-insensitive) \u2192 canonical label\nCATEGORY_PATTERNS = {\n    r\"(vigilant|stand|head\\s*up|alert\\s*vigilance|vigilance)\":            \"Head Up\",\n    r\"(fight|chase)\":                                           \"Out of Sight\",\n    r\"(out\\s*of\\s*sight|out\\s*of\\s*focus|\"\n    r\"out\\s*of\\s*frame|occluded|no\\s*data)\":                    \"Out of Sight\",\n    r\"(trot|trotting)\":                                         \"Trot\",\n    r\"(run|running)\":                                            \"Run\",\n    r\"(walk|walking)\":                                          \"Walk\",\n    r\"sniff\":                                                    \"Graze\",\n    r\"graze\":                                                    \"Graze\",\n    r\"browse|browsing\":                                          \"Browse\",\n    r\"auto[-\\s]*groom\":                                         \"Auto-Groom\",\n    r\"Defecating|defecate|defecation\":                     \"Defecate\",\n    \n}\n\ndef clean_categories(name: str) -&gt; str:\n    \"\"\"\n    Standardise free-text behaviour labels:\n        * remove 'ing' variants (e.g. Running \u2192 Run)\n        * merge Trot &amp; Run\n        * map all occlusion / missing-data phrases to 'Out of Sight'\n    \"\"\"\n    text = name.lower()\n    for pattern, canon in CATEGORY_PATTERNS.items():\n        if re.search(pattern, text):\n            return canon\n    # If nothing matched, title-case the original so it fits the style\n    return name.title()\n\n\ndef filter_label(y_true, y_pred, bad_label):\n    return zip(\n        *[\n            (t, p)\n            for t, p in zip(y_true, y_pred)\n            if (t != bad_label) and (p != bad_label)\n        ]\n    )\n\ndef read_csvs(root):\n    df = pl.concat([pl.read_csv(os.path.join(root, file)) for file in os.listdir(root)])\n    df = df.rename({\"focal_behavior\": \"field\", \"behavior\": \"drone\"})\n    return df\n\n\ndef make_cm(df, *, filter_oos=False):\n    field = [clean_categories(label) for label in df.get_column(\"field\").to_list()]\n    drone = [clean_categories(label) for label in df.get_column(\"drone\").to_list()]\n\n    if filter_oos:\n        field, drone = filter_label(field, drone, \"Out of Sight\")\n      \n    print(\"Field labels:\", sorted(set(field)))\n    print(\"Drone labels:\", sorted(set(drone)))\n\n    cm = sklearn.metrics.confusion_matrix(\n        y_true=field, y_pred=drone, labels=labels, normalize=\"true\"\n    )\n\n    return cm \n\n\nif __name__ == \"__main__\":\n    #df = read_csvs(data_root)\n    df = read_csvs('/fs/ess/PAS2136/Kenya-2023/Zebras/methods_paper_analysis/kabr-tools/_hugging_face/methodology_comparison/focalvsdrone/data')\n    cm = make_cm(df, filter_oos=False)\n</pre>  # Regex patterns (case-insensitive) \u2192 canonical label CATEGORY_PATTERNS = {     r\"(vigilant|stand|head\\s*up|alert\\s*vigilance|vigilance)\":            \"Head Up\",     r\"(fight|chase)\":                                           \"Out of Sight\",     r\"(out\\s*of\\s*sight|out\\s*of\\s*focus|\"     r\"out\\s*of\\s*frame|occluded|no\\s*data)\":                    \"Out of Sight\",     r\"(trot|trotting)\":                                         \"Trot\",     r\"(run|running)\":                                            \"Run\",     r\"(walk|walking)\":                                          \"Walk\",     r\"sniff\":                                                    \"Graze\",     r\"graze\":                                                    \"Graze\",     r\"browse|browsing\":                                          \"Browse\",     r\"auto[-\\s]*groom\":                                         \"Auto-Groom\",     r\"Defecating|defecate|defecation\":                     \"Defecate\",      }  def clean_categories(name: str) -&gt; str:     \"\"\"     Standardise free-text behaviour labels:         * remove 'ing' variants (e.g. Running \u2192 Run)         * merge Trot &amp; Run         * map all occlusion / missing-data phrases to 'Out of Sight'     \"\"\"     text = name.lower()     for pattern, canon in CATEGORY_PATTERNS.items():         if re.search(pattern, text):             return canon     # If nothing matched, title-case the original so it fits the style     return name.title()   def filter_label(y_true, y_pred, bad_label):     return zip(         *[             (t, p)             for t, p in zip(y_true, y_pred)             if (t != bad_label) and (p != bad_label)         ]     )  def read_csvs(root):     df = pl.concat([pl.read_csv(os.path.join(root, file)) for file in os.listdir(root)])     df = df.rename({\"focal_behavior\": \"field\", \"behavior\": \"drone\"})     return df   def make_cm(df, *, filter_oos=False):     field = [clean_categories(label) for label in df.get_column(\"field\").to_list()]     drone = [clean_categories(label) for label in df.get_column(\"drone\").to_list()]      if filter_oos:         field, drone = filter_label(field, drone, \"Out of Sight\")            print(\"Field labels:\", sorted(set(field)))     print(\"Drone labels:\", sorted(set(drone)))      cm = sklearn.metrics.confusion_matrix(         y_true=field, y_pred=drone, labels=labels, normalize=\"true\"     )      return cm    if __name__ == \"__main__\":     #df = read_csvs(data_root)     df = read_csvs('/fs/ess/PAS2136/Kenya-2023/Zebras/methods_paper_analysis/kabr-tools/_hugging_face/methodology_comparison/focalvsdrone/data')     cm = make_cm(df, filter_oos=False) <pre>Field labels: ['Graze', 'Head Up', 'Out of Sight', 'Trot', 'Walk']\nDrone labels: ['Auto-Groom', 'Defecating', 'Graze', 'Head Up', 'Out of Sight', 'Trot', 'Walk']\n</pre> In\u00a0[42]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(12, 10))\nsns.heatmap(cm,\n            annot=True, fmt=\".2f\",\n            xticklabels=labels,\n            yticklabels=labels,\n            cmap='cividis', vmin=0, vmax=1)\nax.set_xlabel(\"Drone Focal\", fontsize=14)\nax.set_ylabel(\"Ground Focal\", fontsize=14)\nax.set_title(\"Gound vs Drone Focal Behavior Data\", fontsize=20)\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=12)\nplt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\nfig.savefig(\"../cm-focal-vs-drone.pdf\", dpi=300)\n</pre> import seaborn as sns import matplotlib.pyplot as plt  fig, ax = plt.subplots(figsize=(12, 10)) sns.heatmap(cm,             annot=True, fmt=\".2f\",             xticklabels=labels,             yticklabels=labels,             cmap='cividis', vmin=0, vmax=1) ax.set_xlabel(\"Drone Focal\", fontsize=14) ax.set_ylabel(\"Ground Focal\", fontsize=14) ax.set_title(\"Gound vs Drone Focal Behavior Data\", fontsize=20) plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=12) plt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=12) plt.tight_layout() plt.show()  fig.savefig(\"../cm-focal-vs-drone.pdf\", dpi=300) In\u00a0[12]: Copied! <pre>fig, ax = plt.subplots(figsize=(12, 10))\nheatmap = sns.heatmap(cm,\n                      annot=False, fmt=\".2f\",\n                      xticklabels=labels,\n                      yticklabels=labels,\n                      cmap='cividis', vmin=0, vmax=1)  # Add label only here\n\n# Set font size for the color bar\ncbar = heatmap.collections[0].colorbar\ncbar.ax.tick_params(labelsize=16)  # Adjust tick label font size\n#cbar.set_label(\"Color Bar Label\", fontsize=20)  # Adjust color bar label font size\n\n# Set other axis labels and title\nax.set_xlabel(\"Drone Focal\", fontsize=20)\nax.set_ylabel(\"Ground Focal\", fontsize=20)\nax.set_title(\"Agreement Between Ground Focal &amp; Drone Focal Behaviors\", fontsize=20)\n\n# Customize tick labels\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=20)\nplt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=20)\n\nplt.tight_layout()\nplt.show()\n\nfig.savefig(\"../cm-focal-vs-drone.pdf\", dpi=300)\n</pre> fig, ax = plt.subplots(figsize=(12, 10)) heatmap = sns.heatmap(cm,                       annot=False, fmt=\".2f\",                       xticklabels=labels,                       yticklabels=labels,                       cmap='cividis', vmin=0, vmax=1)  # Add label only here  # Set font size for the color bar cbar = heatmap.collections[0].colorbar cbar.ax.tick_params(labelsize=16)  # Adjust tick label font size #cbar.set_label(\"Color Bar Label\", fontsize=20)  # Adjust color bar label font size  # Set other axis labels and title ax.set_xlabel(\"Drone Focal\", fontsize=20) ax.set_ylabel(\"Ground Focal\", fontsize=20) ax.set_title(\"Agreement Between Ground Focal &amp; Drone Focal Behaviors\", fontsize=20)  # Customize tick labels plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=20) plt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=20)  plt.tight_layout() plt.show()  fig.savefig(\"../cm-focal-vs-drone.pdf\", dpi=300) In\u00a0[20]: Copied! <pre># get count of 'Out of Sight' in field and drone\ndf = read_csvs('focalvsdrone')\n \ndef count_oos(df):\n    field = [clean_categories(label) for label in df.get_column(\"field\").to_list()]\n    drone = [clean_categories(label) for label in df.get_column(\"drone\").to_list()]\n    field_oos = field.count(\"Out of Sight\")\n    drone_oos = drone.count(\"Out of Sight\")\n    return field_oos, drone_oos\nfield_oos, drone_oos = count_oos(df)\n\n# print the count of 'Out of Sight' in field and drone\nprint(f\"Field Out of Sight: {field_oos}, Drone Out of Sight: {drone_oos}\")\n\nprint(f\"Field Out of Sight (sec): {field_oos/30}, Drone Out of Sight (sec): {drone_oos/30}\")\n</pre> # get count of 'Out of Sight' in field and drone df = read_csvs('focalvsdrone')   def count_oos(df):     field = [clean_categories(label) for label in df.get_column(\"field\").to_list()]     drone = [clean_categories(label) for label in df.get_column(\"drone\").to_list()]     field_oos = field.count(\"Out of Sight\")     drone_oos = drone.count(\"Out of Sight\")     return field_oos, drone_oos field_oos, drone_oos = count_oos(df)  # print the count of 'Out of Sight' in field and drone print(f\"Field Out of Sight: {field_oos}, Drone Out of Sight: {drone_oos}\")  print(f\"Field Out of Sight (sec): {field_oos/30}, Drone Out of Sight (sec): {drone_oos/30}\") <pre>Field Out of Sight: 23804, Drone Out of Sight: 532\nField Out of Sight (sec): 793.4666666666667, Drone Out of Sight (sec): 17.733333333333334\n</pre> In\u00a0[38]: Copied! <pre>793.4666666666667/1323.457999\n</pre> 793.4666666666667/1323.457999 Out[38]: <pre>0.5995404971417356</pre> In\u00a0[39]: Copied! <pre>17.733333333333334/1323.457999\n</pre> 17.733333333333334/1323.457999 Out[39]: <pre>0.013399241492161124</pre> In\u00a0[23]: Copied! <pre># get total length of each session\ndef get_total_length(df):\n    return df.height\n\ntotal_length = get_total_length(df)\nprint(f\"Total length (frames): {total_length}, Total length (sec): {total_length/30}, Total length (min): {total_length/30/60}\")\n</pre> # get total length of each session def get_total_length(df):     return df.height  total_length = get_total_length(df) print(f\"Total length (frames): {total_length}, Total length (sec): {total_length/30}, Total length (min): {total_length/30/60}\") <pre>Total length (frames): 38166, Total length (sec): 1272.2, Total length (min): 21.203333333333333\n</pre> In\u00a0[25]: Copied! <pre># get max and min timestamp of each session\ndef get_max_min_timestamp(df):\n    max_timestamp = df.get_column(\"time\").max()\n    min_timestamp = df.get_column(\"time\").min()\n    return max_timestamp, min_timestamp\n\nmax_timestamp, min_timestamp = get_max_min_timestamp(df)\nprint(f\"Max timestamp: {max_timestamp}, Min timestamp: {min_timestamp}\")\n</pre> # get max and min timestamp of each session def get_max_min_timestamp(df):     max_timestamp = df.get_column(\"time\").max()     min_timestamp = df.get_column(\"time\").min()     return max_timestamp, min_timestamp  max_timestamp, min_timestamp = get_max_min_timestamp(df) print(f\"Max timestamp: {max_timestamp}, Min timestamp: {min_timestamp}\") <pre>Max timestamp: 1900-01-01 15:07:44.473000, Min timestamp: 1900-01-01 10:40:56.090000\n</pre> In\u00a0[36]: Copied! <pre># list of dfs\ndef list_dfs(root):\n    return [pl.read_csv(os.path.join(root, file)) for file in os.listdir(root)]\ndef get_session_lengths(dfs):\n    lengths = []\n    for df in dfs:\n        length = df.height\n        lengths.append(length)\n    return lengths\n\ndef get_max_min_timestamps(dfs):\n    max_timestamps = []\n    min_timestamps = []\n    for df in dfs:\n        max_timestamp, min_timestamp = get_max_min_timestamp(df)\n        max_timestamps.append(max_timestamp)\n        min_timestamps.append(min_timestamp)\n    return max_timestamps, min_timestamps\n\ndfs = list_dfs('/fs/ess/PAS2136/Kenya-2023/Zebras/methods_paper_analysis/kabr-tools/_hugging_face/methodology_comparison/focalvsdrone/data')\nsession_lengths = get_session_lengths(dfs)\nprint(f\"Session lengths (frames): {session_lengths}\")\nprint(f\"Session lengths (sec): {[length/30 for length in session_lengths]}\")\nmax_timestamps, min_timestamps = get_max_min_timestamps(dfs)\n\n# print the max and min timestamps of each session\nprint(f\"Max timestamps: {max_timestamps}\")\nprint(f\"Min timestamps: {min_timestamps}\")\n\nfrom datetime import datetime\n\ndef get_timestamp_differences(max_timestamps, min_timestamps):\n    # Convert strings to datetime objects\n    max_timestamps = [datetime.fromisoformat(ts) for ts in max_timestamps]\n    min_timestamps = [datetime.fromisoformat(ts) for ts in min_timestamps]\n    # Calculate differences in seconds\n    return [(max_ts - min_ts).total_seconds() for max_ts, min_ts in zip(max_timestamps, min_timestamps)]\n\ntimestamp_differences = get_timestamp_differences(max_timestamps, min_timestamps)\nprint(f\"Timestamp differences (sec): {timestamp_differences}\")\nprint(f\"Timestamp differences (min): {[diff/60 for diff in timestamp_differences]}\")\n</pre> # list of dfs def list_dfs(root):     return [pl.read_csv(os.path.join(root, file)) for file in os.listdir(root)] def get_session_lengths(dfs):     lengths = []     for df in dfs:         length = df.height         lengths.append(length)     return lengths  def get_max_min_timestamps(dfs):     max_timestamps = []     min_timestamps = []     for df in dfs:         max_timestamp, min_timestamp = get_max_min_timestamp(df)         max_timestamps.append(max_timestamp)         min_timestamps.append(min_timestamp)     return max_timestamps, min_timestamps  dfs = list_dfs('/fs/ess/PAS2136/Kenya-2023/Zebras/methods_paper_analysis/kabr-tools/_hugging_face/methodology_comparison/focalvsdrone/data') session_lengths = get_session_lengths(dfs) print(f\"Session lengths (frames): {session_lengths}\") print(f\"Session lengths (sec): {[length/30 for length in session_lengths]}\") max_timestamps, min_timestamps = get_max_min_timestamps(dfs)  # print the max and min timestamps of each session print(f\"Max timestamps: {max_timestamps}\") print(f\"Min timestamps: {min_timestamps}\")  from datetime import datetime  def get_timestamp_differences(max_timestamps, min_timestamps):     # Convert strings to datetime objects     max_timestamps = [datetime.fromisoformat(ts) for ts in max_timestamps]     min_timestamps = [datetime.fromisoformat(ts) for ts in min_timestamps]     # Calculate differences in seconds     return [(max_ts - min_ts).total_seconds() for max_ts, min_ts in zip(max_timestamps, min_timestamps)]  timestamp_differences = get_timestamp_differences(max_timestamps, min_timestamps) print(f\"Timestamp differences (sec): {timestamp_differences}\") print(f\"Timestamp differences (min): {[diff/60 for diff in timestamp_differences]}\")  <pre>Session lengths (frames): [9413, 5819, 12409, 10525]\nSession lengths (sec): [313.76666666666665, 193.96666666666667, 413.6333333333333, 350.8333333333333]\nMax timestamps: ['1900-01-01 12:21:56.938667', '1900-01-01 10:44:10.023333', '1900-01-01 15:05:34.364333', '1900-01-01 15:07:44.473000']\nMin timestamps: ['1900-01-01 12:15:44.297000', '1900-01-01 10:40:56.090000', '1900-01-01 14:58:48.556667', '1900-01-01 15:01:53.397667']\nTimestamp differences (sec): [372.641667, 193.933333, 405.807666, 351.075333]\nTimestamp differences (min): [6.21069445, 3.2322222166666665, 6.7634611, 5.85125555]\n</pre> In\u00a0[34]: Copied! <pre># sum timestamp differences\ntotal_timestamp_difference = sum(timestamp_differences)\nprint(f\"Total timestamp difference (sec): {total_timestamp_difference}\")\n# convert total timestamp difference to minutes\ntotal_timestamp_difference_minutes = total_timestamp_difference / 60\nprint(f\"Total timestamp difference (min): {total_timestamp_difference_minutes}\")\n</pre> # sum timestamp differences total_timestamp_difference = sum(timestamp_differences) print(f\"Total timestamp difference (sec): {total_timestamp_difference}\") # convert total timestamp difference to minutes total_timestamp_difference_minutes = total_timestamp_difference / 60 print(f\"Total timestamp difference (min): {total_timestamp_difference_minutes}\") <pre>Total timestamp difference (sec): 1323.457999\nTotal timestamp difference (min): 22.057633316666667\n</pre> In\u00a0[35]: Copied! <pre># average session time\naverage_session_time = total_timestamp_difference / len(dfs)\nprint(f\"Average session time (sec): {average_session_time}\")\n\n# average session std deviation\naverage_session_std = np.std(timestamp_differences)\nprint(f\"Average session std deviation (sec): {average_session_std}\")\n</pre> # average session time average_session_time = total_timestamp_difference / len(dfs) print(f\"Average session time (sec): {average_session_time}\")  # average session std deviation average_session_std = np.std(timestamp_differences) print(f\"Average session std deviation (sec): {average_session_std}\") <pre>Average session time (sec): 330.86449975\nAverage session std deviation (sec): 81.42547525066283\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"methodology_comparison/focalvsdrone/analysis/cm-focal-vs-drone/#comparison-of-data-collected-from-focal-sampling-vs-drone-video-analysis","title":"Comparison of data collected from focal sampling vs drone video analysis\u00b6","text":""},{"location":"methodology_comparison/focalvsdrone/analysis/gantt_chart/","title":"Gantt Charts","text":"In\u00a0[2]: Copied! <pre>import os\nimport pandas as pd \nimport numpy as np\nfrom datetime import datetime, timedelta\nimport pysrt\nimport json\nfrom pathlib import Path\nimport more_itertools as mit\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n</pre> import os import pandas as pd  import numpy as np from datetime import datetime, timedelta import pysrt import json from pathlib import Path import more_itertools as mit import matplotlib.pyplot as plt import seaborn as sns In\u00a0[3]: Copied! <pre># get the start and end times for each behavior duration\n\ndef get_start_end_times(df):\n    times = []\n    for i in range(len(df)):\n        if i == 0:\n            start_behavior = df.iloc[i]['behavior']\n            start_times = df.iloc[i]['time']\n            times.append([start_behavior, start_times, 0])\n        elif df.iloc[i]['behavior'] != df.iloc[i-1]['behavior']:\n            end_behavior = df.iloc[i-1]['behavior']\n            end_times = df.iloc[i-1]['time']\n            times[-1][2] = end_times # update end time of previous behavior\n            \n            behavior = df.iloc[i]['behavior'] # start new behavior\n            start_times = df.iloc[i]['time'] # start new behavior\n            times.append([behavior, start_times, 0]) \n        # handle last behavior\n        if i == len(df)-1:\n            end_behavior = df.iloc[i]['behavior']\n            end_times = df.iloc[i]['time']\n            times[-1][2] = end_times\n    return times \n\ndef calculate_duration(df):\n    df['duration'] = df['end'] - df['start']\n    # convert to seconds\n    df['duration'] = df['duration'].dt.total_seconds()\n    \n    df['rel_start'] = df['start'] - df['start'].iloc[0]\n    df['rel_start'] = df['rel_start'].dt.total_seconds()\n    return df\n</pre> # get the start and end times for each behavior duration  def get_start_end_times(df):     times = []     for i in range(len(df)):         if i == 0:             start_behavior = df.iloc[i]['behavior']             start_times = df.iloc[i]['time']             times.append([start_behavior, start_times, 0])         elif df.iloc[i]['behavior'] != df.iloc[i-1]['behavior']:             end_behavior = df.iloc[i-1]['behavior']             end_times = df.iloc[i-1]['time']             times[-1][2] = end_times # update end time of previous behavior                          behavior = df.iloc[i]['behavior'] # start new behavior             start_times = df.iloc[i]['time'] # start new behavior             times.append([behavior, start_times, 0])          # handle last behavior         if i == len(df)-1:             end_behavior = df.iloc[i]['behavior']             end_times = df.iloc[i]['time']             times[-1][2] = end_times     return times   def calculate_duration(df):     df['duration'] = df['end'] - df['start']     # convert to seconds     df['duration'] = df['duration'].dt.total_seconds()          df['rel_start'] = df['start'] - df['start'].iloc[0]     df['rel_start'] = df['rel_start'].dt.total_seconds()     return df In\u00a0[4]: Copied! <pre>def clean_categories(name):\n    lowercased = name.lower()\n    if \"head up\" in lowercased:\n        return \"Head Up\"\n    elif \"walk\" in lowercased:\n        return \"Walk\"\n    elif \"out of focus\" in lowercased:\n        return \"Out of Sight\"\n    elif \"fighting\" in lowercased:\n        return \"Fight\"\n    elif \"trot/run\" in lowercased:\n        return \"Trot/Run\"\n    elif \"out of sight\" in lowercased:\n        return \"Out of Sight\"\n    elif \"no data\" in lowercased:\n        return \"Out of Sight\"\n    elif \"out of frame\" in lowercased:\n        return \"Out of Sight\"\n    elif \"occluded\" in lowercased:\n        return \"Out of Sight\"\n    elif \"no data\" in lowercased:\n        return \"Out of Sight\"\n    # Replace sniff with graze\n    elif \"sniff\" in lowercased:\n        return \"Graze\"\n    else:\n        return name\n</pre> def clean_categories(name):     lowercased = name.lower()     if \"head up\" in lowercased:         return \"Head Up\"     elif \"walk\" in lowercased:         return \"Walk\"     elif \"out of focus\" in lowercased:         return \"Out of Sight\"     elif \"fighting\" in lowercased:         return \"Fight\"     elif \"trot/run\" in lowercased:         return \"Trot/Run\"     elif \"out of sight\" in lowercased:         return \"Out of Sight\"     elif \"no data\" in lowercased:         return \"Out of Sight\"     elif \"out of frame\" in lowercased:         return \"Out of Sight\"     elif \"occluded\" in lowercased:         return \"Out of Sight\"     elif \"no data\" in lowercased:         return \"Out of Sight\"     # Replace sniff with graze     elif \"sniff\" in lowercased:         return \"Graze\"     else:         return name In\u00a0[5]: Copied! <pre># data source\ndata_dir = Path('focalvsdrone')\n\nfor file in data_dir.glob('*.csv'):\n    focal_drone_dfs = pd.read_csv(file)\n    \n    print(f'Processing file: {file.name}')\n    \n    # Clean the behavior categories before processing\n    focal_drone_dfs['behavior'] = focal_drone_dfs['behavior'].apply(clean_categories)\n    focal_drone_dfs['focal_behavior'] = focal_drone_dfs['focal_behavior'].apply(clean_categories)\n    \n    drone = focal_drone_dfs[['behavior', 'time']]\n    focal = focal_drone_dfs[['focal_behavior', 'time']]\n    # rename focal behavior to behavior\n    focal = focal.rename(columns={'focal_behavior':'behavior'})\n    \n    # create dict of behaviors in focal and drone\n    behaviors = focal['behavior'].unique()\n    behaviors = {b: i for i,b in enumerate(behaviors)}\n    behaviors.update({b: i for i,b in enumerate(drone['behavior'].unique())})\n    \n    # get the start and end times for each behavior duration\n    times = pd.DataFrame(columns=['behavior','start', 'end'])\n    focal_times = get_start_end_times(focal)\n    drone_times = get_start_end_times(drone)\n    \n    # convert to dataframe\n    focal = pd.DataFrame(focal_times, columns=['behavior','start', 'end'])\n    drone = pd.DataFrame(drone_times, columns=['behavior','start', 'end'])\n    \n    # convert to datetime\n    focal['start'] = pd.to_datetime(focal['start'])\n    focal['end'] = pd.to_datetime(focal['end'])\n    drone['start'] = pd.to_datetime(drone['start'])\n    drone['end'] = pd.to_datetime(drone['end'])\n    \n    focal = calculate_duration(focal)\n    drone = calculate_duration(drone)\n    \n    # Define your ethogram in order of occurance\n    # ethogram = ['Out of Sight','Walk', 'Run', 'Mutual Grooming', 'Head Up', 'Graze', 'Fight', 'Drink', 'Defecating', 'Auto-Groom']\n    ethogram = ['Out of Sight', 'Fight','Urinate','Mutual-Groom','Defecate','Auto-Groom','Browse','Trot/Run','Head Up','Walk','Graze']\n    \n    # custom_colors = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#d62728','#2ca02c','#8c564b','#e377c2','#7f7f7f','#17becf']\n    # color_map = {behavior: custom_colors[i] for i, behavior in enumerate(ethogram)}\n    \n    colors = sns.color_palette(\"tab20\", len(ethogram))\n    color_map = {behavior: colors[i] for i, behavior in enumerate(ethogram)}\n\n\n    # plot the gantt chart\n    fig, (ax1, ax2) = plt.subplots(2,1, figsize = (12,4))\n\n    # Set the same y-axis labels for both plots using the ethogram\n    ax1.set_yticks(range(len(ethogram)))\n    ax1.set_yticklabels(ethogram)\n    ax2.set_yticks(range(len(ethogram)))\n    ax2.set_yticklabels(ethogram)\n\n    # Map behaviors to y-positions based on ethogram\n    behavior_positions = {behavior: i for i, behavior in enumerate(ethogram)}\n    \n    # Get the total time range for background bars\n    all_times = []\n    if not focal.empty:\n        all_times.extend([focal['rel_start'].min(), focal['rel_start'].max() + focal['duration'].max()])\n    if not drone.empty:\n        all_times.extend([drone['rel_start'].min(), drone['rel_start'].max() + drone['duration'].max()])\n    \n    if all_times:\n        total_duration = max(all_times) - min(all_times)\n        start_time = min(all_times)\n    else:\n        total_duration = 0\n        start_time = 0\n\n    # Add background bars for all behaviors to show the full ethogram\n    for i, behavior in enumerate(ethogram):\n        # Light gray background bars\n        ax1.barh(y=i, width=total_duration, left=start_time, \n                color='lightgray', alpha=0.2, zorder=0)\n        ax2.barh(y=i, width=total_duration, left=start_time, \n                color='lightgray', alpha=0.2, zorder=0)\n\n    # Get behaviors that were actually observed\n    focal_behaviors = set(focal['behavior'].unique()) if not focal.empty else set()\n    drone_behaviors = set(drone['behavior'].unique()) if not drone.empty else set()\n\n    # Plot focal data\n    for _, row in focal.iterrows():\n        if row['behavior'] in behavior_positions:  # Only plot if behavior is in ethogram\n            y_pos = behavior_positions[row['behavior']]\n            ax1.barh(y=y_pos, width=row['duration'], left=row['rel_start'], \n                    color=color_map[row['behavior']], alpha=0.8, zorder=2)\n\n    # Plot drone data  \n    for _, row in drone.iterrows():\n        if row['behavior'] in behavior_positions:  # Only plot if behavior is in ethogram\n            y_pos = behavior_positions[row['behavior']]\n            ax2.barh(y=y_pos, width=row['duration'], left=row['rel_start'], \n                    color=color_map[row['behavior']], alpha=0.8, zorder=2)\n\n    # Add subtle grid lines for better readability\n    ax1.grid(True, axis='x', alpha=0.3, linestyle='-', linewidth=0.5)\n    ax2.grid(True, axis='x', alpha=0.3, linestyle='-', linewidth=0.5)\n    \n    # Set x-axis limits to match the data range\n    max_time_focal = (focal['rel_start'] + focal['duration']).max() if len(focal) &gt; 0 else 0\n    max_time_drone = (drone['rel_start'] + drone['duration']).max() if len(drone) &gt; 0 else 0\n    max_time = max(max_time_focal, max_time_drone)\n    print(f\"Max time for {file.name}: {max_time} seconds\")\n    \n    ax1.set_xlim(0, max_time)\n    ax2.set_xlim(0, max_time)\n    \n    # Set y-axis limits to show a bit of padding\n    ax1.set_ylim(-0.5, len(ethogram) - 0.5)\n    ax2.set_ylim(-0.5, len(ethogram) - 0.5)\n    \n    ax1.set(title='Field Focal Data', ylabel='Behavior')\n    ax2.set(title='Drone Focal Data', xlabel='Time (seconds)', ylabel='Behavior')\n    plt.tight_layout()\n    \n    # Save the plot\n    output_file = file.with_suffix('.png')\n    plt.savefig(output_file, dpi=300)\n    plt.close(fig)\n</pre> # data source data_dir = Path('focalvsdrone')  for file in data_dir.glob('*.csv'):     focal_drone_dfs = pd.read_csv(file)          print(f'Processing file: {file.name}')          # Clean the behavior categories before processing     focal_drone_dfs['behavior'] = focal_drone_dfs['behavior'].apply(clean_categories)     focal_drone_dfs['focal_behavior'] = focal_drone_dfs['focal_behavior'].apply(clean_categories)          drone = focal_drone_dfs[['behavior', 'time']]     focal = focal_drone_dfs[['focal_behavior', 'time']]     # rename focal behavior to behavior     focal = focal.rename(columns={'focal_behavior':'behavior'})          # create dict of behaviors in focal and drone     behaviors = focal['behavior'].unique()     behaviors = {b: i for i,b in enumerate(behaviors)}     behaviors.update({b: i for i,b in enumerate(drone['behavior'].unique())})          # get the start and end times for each behavior duration     times = pd.DataFrame(columns=['behavior','start', 'end'])     focal_times = get_start_end_times(focal)     drone_times = get_start_end_times(drone)          # convert to dataframe     focal = pd.DataFrame(focal_times, columns=['behavior','start', 'end'])     drone = pd.DataFrame(drone_times, columns=['behavior','start', 'end'])          # convert to datetime     focal['start'] = pd.to_datetime(focal['start'])     focal['end'] = pd.to_datetime(focal['end'])     drone['start'] = pd.to_datetime(drone['start'])     drone['end'] = pd.to_datetime(drone['end'])          focal = calculate_duration(focal)     drone = calculate_duration(drone)          # Define your ethogram in order of occurance     # ethogram = ['Out of Sight','Walk', 'Run', 'Mutual Grooming', 'Head Up', 'Graze', 'Fight', 'Drink', 'Defecating', 'Auto-Groom']     ethogram = ['Out of Sight', 'Fight','Urinate','Mutual-Groom','Defecate','Auto-Groom','Browse','Trot/Run','Head Up','Walk','Graze']          # custom_colors = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#d62728','#2ca02c','#8c564b','#e377c2','#7f7f7f','#17becf']     # color_map = {behavior: custom_colors[i] for i, behavior in enumerate(ethogram)}          colors = sns.color_palette(\"tab20\", len(ethogram))     color_map = {behavior: colors[i] for i, behavior in enumerate(ethogram)}       # plot the gantt chart     fig, (ax1, ax2) = plt.subplots(2,1, figsize = (12,4))      # Set the same y-axis labels for both plots using the ethogram     ax1.set_yticks(range(len(ethogram)))     ax1.set_yticklabels(ethogram)     ax2.set_yticks(range(len(ethogram)))     ax2.set_yticklabels(ethogram)      # Map behaviors to y-positions based on ethogram     behavior_positions = {behavior: i for i, behavior in enumerate(ethogram)}          # Get the total time range for background bars     all_times = []     if not focal.empty:         all_times.extend([focal['rel_start'].min(), focal['rel_start'].max() + focal['duration'].max()])     if not drone.empty:         all_times.extend([drone['rel_start'].min(), drone['rel_start'].max() + drone['duration'].max()])          if all_times:         total_duration = max(all_times) - min(all_times)         start_time = min(all_times)     else:         total_duration = 0         start_time = 0      # Add background bars for all behaviors to show the full ethogram     for i, behavior in enumerate(ethogram):         # Light gray background bars         ax1.barh(y=i, width=total_duration, left=start_time,                  color='lightgray', alpha=0.2, zorder=0)         ax2.barh(y=i, width=total_duration, left=start_time,                  color='lightgray', alpha=0.2, zorder=0)      # Get behaviors that were actually observed     focal_behaviors = set(focal['behavior'].unique()) if not focal.empty else set()     drone_behaviors = set(drone['behavior'].unique()) if not drone.empty else set()      # Plot focal data     for _, row in focal.iterrows():         if row['behavior'] in behavior_positions:  # Only plot if behavior is in ethogram             y_pos = behavior_positions[row['behavior']]             ax1.barh(y=y_pos, width=row['duration'], left=row['rel_start'],                      color=color_map[row['behavior']], alpha=0.8, zorder=2)      # Plot drone data       for _, row in drone.iterrows():         if row['behavior'] in behavior_positions:  # Only plot if behavior is in ethogram             y_pos = behavior_positions[row['behavior']]             ax2.barh(y=y_pos, width=row['duration'], left=row['rel_start'],                      color=color_map[row['behavior']], alpha=0.8, zorder=2)      # Add subtle grid lines for better readability     ax1.grid(True, axis='x', alpha=0.3, linestyle='-', linewidth=0.5)     ax2.grid(True, axis='x', alpha=0.3, linestyle='-', linewidth=0.5)          # Set x-axis limits to match the data range     max_time_focal = (focal['rel_start'] + focal['duration']).max() if len(focal) &gt; 0 else 0     max_time_drone = (drone['rel_start'] + drone['duration']).max() if len(drone) &gt; 0 else 0     max_time = max(max_time_focal, max_time_drone)     print(f\"Max time for {file.name}: {max_time} seconds\")          ax1.set_xlim(0, max_time)     ax2.set_xlim(0, max_time)          # Set y-axis limits to show a bit of padding     ax1.set_ylim(-0.5, len(ethogram) - 0.5)     ax2.set_ylim(-0.5, len(ethogram) - 0.5)          ax1.set(title='Field Focal Data', ylabel='Behavior')     ax2.set(title='Drone Focal Data', xlabel='Time (seconds)', ylabel='Behavior')     plt.tight_layout()          # Save the plot     output_file = file.with_suffix('.png')     plt.savefig(output_file, dpi=300)     plt.close(fig) <pre>Processing file: focal_drone_df_12_01_23_female_grevy.csv\nMax time for focal_drone_df_12_01_23_female_grevy.csv: 372.641667 seconds\nProcessing file: focal_drone_df_17_01_23_scar_cleaned.csv\nMax time for focal_drone_df_17_01_23_scar_cleaned.csv: 193.933333 seconds\nProcessing file: focal_drone_df_16_01_23_white_female.csv\nMax time for focal_drone_df_16_01_23_white_female.csv: 405.80766600000004 seconds\nProcessing file: focal_drone_df_16_01_23_thick_neck_stripes.csv\nMax time for focal_drone_df_16_01_23_thick_neck_stripes.csv: 351.075333 seconds\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"methodology_comparison/focalvsdrone/analysis/gantt_chart/#generate-gantt-charts-showing-behavior-gathered-from-focal-sampling-vs-drones","title":"Generate Gantt Charts showing behavior gathered from focal sampling vs drones\u00b6","text":""},{"location":"methodology_comparison/kabr_dataset/data_analysis/","title":"KABR Dataset Analysis","text":"<p>See the KABR mini-scene dataset in HF here: https://huggingface.co/datasets/imageomics/KABR</p> <p>Refer to our previous papers for details of the mini-scene dataset:</p> <ul> <li>KABR: In-Situ Dataset for Kenyan Animal Behavior Recognition from Drone Videos</li> <li>Deep dive into KABR: a dataset for understanding ungulate behavior from in-situ drone video</li> </ul> In\u00a0[23]: Copied! <pre># import libraries\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n</pre> # import libraries import pandas as pd import warnings warnings.filterwarnings('ignore') In\u00a0[24]: Copied! <pre># import metadata on drone sessions used to create mini-scenes\ndata = pd.read_csv('data/miniscene_sessions_summary.csv')\n</pre> # import metadata on drone sessions used to create mini-scenes data = pd.read_csv('data/miniscene_sessions_summary.csv') In\u00a0[25]: Copied! <pre># get number of sessions\nnum_sessions = data['Session '].nunique()\nprint(f'Number of sessions: {num_sessions}')\n</pre> # get number of sessions num_sessions = data['Session '].nunique() print(f'Number of sessions: {num_sessions}') <pre>Number of sessions: 16\n</pre> In\u00a0[26]: Copied! <pre># calculate duration of each session and get the min, max, and avg\ndata['Duration'] = pd.to_timedelta(data['End Time']) - pd.to_timedelta(data['Start Time'])\nmin_duration = data['Duration'].min()\nmax_duration = data['Duration'].max()\navg_duration = data['Duration'].mean()\n\nprint(f'Minimum session duration: {min_duration}')\nprint(f'Maximum session duration: {max_duration}')\nprint(f'Average session duration: {avg_duration}')\n</pre> # calculate duration of each session and get the min, max, and avg data['Duration'] = pd.to_timedelta(data['End Time']) - pd.to_timedelta(data['Start Time']) min_duration = data['Duration'].min() max_duration = data['Duration'].max() avg_duration = data['Duration'].mean()  print(f'Minimum session duration: {min_duration}') print(f'Maximum session duration: {max_duration}') print(f'Average session duration: {avg_duration}') <pre>Minimum session duration: 0 days 00:05:00\nMaximum session duration: 0 days 00:52:14\nAverage session duration: 0 days 00:24:16.375000\n</pre> In\u00a0[27]: Copied! <pre># get avg, min, and max herd size\navg_herd_size = data['Herd Size'].mean()\nmin_herd_size = data['Herd Size'].min()\nmax_herd_size = data['Herd Size'].max()\nprint(f'Average herd size: {avg_herd_size}')\nprint(f'Minimum herd size: {min_herd_size}')\nprint(f'Maximum herd size: {max_herd_size}')\n</pre> # get avg, min, and max herd size avg_herd_size = data['Herd Size'].mean() min_herd_size = data['Herd Size'].min() max_herd_size = data['Herd Size'].max() print(f'Average herd size: {avg_herd_size}') print(f'Minimum herd size: {min_herd_size}') print(f'Maximum herd size: {max_herd_size}') <pre>Average herd size: 6.0625\nMinimum herd size: 2.0\nMaximum herd size: 16.0\n</pre> In\u00a0[28]: Copied! <pre># import data\ndf = pd.read_csv('data/consolidated_metadata.csv')\n</pre> # import data df = pd.read_csv('data/consolidated_metadata.csv') In\u00a0[29]: Copied! <pre># find the number of mini-scenes\n# count the number of unique id and video combinations\n\ndf['mini-scene-id'] = df['video'] + '_' + df['id'].astype(str)\n# count unique mini-scene ids\nmini_scene_count = df['mini-scene-id'].nunique()\nprint(f'The number of unique mini-scenes in the dataset is: {mini_scene_count}')\n</pre> # find the number of mini-scenes # count the number of unique id and video combinations  df['mini-scene-id'] = df['video'] + '_' + df['id'].astype(str) # count unique mini-scene ids mini_scene_count = df['mini-scene-id'].nunique() print(f'The number of unique mini-scenes in the dataset is: {mini_scene_count}') <pre>The number of unique mini-scenes in the dataset is: 807\n</pre> In\u00a0[30]: Copied! <pre># create video id and date columns from video\ndf['video_id'] = df['video'].str.split('-').str[1]\n\n# extract date from video name\ndf['date'] = df['video'].str.split('-').str[0]\n# keep only the first 8 characters of the date\ndf['date'] = df['date'].str[:8]\n</pre> # create video id and date columns from video df['video_id'] = df['video'].str.split('-').str[1]  # extract date from video name df['date'] = df['video'].str.split('-').str[0] # keep only the first 8 characters of the date df['date'] = df['date'].str[:8] In\u00a0[31]: Copied! <pre># calculate number of mini-scenes per date\n# Extract day from the video name\ndf['day'] = df[\"date\"].str.extract(r\"(\\d{2})\") \n\n# Calculate the number of mini-scenes per date\nmini_scenes_per_day = df.groupby('day')['mini-scene-id'].nunique()\n\nprint(\"Number of mini-scenes per date:\")\nprint(mini_scenes_per_day)\n\n# calculate number of mini-scenes per video\nmini_scenes_per_video = df.groupby('video')['mini-scene-id'].nunique()\n# print(\"Number of mini-scenes per video:\")\n# print(mini_scenes_per_video)\n</pre> # calculate number of mini-scenes per date # Extract day from the video name df['day'] = df[\"date\"].str.extract(r\"(\\d{2})\")   # Calculate the number of mini-scenes per date mini_scenes_per_day = df.groupby('day')['mini-scene-id'].nunique()  print(\"Number of mini-scenes per date:\") print(mini_scenes_per_day)  # calculate number of mini-scenes per video mini_scenes_per_video = df.groupby('video')['mini-scene-id'].nunique() # print(\"Number of mini-scenes per video:\") # print(mini_scenes_per_video) <pre>Number of mini-scenes per date:\nday\n11     62\n12    146\n13    438\n16    112\n17     49\nName: mini-scene-id, dtype: int64\n</pre> In\u00a0[32]: Copied! <pre># import dataset of mini-scenes with species labels\nspecies_df = pd.read_csv('data/miniscene_sessions_summary.csv')\n</pre> # import dataset of mini-scenes with species labels species_df = pd.read_csv('data/miniscene_sessions_summary.csv')  In\u00a0[33]: Copied! <pre># from data file, create summary of data, video, and species\ndata_species = species_df[['Date ', 'Species','Video File Names']].drop_duplicates()\n\n# create lookup joining date with video file names, e.g. '12_01_23-DJI_0994'\n# new row for each data, video file name, and species\ndata_species['video_id'] = data_species['Video File Names'].str.split(',')\n# explode the Video File Names column to have one row per video file name\ndata_species = data_species.explode('video_id')\n\ndata_species['day'] = data_species['Date '].str.extract(r'(\\d{2})')  # Extract day from the date\n\ndata_species = data_species[['day', 'video_id', 'Species']]\n\n# strip whitespace from video_id\ndata_species['video_id'] = data_species['video_id'].str.strip()\n\ndata_species['day_video'] = data_species['day'] + '-' + data_species['video_id']\n\ndata_species.head()\n</pre> # from data file, create summary of data, video, and species data_species = species_df[['Date ', 'Species','Video File Names']].drop_duplicates()  # create lookup joining date with video file names, e.g. '12_01_23-DJI_0994' # new row for each data, video file name, and species data_species['video_id'] = data_species['Video File Names'].str.split(',') # explode the Video File Names column to have one row per video file name data_species = data_species.explode('video_id')  data_species['day'] = data_species['Date '].str.extract(r'(\\d{2})')  # Extract day from the date  data_species = data_species[['day', 'video_id', 'Species']]  # strip whitespace from video_id data_species['video_id'] = data_species['video_id'].str.strip()  data_species['day_video'] = data_species['day'] + '-' + data_species['video_id']  data_species.head() Out[33]: day video_id Species day_video 0 11 DJI_0977 Grevy's 11-DJI_0977 0 11 DJI_0978 Grevy's 11-DJI_0978 0 11 DJI_0979 Grevy's 11-DJI_0979 0 11 DJI_0980 Grevy's 11-DJI_0980 1 12 DJI_0987 Plains 12-DJI_0987 In\u00a0[34]: Copied! <pre>df_counts = mini_scenes_per_video.rename(\"mini_scene_count\").reset_index()\ndf_counts.columns = ['video', 'mini_scene_count']\n\n# Extract date from 'video' column in df_counts\ndf_counts['day'] =df_counts['video'].str.extract(r'(\\d{2})_')  # just day part\ndf_counts['video_id'] = df_counts['video'].str.extract(r'(DJI_\\d{4})')\n# strip whitespace from video_id\ndf_counts['video_id'] = df_counts['video_id'].str.strip()\ndf_counts['day_video'] = df_counts['day'] + '-' + df_counts['video_id']\n\ndf_counts = df_counts[['day_video', 'mini_scene_count']]\n\ndf_merged = df_counts.merge(data_species, on=['day_video'], how='left')\n\nmini_scenes_per_species = df_merged.groupby('Species')['mini_scene_count'].sum().reset_index()\n\nprint(mini_scenes_per_species)\n\nsum(mini_scenes_per_species['mini_scene_count'])  # Total mini-scenes across all species\n</pre> df_counts = mini_scenes_per_video.rename(\"mini_scene_count\").reset_index() df_counts.columns = ['video', 'mini_scene_count']  # Extract date from 'video' column in df_counts df_counts['day'] =df_counts['video'].str.extract(r'(\\d{2})_')  # just day part df_counts['video_id'] = df_counts['video'].str.extract(r'(DJI_\\d{4})') # strip whitespace from video_id df_counts['video_id'] = df_counts['video_id'].str.strip() df_counts['day_video'] = df_counts['day'] + '-' + df_counts['video_id']  df_counts = df_counts[['day_video', 'mini_scene_count']]  df_merged = df_counts.merge(data_species, on=['day_video'], how='left')  mini_scenes_per_species = df_merged.groupby('Species')['mini_scene_count'].sum().reset_index()  print(mini_scenes_per_species)  sum(mini_scenes_per_species['mini_scene_count'])  # Total mini-scenes across all species   <pre>     Species  mini_scene_count\n0   Giraffes                40\n1  Giraffes                 22\n2   Grevy's                174\n3      Mixed               198\n4     Plains               307\n5    Plains                 66\n</pre> Out[34]: <pre>807</pre> In\u00a0[35]: Copied! <pre>df['behaviour'].value_counts()\n</pre> df['behaviour'].value_counts() Out[35]: <pre>behaviour\nGraze              382268\nWalk               320872\nHead Up            252316\nOut of Focus        62549\nWalking             44893\nOut of Frame        18813\nOccluded            18701\nRunning             18674\nBrowsing            14721\nTrotting            13479\nAuto-Groom           5866\nDefecating           2172\nSniff                 580\nMutual Grooming       413\nUrinating             335\nFighting               29\nName: count, dtype: int64</pre> In\u00a0[36]: Copied! <pre># drop rows with behavior out of focus, out of frame, or occluded\ndf = df[df['behaviour'] != 'Out of Focus']\ndf = df[df['behaviour'] != 'Out of Frame']\ndf = df[df['behaviour'] != 'Occluded']\n\ndf['behaviour'].value_counts()\n</pre> # drop rows with behavior out of focus, out of frame, or occluded df = df[df['behaviour'] != 'Out of Focus'] df = df[df['behaviour'] != 'Out of Frame'] df = df[df['behaviour'] != 'Occluded']  df['behaviour'].value_counts() Out[36]: <pre>behaviour\nGraze              382268\nWalk               320872\nHead Up            252316\nWalking             44893\nRunning             18674\nBrowsing            14721\nTrotting            13479\nAuto-Groom           5866\nDefecating           2172\nSniff                 580\nMutual Grooming       413\nUrinating             335\nFighting               29\nName: count, dtype: int64</pre> In\u00a0[37]: Copied! <pre># rename for clarity\ndf['behaviour'] = df['behaviour'].replace('Walk', 'Walking')\ndf['behaviour'] = df['behaviour'].replace('Walking', 'Walk')\ndf['behaviour'] = df['behaviour'].replace('Running', 'Run')\ndf['behaviour'] = df['behaviour'].replace('Trotting', 'Trot')\ndf['behaviour'] = df['behaviour'].replace('Defecating', 'Defecate')\ndf['behaviour'] = df['behaviour'].replace('Urinating', 'Urinate')\ndf['behaviour'] = df['behaviour'].replace('Mutual Grooming', 'Mutual-Groom')\ndf['behaviour'] = df['behaviour'].replace('Fighting', 'Fight')\ndf['behaviour'] = df['behaviour'].replace('Browsing', 'Browse')\n</pre> # rename for clarity df['behaviour'] = df['behaviour'].replace('Walk', 'Walking') df['behaviour'] = df['behaviour'].replace('Walking', 'Walk') df['behaviour'] = df['behaviour'].replace('Running', 'Run') df['behaviour'] = df['behaviour'].replace('Trotting', 'Trot') df['behaviour'] = df['behaviour'].replace('Defecating', 'Defecate') df['behaviour'] = df['behaviour'].replace('Urinating', 'Urinate') df['behaviour'] = df['behaviour'].replace('Mutual Grooming', 'Mutual-Groom') df['behaviour'] = df['behaviour'].replace('Fighting', 'Fight') df['behaviour'] = df['behaviour'].replace('Browsing', 'Browse') In\u00a0[38]: Copied! <pre>df['behaviour'].unique()\n</pre> df['behaviour'].unique() Out[38]: <pre>array(['Walk', 'Head Up', 'Graze', 'Auto-Groom', 'Defecate', 'Trot',\n       'Run', 'Browse', 'Sniff', 'Mutual-Groom', 'Urinate', 'Fight'],\n      dtype=object)</pre> In\u00a0[44]: Copied! <pre># plot distribution of behaviors\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set_theme(style=\"darkgrid\")\n\n# Set figure size BEFORE creating the plot\nplt.figure(figsize=(7, 6))\n\n# Get the order of behaviors by count\nbehavior_order = df['behaviour'].value_counts().index\n\n# Create color palette: different colors for head (first 3) vs tail (remainder)\nn_behaviors = len(behavior_order)\ncolors = ['#2E86AB'] * 3 + ['#A23B72'] * (n_behaviors - 3)  # Blue for head, purple for tail\n# Alternative color scheme:\n# colors = ['steelblue'] * 3 + ['lightcoral'] * (n_behaviors - 3)\n\n# Create the plot with custom colors\nax = sns.countplot(x=\"behaviour\", data=df, order=behavior_order, palette=colors)\n\nfor i, bar in enumerate(ax.patches):\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n            f'{int(height)}', ha='center', va='bottom', fontsize=10)\n\n# add labels\nplt.xlabel('Behavior Label')\nplt.ylabel('Count of Behaviors (Video Frames)')\n\n# add title\nplt.title('Distribution of Behaviors in KABR Dataset (Head vs Tail)')\n\n# rotate x-axis labels\nplt.xticks(rotation=45)\n\n# Add legend to distinguish head vs tail\nfrom matplotlib.patches import Patch\nlegend_elements = [Patch(facecolor='#2E86AB', label='Head (Top 3)'),\n                   Patch(facecolor='#A23B72', label='Tail (Remaining)')]\nax.legend(handles=legend_elements, loc='upper right')\n\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=12)\n\nplt.tight_layout()  # Helps with label spacing\nplt.show()\n</pre> # plot distribution of behaviors import seaborn as sns import matplotlib.pyplot as plt  sns.set_theme(style=\"darkgrid\")  # Set figure size BEFORE creating the plot plt.figure(figsize=(7, 6))  # Get the order of behaviors by count behavior_order = df['behaviour'].value_counts().index  # Create color palette: different colors for head (first 3) vs tail (remainder) n_behaviors = len(behavior_order) colors = ['#2E86AB'] * 3 + ['#A23B72'] * (n_behaviors - 3)  # Blue for head, purple for tail # Alternative color scheme: # colors = ['steelblue'] * 3 + ['lightcoral'] * (n_behaviors - 3)  # Create the plot with custom colors ax = sns.countplot(x=\"behaviour\", data=df, order=behavior_order, palette=colors)  for i, bar in enumerate(ax.patches):     height = bar.get_height()     ax.text(bar.get_x() + bar.get_width()/2., height + height*0.01,             f'{int(height)}', ha='center', va='bottom', fontsize=10)  # add labels plt.xlabel('Behavior Label') plt.ylabel('Count of Behaviors (Video Frames)')  # add title plt.title('Distribution of Behaviors in KABR Dataset (Head vs Tail)')  # rotate x-axis labels plt.xticks(rotation=45)  # Add legend to distinguish head vs tail from matplotlib.patches import Patch legend_elements = [Patch(facecolor='#2E86AB', label='Head (Top 3)'),                    Patch(facecolor='#A23B72', label='Tail (Remaining)')] ax.legend(handles=legend_elements, loc='upper right')  plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=12)  plt.tight_layout()  # Helps with label spacing plt.show() In\u00a0[97]: Copied! <pre># find the number of mini-scenes\n# count the number of unique id and video combinations\n\n# create \ndf['mini-scene-id'] = df['video'] + '_' + df['id'].astype(str)\n# count unique mini-scene ids\nmini_scene_count = df['mini-scene-id'].nunique()\nprint(f'The number of unique mini-scenes in the dataset is: {mini_scene_count}')\n\n# print the unique videos\nunique_videos = df['video'].unique()\nprint(f'The number of unique videos in the dataset is: {len(unique_videos)}')\nprint(f'Unique videos: {unique_videos}')\n</pre> # find the number of mini-scenes # count the number of unique id and video combinations  # create  df['mini-scene-id'] = df['video'] + '_' + df['id'].astype(str) # count unique mini-scene ids mini_scene_count = df['mini-scene-id'].nunique() print(f'The number of unique mini-scenes in the dataset is: {mini_scene_count}')  # print the unique videos unique_videos = df['video'].unique() print(f'The number of unique videos in the dataset is: {len(unique_videos)}') print(f'Unique videos: {unique_videos}') <pre>The number of unique mini-scenes in the dataset is: 801\nThe number of unique videos in the dataset is: 58\nUnique videos: ['12_01_23-DJI_0994' '16_01_23_session_2-DJI_0002' '13_01_23-DJI_0037'\n '11_01_23-DJI_0979' '13_01_23-DJI_0020' '13_01_23-DJI_0019'\n '17_01_2023_session_2-DJI_0013' '13_01_23-DJI_0039' '12_01_23-DJI_0001'\n '12_01_23-DJI_0006' '13_01_23-DJI_0041' '13_01_23-DJI_0024'\n '13_01_23-DJI_0015' '13_01_23-DJI_0031' '12_01_23-DJI_0003'\n '12_01_23-DJI_0008' '16_01_23_session_2-DJI_0003' '13_01_23-DJI_0032'\n '13_01_23-DJI_0013' '16_01_23_session_1-DJI_0001' '13_01_23-DJI_0009'\n '12_01_23-DJI_0997' '12_01_23-DJI_0989' '17_01_2023_session_2-DJI_0008'\n '11_01_23-DJI_0978' '13_01_23-DJI_0021' '13_01_23-DJI_0036'\n '17_01_2023_session_2-DJI_0010' '17_01_2023_session_1-DJI_0006'\n '16_01_23_session_1-DJI_0004' '13_01_23-DJI_0022' '13_01_23-DJI_0016'\n '12_01_23-DJI_0998' '16_01_23_session_1-DJI_0003' '12_01_23-DJI_0002'\n '13_01_23-DJI_0035' '13_01_23-DJI_0033' '17_01_2023_session_2-DJI_0012'\n '11_01_23-DJI_0980' '13_01_23-DJI_0040' '16_01_23_session_1-DJI_0002'\n '13_01_23-DJI_0023' '13_01_23-DJI_0042' '17_01_2023_session_2-DJI_0011'\n '13_01_23-DJI_0038' '12_01_23-DJI_0988' '12_01_23-DJI_0992'\n '13_01_23-DJI_0018' '16_01_23_session_2-DJI_0001' '11_01_23-DJI_0977'\n '16_01_23_session_2-DJI_0004' '13_01_23-DJI_0011'\n '17_01_2023_session_1-DJI_0007' '13_01_23-DJI_0012' '12_01_23-DJI_0987'\n '12_01_23-DJI_0007' '13_01_23-DJI_0029' '13_01_23-DJI_0043']\n</pre> In\u00a0[98]: Copied! <pre>import numpy as np\n\nlabels = [\n    \"Graze\", \"Walk\", \"Head Up\", \"Run\", \n    \"Browse\", \"Trot\", \"Auto-Groom\", \"Out of Sight\"\n]\n\ncm = np.array([\n    [0.87, 0.02, 0.07, 0.00, 0.00, 0.00, 0.01, 0.02],  # Graze\n    [0.04, 0.87, 0.06, 0.02, 0.00, 0.01, 0.00, 0.01],  # Walk\n    [0.02, 0.01, 0.94, 0.00, 0.00, 0.02, 0.00, 0.00],  # Head Up\n    [0.00, 0.19, 0.00, 0.71, 0.10, 0.00, 0.00, 0.00],  # Trot\n    [0.00, 0.13, 0.00, 0.10, 0.77, 0.00, 0.00, 0.00],  # Run\n    [0.48, 0.08, 0.04, 0.00, 0.00, 0.00, 0.40, 0.00],  # Browse\n    [0.50, 0.00, 0.25, 0.00, 0.00, 0.00, 0.25, 0.00],  # Auto-Groom\n    [0.66, 0.05, 0.11, 0.00, 0.00, 0.00, 0.00, 0.18],  # Out of Sight\n])\n</pre> import numpy as np  labels = [     \"Graze\", \"Walk\", \"Head Up\", \"Run\",      \"Browse\", \"Trot\", \"Auto-Groom\", \"Out of Sight\" ]  cm = np.array([     [0.87, 0.02, 0.07, 0.00, 0.00, 0.00, 0.01, 0.02],  # Graze     [0.04, 0.87, 0.06, 0.02, 0.00, 0.01, 0.00, 0.01],  # Walk     [0.02, 0.01, 0.94, 0.00, 0.00, 0.02, 0.00, 0.00],  # Head Up     [0.00, 0.19, 0.00, 0.71, 0.10, 0.00, 0.00, 0.00],  # Trot     [0.00, 0.13, 0.00, 0.10, 0.77, 0.00, 0.00, 0.00],  # Run     [0.48, 0.08, 0.04, 0.00, 0.00, 0.00, 0.40, 0.00],  # Browse     [0.50, 0.00, 0.25, 0.00, 0.00, 0.00, 0.25, 0.00],  # Auto-Groom     [0.66, 0.05, 0.11, 0.00, 0.00, 0.00, 0.00, 0.18],  # Out of Sight ]) In\u00a0[99]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(12, 10))\nsns.heatmap(cm,\n            annot=True, fmt=\".2f\",\n            xticklabels=labels,\n            yticklabels=labels,\n            cmap='cividis', vmin=0, vmax=1)\nax.set_xlabel(\"Predicted label\", fontsize=14)\nax.set_ylabel(\"True label\", fontsize=14)\nax.set_title(\"Manual Annotations vs X3D Predicted Behaviors\", fontsize=20)\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=12)\nplt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\nfig.savefig('manualvsX3D.pdf', dpi=300, bbox_inches='tight')\n</pre> import seaborn as sns import matplotlib.pyplot as plt  fig, ax = plt.subplots(figsize=(12, 10)) sns.heatmap(cm,             annot=True, fmt=\".2f\",             xticklabels=labels,             yticklabels=labels,             cmap='cividis', vmin=0, vmax=1) ax.set_xlabel(\"Predicted label\", fontsize=14) ax.set_ylabel(\"True label\", fontsize=14) ax.set_title(\"Manual Annotations vs X3D Predicted Behaviors\", fontsize=20) plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=12) plt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=12) plt.tight_layout() plt.show()  fig.savefig('manualvsX3D.pdf', dpi=300, bbox_inches='tight') In\u00a0[102]: Copied! <pre>fig, ax = plt.subplots(figsize=(12, 10))\nheatmap = sns.heatmap(cm,\n            annot=False, fmt=\".2f\",\n            xticklabels=labels,\n            yticklabels=labels,\n            cmap='cividis', vmin=0, vmax=1)\n\n# Set font size for the color bar\ncbar = heatmap.collections[0].colorbar\ncbar.ax.tick_params(labelsize=16)\n\nax.set_xlabel(\"Predicted label\", fontsize=20)\nax.set_ylabel(\"True label\", fontsize=20)\nax.set_title(\"Agreement Between Manual &amp; ML Behavior Annotations\", fontsize=20)\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=20)\nplt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=20)\nplt.tight_layout()\nplt.show()\n\nfig.savefig('manualvsX3D.pdf', dpi=300, bbox_inches='tight')\n</pre> fig, ax = plt.subplots(figsize=(12, 10)) heatmap = sns.heatmap(cm,             annot=False, fmt=\".2f\",             xticklabels=labels,             yticklabels=labels,             cmap='cividis', vmin=0, vmax=1)  # Set font size for the color bar cbar = heatmap.collections[0].colorbar cbar.ax.tick_params(labelsize=16)  ax.set_xlabel(\"Predicted label\", fontsize=20) ax.set_ylabel(\"True label\", fontsize=20) ax.set_title(\"Agreement Between Manual &amp; ML Behavior Annotations\", fontsize=20) plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=20) plt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=20) plt.tight_layout() plt.show()  fig.savefig('manualvsX3D.pdf', dpi=300, bbox_inches='tight') In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"methodology_comparison/kabr_dataset/data_analysis/#analysis-of-subset-of-data-used-to-create-mini-scene-dataset-to-train-behavior-recognition-model","title":"Analysis of subset of data used to create mini-scene dataset to train behavior recognition model\u00b6","text":""},{"location":"methodology_comparison/kabr_dataset/data_analysis/#analyze-consolidated-metadata-file","title":"Analyze consolidated metadata file\u00b6","text":"<p>This file contains behavior annotations, bounding boxes, and telemetry (altitude, GPS, etc.) for each frame in the video. Each row contains the video and mini-scene id.</p> <p>See previously released 'consolidated_metadata.csv' file in the Hugging Face dataset for data.</p>"},{"location":"methodology_comparison/kabr_dataset/data_analysis/#create-lookup-of-video-to-species-from-the-summary-file","title":"Create lookup of video to species from the summary file\u00b6","text":""},{"location":"methodology_comparison/kabr_dataset/data_analysis/#calculate-the-number-of-mini-scenes-by-species-using-lookup-table","title":"Calculate the number of mini scenes by species using lookup table\u00b6","text":""},{"location":"methodology_comparison/kabr_dataset/data_analysis/#get-number-of-unique-behaviors-captured-in-the-dataset","title":"Get number of unique behaviors captured in the dataset\u00b6","text":""},{"location":"methodology_comparison/kabr_dataset/data_analysis/#plot-performance-of-x3d-model","title":"Plot performance of X3D model\u00b6","text":""},{"location":"methodology_comparison/kabr_dataset/data/","title":"Data used in this analysis was derived from KABR mini-scene dataset","text":""},{"location":"methodology_comparison/kabr_dataset/data/#data-used-in-this-analysis-was-derived-from-kabr-mini-scene-dataset","title":"Data used in this analysis was derived from KABR mini-scene dataset","text":"<p>File descriptions:</p>"},{"location":"methodology_comparison/kabr_dataset/data/#miniscene_session_summarycsv","title":"miniscene_session_summary.csv","text":"<ul> <li>Contains summary information for each mini-scene session</li> <li>Columns: <code>Session</code>, <code>Date</code>, <code>Start Time</code>, <code>End Time</code>, <code>Duration</code>, <code>Species</code>, <code>Herd Size</code>, <code>Video File Names</code>, <code>Weather</code>, <code>Bitterlich Score</code>, and <code>Field Notes</code>.</li> </ul>"},{"location":"methodology_comparison/kabr_dataset/data/#video_miniscene_idcsv","title":"video_miniscene_id.csv","text":"<ul> <li>Contains mapping of video file names to mini-scene IDs</li> <li>Columns: Video File Name, Mini-scene ID</li> </ul>"},{"location":"methodology_comparison/kabr_dataset/data/#video_speciescsv","title":"video_species.csv","text":"<ul> <li>Contains mapping of video file names to species (Grevy's, Plains, or Giraffes)</li> <li>Columns: Video File Name, Species</li> </ul>"},{"location":"methodology_comparison/kabr_dataset/data/#data-source","title":"Data source:","text":"<p>The KABR mini-scene dataset in HF here: https://huggingface.co/datasets/imageomics/KABR Citation: @misc{KABR_Data,   author = {Kholiavchenko, Maksim and Kline, Jenna and Ramirez, Michelle and Stevens, Sam and Sheets, Alec and Babu, Reshma and Banerji, Namrata and Campolongo, Elizabeth and Thompson, Matthew and Van Tiel, Nina and Miliko, Jackson and Bessa, Eduardo and Duporge, Isla and Berger-Wolf, Tanya and Rubenstein, Daniel and Stewart, Charles},   title = {KABR: In-Situ Dataset for Kenyan Animal Behavior Recognition from Drone Videos},   year = {2023},   url = {https://huggingface.co/datasets/imageomics/KABR},   doi = {10.57967/hf/1010},   publisher = {Hugging Face} }</p> <p>Consolidated metadata contains summary of mini-scenes, along with telemetry data and annotations. https://huggingface.co/datasets/imageomics/kabr-behavior-telemetry Citation:  @misc{kline2024integratingbiologicaldataautonomous,       title={Integrating Biological Data into Autonomous Remote Sensing Systems for In Situ Imageomics: A Case Study for Kenyan Animal Behavior Sensing with Unmanned Aerial Vehicles (UAVs)},        author={Jenna M. Kline and Maksim Kholiavchenko and Otto Brookes and Tanya Berger-Wolf and Charles V. Stewart and Christopher Stewart},       year={2024},       eprint={2407.16864},       archivePrefix={arXiv},       primaryClass={cs.RO},       url={https://arxiv.org/abs/2407.16864},  }</p>"},{"location":"methodology_comparison/scanvsfocal/analysis/cm-scan-vs-focal-by-species/","title":"By Species","text":"<p>Download <code> scanvsfocal</code>  files used in this analysis from kabr-methodology collection in Hugging Face.</p> In\u00a0[13]: Copied! <pre>\"\"\"\nScript to generate a confusion matrix between field and drone focal sampling.\n\"\"\"\n\nimport argparse\nimport datetime\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport behavior\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Regex patterns (case-insensitive) \u2192 canonical label\nCATEGORY_PATTERNS = {\n    r\"(vigilant|stand|head\\s*up|alert\\s*vigilance|vigilance|scanning)\":            \"Head Up\",\n    r\"(fight|chase)\":                                           \"Out of Sight\",\n    r\"(out\\s*of\\s*sight|out\\s*of\\s*focus|\"\n    r\"out\\s*of\\s*frame|occluded|no\\s*data)\":                    \"Out of Sight\",\n    r\"(trot|trotting)\":                                           \"Trot\",\n    r\"(run|running)\":                                            \"Run\",\n    r\"(walk|walking)\":                                          \"Walk\",\n    r\"sniff\":                                                    \"Graze\",\n    r\"graze\":                                                    \"Graze\",\n    r\"browse|browsing\":                                          \"Browse\",\n    r\"auto[-\\s]*groom\":                                         \"Auto-Groom\",\n}\n\ndef clean_categories(name: str) -&gt; str:\n    \"\"\"\n    Standardise free-text behaviour labels:\n        * remove 'ing' variants (e.g. Running \u2192 Run)\n        * merge Trot &amp; Run\n        * map all occlusion / missing-data phrases to 'Out of Sight'\n    \"\"\"\n    text = name.lower()\n    for pattern, canon in CATEGORY_PATTERNS.items():\n        if re.search(pattern, text):\n            return canon\n    # If nothing matched, title-case the original so it fits the style\n    return name.title()\n\n\ndef main():\n    ground_truth_files = [\n        \"../data/plain/Scan-group_1.csv\",\n        \"../data/plain/Scan-group_2.csv\",\n        \"../data/grevys/Scan grevys group 1 morning 01_11.csv\",\n        \"../data/grevys/Scan grevys group 2_a 01_11.csv\",\n        \"../data/grevys/Scan grevys group 2_b 01_11.csv\",\n        \"../data/grevys/Scan grevys group 2_c 01_11.csv\",\n        \"../data/giraffe/Scan_giraffe_group_1.csv\",\n        # \"../data/giraffe/focal1-female.csv\",\n        # \"../data/giraffe/focal1-male.csv\",\n    ]\n    cmp_files = [\n        \"../data/plain/Focal-group_1.csv\",\n        \"../data/plain/Focal-group_2.csv\",\n        \"../data/grevys/Focal grevys group 1 morning 01_11.csv\",\n        \"../data/grevys/Focal grevys group 2_a 01_11.csv\",\n        \"../data/grevys/Focal grevys group 2_b 01_11.csv\",\n        \"../data/grevys/Focal grevys group 2_c 01_11.csv\",\n        # \"../data/giraffe/Scan_giraffe_group_1.csv\",\n        \"../data/giraffe/focal1-female.csv\",\n        \"../data/giraffe/focal1-male.csv\",\n    ]\n   \n    \n    minutes = 10\n\n    ground_truth_samples = []\n    for file in ground_truth_files:\n        ground_truth_samples.extend(behavior.Focal.from_scan_file(file, clean_categories))\n\n    cmp_samples = []\n    for file in cmp_files:\n        cmp_samples.extend(behavior.Focal.from_scan_file(file, clean_categories))\n        \n\n    # Lookup from behavior to integer\n    behavior_lookup = {}\n    for sample in ground_truth_samples + cmp_samples:\n        for b in sample.behaviors:\n            if b not in behavior_lookup:\n                behavior_lookup[b] = len(behavior_lookup)\n    \n\n    # Start the matrix\n    matrix = np.zeros((len(behavior_lookup), len(behavior_lookup)))\n\n    # Go through all pairs of samples\n    for ground_truth_sample, cmp_sample in zip(tqdm(ground_truth_samples), cmp_samples):\n        for action in ground_truth_sample.relative_slice(\n            datetime.timedelta(), datetime.timedelta(minutes=minutes)\n        ):\n            cmp_actions = cmp_sample.relative_slice(\n                action.relative_start, action.relative_stop\n            )\n\n            for cmp_action in cmp_actions:\n                matrix[behavior_lookup[action.name]][\n                    behavior_lookup[cmp_action.name]\n                ] += cmp_action.duration.seconds\n\n    # Normalize matrix\n    delete_from_both = []\n    for x, row in enumerate(matrix):\n        if sum(row) &gt; 0:\n            matrix[x] = [y / sum(row) for y in row]\n\n        if sum(matrix[x, :]) == 0 and sum(matrix[:, x]) == 0:\n            delete_from_both.append(x)\n    \n    matrix = np.delete(matrix, tuple(delete_from_both), axis=0)\n    matrix = np.delete(matrix, tuple(delete_from_both), axis=1)\n    \n    cleaned_behavior_lookup = {}\n    for b, old_idx in sorted(behavior_lookup.items(), key=lambda pair: pair[1]):\n        if old_idx in delete_from_both:\n            continue\n\n        cleaned_behavior_lookup[b] = len(cleaned_behavior_lookup)\n    behavior_lookup = cleaned_behavior_lookup\n\n    # # Plot the matrix\n    # fig, ax = plt.subplots()\n    # im = ax.imshow(matrix)\n    \n    print(\"Behaviors found:\", list(behavior_lookup.keys()))\n    print(\"Number of behaviors:\", len(behavior_lookup))\n    \n    return behavior_lookup, matrix\n\n\nif __name__ == \"__main__\":\n    cm = main()\n</pre> \"\"\" Script to generate a confusion matrix between field and drone focal sampling. \"\"\"  import argparse import datetime import matplotlib.pyplot as plt import numpy as np from tqdm.auto import tqdm import behavior import re import seaborn as sns import matplotlib.pyplot as plt  # Regex patterns (case-insensitive) \u2192 canonical label CATEGORY_PATTERNS = {     r\"(vigilant|stand|head\\s*up|alert\\s*vigilance|vigilance|scanning)\":            \"Head Up\",     r\"(fight|chase)\":                                           \"Out of Sight\",     r\"(out\\s*of\\s*sight|out\\s*of\\s*focus|\"     r\"out\\s*of\\s*frame|occluded|no\\s*data)\":                    \"Out of Sight\",     r\"(trot|trotting)\":                                           \"Trot\",     r\"(run|running)\":                                            \"Run\",     r\"(walk|walking)\":                                          \"Walk\",     r\"sniff\":                                                    \"Graze\",     r\"graze\":                                                    \"Graze\",     r\"browse|browsing\":                                          \"Browse\",     r\"auto[-\\s]*groom\":                                         \"Auto-Groom\", }  def clean_categories(name: str) -&gt; str:     \"\"\"     Standardise free-text behaviour labels:         * remove 'ing' variants (e.g. Running \u2192 Run)         * merge Trot &amp; Run         * map all occlusion / missing-data phrases to 'Out of Sight'     \"\"\"     text = name.lower()     for pattern, canon in CATEGORY_PATTERNS.items():         if re.search(pattern, text):             return canon     # If nothing matched, title-case the original so it fits the style     return name.title()   def main():     ground_truth_files = [         \"../data/plain/Scan-group_1.csv\",         \"../data/plain/Scan-group_2.csv\",         \"../data/grevys/Scan grevys group 1 morning 01_11.csv\",         \"../data/grevys/Scan grevys group 2_a 01_11.csv\",         \"../data/grevys/Scan grevys group 2_b 01_11.csv\",         \"../data/grevys/Scan grevys group 2_c 01_11.csv\",         \"../data/giraffe/Scan_giraffe_group_1.csv\",         # \"../data/giraffe/focal1-female.csv\",         # \"../data/giraffe/focal1-male.csv\",     ]     cmp_files = [         \"../data/plain/Focal-group_1.csv\",         \"../data/plain/Focal-group_2.csv\",         \"../data/grevys/Focal grevys group 1 morning 01_11.csv\",         \"../data/grevys/Focal grevys group 2_a 01_11.csv\",         \"../data/grevys/Focal grevys group 2_b 01_11.csv\",         \"../data/grevys/Focal grevys group 2_c 01_11.csv\",         # \"../data/giraffe/Scan_giraffe_group_1.csv\",         \"../data/giraffe/focal1-female.csv\",         \"../data/giraffe/focal1-male.csv\",     ]              minutes = 10      ground_truth_samples = []     for file in ground_truth_files:         ground_truth_samples.extend(behavior.Focal.from_scan_file(file, clean_categories))      cmp_samples = []     for file in cmp_files:         cmp_samples.extend(behavior.Focal.from_scan_file(file, clean_categories))               # Lookup from behavior to integer     behavior_lookup = {}     for sample in ground_truth_samples + cmp_samples:         for b in sample.behaviors:             if b not in behavior_lookup:                 behavior_lookup[b] = len(behavior_lookup)           # Start the matrix     matrix = np.zeros((len(behavior_lookup), len(behavior_lookup)))      # Go through all pairs of samples     for ground_truth_sample, cmp_sample in zip(tqdm(ground_truth_samples), cmp_samples):         for action in ground_truth_sample.relative_slice(             datetime.timedelta(), datetime.timedelta(minutes=minutes)         ):             cmp_actions = cmp_sample.relative_slice(                 action.relative_start, action.relative_stop             )              for cmp_action in cmp_actions:                 matrix[behavior_lookup[action.name]][                     behavior_lookup[cmp_action.name]                 ] += cmp_action.duration.seconds      # Normalize matrix     delete_from_both = []     for x, row in enumerate(matrix):         if sum(row) &gt; 0:             matrix[x] = [y / sum(row) for y in row]          if sum(matrix[x, :]) == 0 and sum(matrix[:, x]) == 0:             delete_from_both.append(x)          matrix = np.delete(matrix, tuple(delete_from_both), axis=0)     matrix = np.delete(matrix, tuple(delete_from_both), axis=1)          cleaned_behavior_lookup = {}     for b, old_idx in sorted(behavior_lookup.items(), key=lambda pair: pair[1]):         if old_idx in delete_from_both:             continue          cleaned_behavior_lookup[b] = len(cleaned_behavior_lookup)     behavior_lookup = cleaned_behavior_lookup      # # Plot the matrix     # fig, ax = plt.subplots()     # im = ax.imshow(matrix)          print(\"Behaviors found:\", list(behavior_lookup.keys()))     print(\"Number of behaviors:\", len(behavior_lookup))          return behavior_lookup, matrix   if __name__ == \"__main__\":     cm = main()   <pre> 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 16/17 [00:00&lt;00:00, 10825.76it/s]</pre> <pre>Behaviors found: ['Graze', 'Head Up', 'Walk', 'Browse', 'Urinate', 'Auto-Groom', 'Run', 'Trot']\nNumber of behaviors: 8\n</pre> <pre></pre> In\u00a0[14]: Copied! <pre>import numpy as np\n\n# labels = [\n#     \"Graze\", \"Walk\", \"Head Up\", \"Trot/Run\", \"Browse\", \"Auto-Groom\",\n#      \"Fight\", \"Out of Sight\"\n#     ]\nlabels = [\n    \"Graze\", \"Walk\", \"Head Up\", \"Run\", \n    \"Browse\", \"Trot\", \"Auto-Groom\", \"Out of Sight\"]\n</pre> import numpy as np  # labels = [ #     \"Graze\", \"Walk\", \"Head Up\", \"Trot/Run\", \"Browse\", \"Auto-Groom\", #      \"Fight\", \"Out of Sight\" #     ] labels = [     \"Graze\", \"Walk\", \"Head Up\", \"Run\",      \"Browse\", \"Trot\", \"Auto-Groom\", \"Out of Sight\"] In\u00a0[15]: Copied! <pre>fig, ax = plt.subplots(figsize=(12, 10))\nsns.heatmap(cm[1],\n            annot=True, fmt=\".2f\",\n            xticklabels=labels,\n            yticklabels=labels,\n            cmap='viridis', vmin=0, vmax=1)\nax.set_xlabel(\"Focal Data\", fontsize=14)\nax.set_ylabel(\"Scan Data\", fontsize=14)\nax.set_title(\"Ground Scan vs Focal Behavior Data\", fontsize=20)\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=12)\nplt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=12)\nplt.tight_layout()\nplt.show()\n\nfig.savefig(\"../field_scan_vs_focal_sampling.pdf\", dpi=300)\n</pre> fig, ax = plt.subplots(figsize=(12, 10)) sns.heatmap(cm[1],             annot=True, fmt=\".2f\",             xticklabels=labels,             yticklabels=labels,             cmap='viridis', vmin=0, vmax=1) ax.set_xlabel(\"Focal Data\", fontsize=14) ax.set_ylabel(\"Scan Data\", fontsize=14) ax.set_title(\"Ground Scan vs Focal Behavior Data\", fontsize=20) plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=12) plt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=12) plt.tight_layout() plt.show()  fig.savefig(\"../field_scan_vs_focal_sampling.pdf\", dpi=300) In\u00a0[16]: Copied! <pre>fig, ax = plt.subplots(figsize=(12, 10))\nheatmap = sns.heatmap(cm[1],\n            annot=False, fmt=\".2f\",\n            xticklabels=labels,\n            yticklabels=labels,\n            cmap='cividis', vmin=0, vmax=1)\n\ncbar = heatmap.collections[0].colorbar\ncbar.ax.tick_params(labelsize=16)\n\nax.set_xlabel(\"Ground Focal\", fontsize=20)\nax.set_ylabel(\"Ground Scan\", fontsize=20)\nax.set_title(\"Agreement Between Ground Scan &amp; Ground Focal Behaviors\", fontsize=20)\n\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=20)\nplt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=20)\n\nplt.tight_layout()\nplt.show()\n\nfig.savefig(\"../field_scan_vs_focal_sampling.pdf\", dpi=300)\n</pre> fig, ax = plt.subplots(figsize=(12, 10)) heatmap = sns.heatmap(cm[1],             annot=False, fmt=\".2f\",             xticklabels=labels,             yticklabels=labels,             cmap='cividis', vmin=0, vmax=1)  cbar = heatmap.collections[0].colorbar cbar.ax.tick_params(labelsize=16)  ax.set_xlabel(\"Ground Focal\", fontsize=20) ax.set_ylabel(\"Ground Scan\", fontsize=20) ax.set_title(\"Agreement Between Ground Scan &amp; Ground Focal Behaviors\", fontsize=20)  plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=20) plt.setp(ax.get_yticklabels(), rotation=0, ha=\"right\", fontsize=20)  plt.tight_layout() plt.show()  fig.savefig(\"../field_scan_vs_focal_sampling.pdf\", dpi=300) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"methodology_comparison/scanvsfocal/analysis/cm-scan-vs-focal-by-species/#comparison-of-data-collected-from-scan-vs-focal-sampling-by-species","title":"Comparison of data collected from scan vs focal sampling by species\u00b6","text":""},{"location":"methodology_comparison/scanvsfocal/analysis/behavior/__init__/","title":"init","text":"In\u00a0[\u00a0]: Copied! <pre>from .main import Action, Focal\n</pre> from .main import Action, Focal In\u00a0[\u00a0]: Copied! <pre>__all__ = [\"Action\", \"Focal\"]\n</pre> __all__ = [\"Action\", \"Focal\"]"},{"location":"methodology_comparison/scanvsfocal/analysis/behavior/main/","title":"Main","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nPackage to manage focal data from Animal Behavior Pro\n\"\"\"\nimport csv\nimport collections\nimport dataclasses\nimport datetime\n</pre> \"\"\" Package to manage focal data from Animal Behavior Pro \"\"\" import csv import collections import dataclasses import datetime In\u00a0[\u00a0]: Copied! <pre>def _read_csv(file) -&gt; \"dict[str, str]\":\n    with open(file) as fd:\n        reader = csv.DictReader(fd)\n        return list(reader)\n</pre> def _read_csv(file) -&gt; \"dict[str, str]\":     with open(file) as fd:         reader = csv.DictReader(fd)         return list(reader) In\u00a0[\u00a0]: Copied! <pre>def _clean_value(raw_value):\n    return raw_value.strip('\" ')\n</pre> def _clean_value(raw_value):     return raw_value.strip('\" ') In\u00a0[\u00a0]: Copied! <pre>def _parse_absolute_time(ymd, hms):\n    ymd = _clean_value(ymd)\n    hms = _clean_value(hms)\n    return datetime.datetime.strptime(ymd + \"|\" + hms, \"%Y-%m-%d|%H:%M:%S\")\n</pre> def _parse_absolute_time(ymd, hms):     ymd = _clean_value(ymd)     hms = _clean_value(hms)     return datetime.datetime.strptime(ymd + \"|\" + hms, \"%Y-%m-%d|%H:%M:%S\") In\u00a0[\u00a0]: Copied! <pre>@dataclasses.dataclass(frozen=True)\nclass Action:\n    name: str\n    absolute_start: datetime.datetime\n    relative_start: datetime.timedelta\n    duration: datetime.timedelta\n\n    @classmethod\n    def from_row(cls, row, conversion=None):\n        name = _clean_value(row[\" Behavior\"])\n        if callable(conversion):\n            name = conversion(name)\n\n        absolute_start = _parse_absolute_time(\n            row[\"Date_ymd\"], row[\" Time_Absolute_hms\"]\n        )\n\n        relative_start = datetime.timedelta(seconds=float(row[\" Time_Relative_s\"]))\n        duration = datetime.timedelta(seconds=float(row[\" Duration_s\"]))\n\n        return cls(name, absolute_start, relative_start, duration)\n\n    @property\n    def absolute_stop(self):\n        return self.absolute_start + self.duration\n\n    @property\n    def relative_stop(self):\n        return self.relative_start + self.duration\n\n    def relative_slice(self, start_time, stop_time):\n        \"\"\"\n        Returns a copy of this action starting from start_time and ending at stop_time\n        \"\"\"\n        absolute_start = self.absolute_start\n\n        relative_start = self.relative_start\n        if start_time &gt; relative_start:\n            absolute_start += start_time - relative_start\n            relative_start = start_time\n\n        stop_time = min(stop_time, self.relative_stop)\n        duration = stop_time - relative_start\n\n        return self.__class__(self.name, absolute_start, relative_start, duration)\n</pre> @dataclasses.dataclass(frozen=True) class Action:     name: str     absolute_start: datetime.datetime     relative_start: datetime.timedelta     duration: datetime.timedelta      @classmethod     def from_row(cls, row, conversion=None):         name = _clean_value(row[\" Behavior\"])         if callable(conversion):             name = conversion(name)          absolute_start = _parse_absolute_time(             row[\"Date_ymd\"], row[\" Time_Absolute_hms\"]         )          relative_start = datetime.timedelta(seconds=float(row[\" Time_Relative_s\"]))         duration = datetime.timedelta(seconds=float(row[\" Duration_s\"]))          return cls(name, absolute_start, relative_start, duration)      @property     def absolute_stop(self):         return self.absolute_start + self.duration      @property     def relative_stop(self):         return self.relative_start + self.duration      def relative_slice(self, start_time, stop_time):         \"\"\"         Returns a copy of this action starting from start_time and ending at stop_time         \"\"\"         absolute_start = self.absolute_start          relative_start = self.relative_start         if start_time &gt; relative_start:             absolute_start += start_time - relative_start             relative_start = start_time          stop_time = min(stop_time, self.relative_stop)         duration = stop_time - relative_start          return self.__class__(self.name, absolute_start, relative_start, duration) In\u00a0[\u00a0]: Copied! <pre>class Focal:\n    def __init__(self, actor, actions):\n        self._actor = actor\n        self._actions = actions\n\n    @classmethod\n    def from_file(cls, file, conversion=None):\n        \"\"\"\n        conversion: Optional function that takes a string and returns a string. Used to change/merge categories.\n        \"\"\"\n        actions: \"list[Action]\" = []\n\n        rows = _read_csv(file)\n\n        actor = _clean_value(rows[0][\" Actor\"])\n        assert all(_clean_value(row[\" Actor\"]) == actor for row in rows)\n\n        for row in rows:\n            # Assume that all behaviors are mutually exclusive. Anytime we\n            # see a State stop, then it is always followed by a State start.\n            if row[\" Event_Type\"] != \" State start\":\n                continue\n\n            action = Action.from_row(row, conversion)\n            actions.append(action)\n\n        return cls(actor, actions)\n\n    @classmethod\n    def from_scan_file(cls, file, conversion=None):\n        \"\"\"\n        Produces multiple \"Focal\" items from a single Scan file.\n        \"\"\"\n        actions = collections.defaultdict(list)\n\n        rows = _read_csv(file)\n\n        for row in rows:\n            # Assume that all behaviors are mutually exclusive. Anytime we\n            # see a State stop, then it is always followed by a State start.\n            if row[\" Event_Type\"] != \" State start\":\n                continue\n\n            action = Action.from_row(row, conversion)\n            if action.name != 'Out of Sight': actions[_clean_value(row[\" Actor\"])].append(action)\n\n        return [cls(actor, actions[actor]) for actor in actions]\n\n    def relative_slice(self, start_time, stop_time):\n        actions = []\n        for action in self:\n            # Skip actions that end before start_time\n            if action.relative_stop &lt; start_time:\n                continue\n\n            # Skip actions that start after end_time\n            if action.relative_start &gt; stop_time:\n                continue\n\n            actions.append(action.relative_slice(start_time, stop_time))  \n        return self.__class__(self._actor, actions)\n\n    def __iter__(self):\n        return iter(self._actions)\n\n    def __repr__(self):\n        return f\"Focal('{self._actor}', {len(self._actions)} actions)\"\n\n    \n    @property\n    def behaviors(self):\n        return sorted(action.name for action in self._actions)\n\n    @property\n    def actor(self):\n        return self._actor\n</pre> class Focal:     def __init__(self, actor, actions):         self._actor = actor         self._actions = actions      @classmethod     def from_file(cls, file, conversion=None):         \"\"\"         conversion: Optional function that takes a string and returns a string. Used to change/merge categories.         \"\"\"         actions: \"list[Action]\" = []          rows = _read_csv(file)          actor = _clean_value(rows[0][\" Actor\"])         assert all(_clean_value(row[\" Actor\"]) == actor for row in rows)          for row in rows:             # Assume that all behaviors are mutually exclusive. Anytime we             # see a State stop, then it is always followed by a State start.             if row[\" Event_Type\"] != \" State start\":                 continue              action = Action.from_row(row, conversion)             actions.append(action)          return cls(actor, actions)      @classmethod     def from_scan_file(cls, file, conversion=None):         \"\"\"         Produces multiple \"Focal\" items from a single Scan file.         \"\"\"         actions = collections.defaultdict(list)          rows = _read_csv(file)          for row in rows:             # Assume that all behaviors are mutually exclusive. Anytime we             # see a State stop, then it is always followed by a State start.             if row[\" Event_Type\"] != \" State start\":                 continue              action = Action.from_row(row, conversion)             if action.name != 'Out of Sight': actions[_clean_value(row[\" Actor\"])].append(action)          return [cls(actor, actions[actor]) for actor in actions]      def relative_slice(self, start_time, stop_time):         actions = []         for action in self:             # Skip actions that end before start_time             if action.relative_stop &lt; start_time:                 continue              # Skip actions that start after end_time             if action.relative_start &gt; stop_time:                 continue              actions.append(action.relative_slice(start_time, stop_time))           return self.__class__(self._actor, actions)      def __iter__(self):         return iter(self._actions)      def __repr__(self):         return f\"Focal('{self._actor}', {len(self._actions)} actions)\"           @property     def behaviors(self):         return sorted(action.name for action in self._actions)      @property     def actor(self):         return self._actor"},{"location":"methodology_comparison/scanvsfocal/analysis/behavior/test/__init__/","title":"init","text":""},{"location":"methodology_comparison/scanvsfocal/analysis/behavior/test/test_action/","title":"Test action","text":"In\u00a0[\u00a0]: Copied! <pre>import datetime\n</pre> import datetime In\u00a0[\u00a0]: Copied! <pre>from ..main import Action\n</pre> from ..main import Action In\u00a0[\u00a0]: Copied! <pre>def test_imports():\n    pass\n</pre> def test_imports():     pass In\u00a0[\u00a0]: Copied! <pre>def test_constructor():\n    action = Action(\n        \"Run\",\n        datetime.datetime(1900, 4, 5, 14, 30, 0),\n        datetime.timedelta(seconds=0),\n        datetime.timedelta(seconds=12.4),\n    )\n</pre> def test_constructor():     action = Action(         \"Run\",         datetime.datetime(1900, 4, 5, 14, 30, 0),         datetime.timedelta(seconds=0),         datetime.timedelta(seconds=12.4),     ) In\u00a0[\u00a0]: Copied! <pre>def test_relative_start():\n    action = Action(\n        \"Run\",\n        datetime.datetime(1900, 4, 5, 14, 30, 0),\n        datetime.timedelta(seconds=12.4),\n        datetime.timedelta(seconds=14.3),\n    )\n\n    assert action.relative_start == datetime.timedelta(seconds=12.4)\n</pre> def test_relative_start():     action = Action(         \"Run\",         datetime.datetime(1900, 4, 5, 14, 30, 0),         datetime.timedelta(seconds=12.4),         datetime.timedelta(seconds=14.3),     )      assert action.relative_start == datetime.timedelta(seconds=12.4) In\u00a0[\u00a0]: Copied! <pre>def test_relative_stop():\n    action = Action(\n        \"Run\",\n        datetime.datetime(1900, 4, 5, 14, 30, 0),\n        datetime.timedelta(seconds=12.4),\n        datetime.timedelta(seconds=14.3),\n    )\n\n    assert action.relative_stop == datetime.timedelta(seconds=26.7)\n</pre> def test_relative_stop():     action = Action(         \"Run\",         datetime.datetime(1900, 4, 5, 14, 30, 0),         datetime.timedelta(seconds=12.4),         datetime.timedelta(seconds=14.3),     )      assert action.relative_stop == datetime.timedelta(seconds=26.7) In\u00a0[\u00a0]: Copied! <pre>def test_relative_slice_change_duration():\n    action = Action(\n        \"Run\",\n        datetime.datetime(1900, 1, 1, 14, 30, 2),\n        datetime.timedelta(seconds=2),\n        datetime.timedelta(seconds=3),\n    )\n\n    start_time = datetime.timedelta(seconds=1.5)\n    stop_time = datetime.timedelta(seconds=4)\n\n    expected = Action(\n        \"Run\",\n        datetime.datetime(1900, 1, 1, 14, 30, 2),\n        datetime.timedelta(seconds=2),\n        datetime.timedelta(seconds=2),\n    )\n\n    assert action.relative_slice(start_time, stop_time) == expected\n</pre> def test_relative_slice_change_duration():     action = Action(         \"Run\",         datetime.datetime(1900, 1, 1, 14, 30, 2),         datetime.timedelta(seconds=2),         datetime.timedelta(seconds=3),     )      start_time = datetime.timedelta(seconds=1.5)     stop_time = datetime.timedelta(seconds=4)      expected = Action(         \"Run\",         datetime.datetime(1900, 1, 1, 14, 30, 2),         datetime.timedelta(seconds=2),         datetime.timedelta(seconds=2),     )      assert action.relative_slice(start_time, stop_time) == expected In\u00a0[\u00a0]: Copied! <pre>def test_relative_slice_change_start():\n    action = Action(\n        \"Run\",\n        datetime.datetime(1900, 1, 1, 14, 30, 1, 500_000),\n        datetime.timedelta(seconds=1.5),\n        datetime.timedelta(seconds=2.5),\n    )\n\n    start_time = datetime.timedelta(seconds=2)\n    stop_time = datetime.timedelta(seconds=5)\n\n    expected = Action(\n        \"Run\",\n        datetime.datetime(1900, 1, 1, 14, 30, 2),\n        datetime.timedelta(seconds=2),\n        datetime.timedelta(seconds=2),\n    )\n\n    assert action.relative_slice(start_time, stop_time) == expected\n</pre> def test_relative_slice_change_start():     action = Action(         \"Run\",         datetime.datetime(1900, 1, 1, 14, 30, 1, 500_000),         datetime.timedelta(seconds=1.5),         datetime.timedelta(seconds=2.5),     )      start_time = datetime.timedelta(seconds=2)     stop_time = datetime.timedelta(seconds=5)      expected = Action(         \"Run\",         datetime.datetime(1900, 1, 1, 14, 30, 2),         datetime.timedelta(seconds=2),         datetime.timedelta(seconds=2),     )      assert action.relative_slice(start_time, stop_time) == expected In\u00a0[\u00a0]: Copied! <pre>def test_relative_slice_no_change():\n    action = Action(\n        \"Run\",\n        datetime.datetime(2001, 12, 4, 2, 0, 0, 0),\n        datetime.timedelta(seconds=5),\n        datetime.timedelta(seconds=2),\n    )\n\n    start_time = datetime.timedelta(seconds=4)\n    stop_time = datetime.timedelta(seconds=8)\n\n    assert action.relative_slice(start_time, stop_time) == action\n</pre> def test_relative_slice_no_change():     action = Action(         \"Run\",         datetime.datetime(2001, 12, 4, 2, 0, 0, 0),         datetime.timedelta(seconds=5),         datetime.timedelta(seconds=2),     )      start_time = datetime.timedelta(seconds=4)     stop_time = datetime.timedelta(seconds=8)      assert action.relative_slice(start_time, stop_time) == action In\u00a0[\u00a0]: Copied! <pre>def test_relative_slice_both_change():\n    action = Action(\n        \"Run\",\n        datetime.datetime(2001, 12, 4, 2, 0, 0, 0),\n        datetime.timedelta(seconds=4),\n        datetime.timedelta(seconds=4),\n    )\n\n    start_time = datetime.timedelta(seconds=5)\n    stop_time = datetime.timedelta(seconds=7)\n\n    expected = Action(\n        \"Run\",\n        datetime.datetime(2001, 12, 4, 2, 0, 1),\n        datetime.timedelta(seconds=5),\n        datetime.timedelta(seconds=2),\n    )\n\n    assert action.relative_slice(start_time, stop_time) == expected\n</pre> def test_relative_slice_both_change():     action = Action(         \"Run\",         datetime.datetime(2001, 12, 4, 2, 0, 0, 0),         datetime.timedelta(seconds=4),         datetime.timedelta(seconds=4),     )      start_time = datetime.timedelta(seconds=5)     stop_time = datetime.timedelta(seconds=7)      expected = Action(         \"Run\",         datetime.datetime(2001, 12, 4, 2, 0, 1),         datetime.timedelta(seconds=5),         datetime.timedelta(seconds=2),     )      assert action.relative_slice(start_time, stop_time) == expected"},{"location":"pipeline/analysis/","title":"Ecological Analysis","text":""},{"location":"pipeline/analysis/#step-4-ecological-analysis","title":"Step 4: Ecological Analysis","text":""},{"location":"pipeline/analysis/#overview","title":"Overview","text":"<p>After labeling mini-scenes with behaviors, you can perform various ecological analyses to generate insights from your behavioral data. The KABR tools framework supports multiple types of analysis including time budgets, social interactions, and behavioral transitions.</p>"},{"location":"pipeline/analysis/#time-budget-analysis","title":"Time Budget Analysis","text":"<p>Time budget analysis shows how animals allocate their time across different behaviors during observation periods.</p>"},{"location":"pipeline/analysis/#example-analysis","title":"Example Analysis","text":"<p>Figure 1: Example flight path and video clip from KABR dataset: two male Grevy's zebras observed for 10 minutes on 01/18/23.</p> <p></p> <p>Figure 2: Overall time budget for duration of 10 minute observation.</p> <p> </p> <p>Figure 3: Gantt chart for each zebra (3 minute duration).</p>"},{"location":"pipeline/analysis/#implementation","title":"Implementation","text":"<p>See the time budgets notebook for the code to create these visualizations.</p>"},{"location":"pipeline/analysis/#social-interactions","title":"Social Interactions","text":"<p>Social interaction analysis examines how different species and individuals interact within the same environment, including proximity patterns and mixed-species associations.</p>"},{"location":"pipeline/analysis/#implementation_1","title":"Implementation","text":"<p>See the social interactions notebook for the code to create these visualizations.</p>"},{"location":"pipeline/analysis/#behavior-transitions","title":"Behavior Transitions","text":"<p>Behavioral transition analysis reveals patterns in how animals move between different behavioral states over time, providing insights into behavioral sequences and decision-making processes.</p>"},{"location":"pipeline/analysis/#implementation_2","title":"Implementation","text":"<p>See the behavior transitions notebook for the code to create these visualizations.</p>"},{"location":"pipeline/analysis/#case-studies","title":"Case Studies","text":"<p>Explore real-world applications in the case studies directory:</p> <ul> <li>Grevy's Landscape Analysis - Landscape-scale behavioral analysis.</li> <li>Mixed Species Social - Multi-species interaction analysis.</li> <li>Zebra Behavior Transitions - Behavioral transition patterns.</li> </ul>"},{"location":"pipeline/analysis/#key-metrics-generated","title":"Key Metrics Generated","text":"<p>The analysis pipeline can generate several key ecological metrics:</p> <ol> <li>Time Budgets - Proportion of time spent in each behavioral category.</li> <li>Behavioral Transitions - Probability matrices of behavior changes.</li> <li>Social Interactions - Proximity and interaction frequency between individuals.</li> <li>Habitat Associations - Relationship between behaviors and spatial locations.</li> <li>Group Composition Dynamics - Changes in group structure over time.</li> </ol>"},{"location":"pipeline/analysis/#visualization-tools","title":"Visualization Tools","text":"<p>The framework includes tools for creating publication-ready visualizations:</p> <ul> <li>Gantt charts for individual behavioral timelines.</li> <li>Heat maps for behavioral transition probabilities.</li> <li>Spatial plots for habitat use patterns.</li> <li>Social network diagrams for interaction patterns.</li> <li>Time series plots for behavioral trends.</li> </ul>"},{"location":"pipeline/analysis/#next-steps","title":"Next Steps","text":"<p>For additional customization and advanced features, see Optional Steps which covers fine-tuning YOLO models and additional utility tools.</p>"},{"location":"pipeline/behavior-labeling/","title":"Behavior Labeling","text":""},{"location":"pipeline/behavior-labeling/#step-3-label-mini-scenes-with-behavior","title":"Step 3: Label Mini-scenes with Behavior","text":""},{"location":"pipeline/behavior-labeling/#overview","title":"Overview","text":"<p>You can use the KABR model on Hugging Face to label the mini-scenes with behavior. See the ethogram folder for the list of behaviors used to label the zebra videos.</p>"},{"location":"pipeline/behavior-labeling/#using-the-miniscene2behavior-tool","title":"Using the miniscene2behavior Tool","text":"<p>Label the mini-scenes using the following command:</p> <pre><code>miniscene2behavior [--hub huggingface_hub] [--config path_to_config] --checkpoint path_to_checkpoint [--gpu_num number_of_gpus] --miniscene path_to_miniscene [--output path_to_output_csv]\n</code></pre>"},{"location":"pipeline/behavior-labeling/#usage-examples","title":"Usage Examples","text":""},{"location":"pipeline/behavior-labeling/#download-checkpoint-from-hugging-face-and-extract-config","title":"Download checkpoint from Hugging Face and extract config","text":"<pre><code>miniscene2behavior --hub imageomics/x3d-kabr-kinetics --checkpoint checkpoint_epoch_00075.pyth.zip --miniscene path_to_miniscene\n</code></pre>"},{"location":"pipeline/behavior-labeling/#download-checkpoint-and-config-from-hugging-face","title":"Download checkpoint and config from Hugging Face","text":"<pre><code>miniscene2behavior --hub imageomics/x3d-kabr-kinetics --config config.yml --checkpoint checkpoint_epoch_00075.pyth --miniscene path_to_miniscene\n</code></pre>"},{"location":"pipeline/behavior-labeling/#use-local-checkpoint-and-config","title":"Use local checkpoint and config","text":"<pre><code>miniscene2behavior --config config.yml --checkpoint checkpoint_epoch_00075.pyth --miniscene path_to_miniscene\n</code></pre>"},{"location":"pipeline/behavior-labeling/#important-notes","title":"Important Notes","text":"<p>GPU Usage</p> <p>If <code>gpu_num</code> is 0, the model will use CPU. Using at least 1 GPU greatly increases inference speed. If you're using OSC, you can request a node with one GPU by running: </p><pre><code>sbatch -N 1 --gpus-per-node 1 -A [account] --time=[minutes] [bash script]\n</code></pre><p></p> <p>Input Format</p> <p>Mini-scenes are clipped videos focused on individual animals and video is the raw video file from which mini-scenes have been extracted.</p>"},{"location":"pipeline/behavior-labeling/#resources","title":"Resources","text":"<ul> <li>Pre-trained KABR model on Hugging Face.</li> <li>Ethogram definitions - Behavior classification system used for zebra videos.</li> <li>Example annotated outputs on Hugging Face.</li> </ul>"},{"location":"pipeline/behavior-labeling/#tool-reference","title":"Tool Reference","text":""},{"location":"pipeline/behavior-labeling/#miniscene2behavior","title":"miniscene2behavior","text":"<p>Source: src/kabr_tools/miniscene2behavior.py</p> <p>Apply machine learning models to classify animal behaviors from mini-scene videos.</p> <p>Parameters: - <code>--hub</code>: Hugging Face hub repository containing model files. - <code>--config</code>: Path to configuration file (local or from hub). - <code>--checkpoint</code>: Path to model checkpoint file. - <code>--gpu_num</code>: Number of GPUs to use (0 for CPU). - <code>--miniscene</code>: Path to mini-scene videos directory. - <code>--output</code>: Path for output CSV file (optional).</p>"},{"location":"pipeline/behavior-labeling/#next-steps","title":"Next Steps","text":"<p>Once you have labeled your mini-scenes with behaviors, proceed to Step 4: Ecological Analysis to generate insights and visualizations from your behavioral data.</p>"},{"location":"pipeline/data-collection/","title":"Video Data Collection","text":""},{"location":"pipeline/data-collection/#step-1-video-data-collection-with-drones","title":"Step 1: Video Data Collection with Drones","text":"<p>Figure: Clip of drone video containing Plains and Grevy's zebras, plus some impalas.</p>"},{"location":"pipeline/data-collection/#overview","title":"Overview","text":"<p>The drone videos for the KABR dataset were collected at the Mpala Research Centre in January 2023. The missions were flown manually, using a DJI 2S Air drone.</p>"},{"location":"pipeline/data-collection/#best-practices","title":"Best Practices","text":"<p>We collaborated with expert ecologists to ensure minimal disturbance to the animals. Our approach included:</p> <ul> <li>Launch Position: Approximately 200 meters horizontally from the animals.</li> <li>Initial Altitude: 30-40 meters above ground.</li> <li>Approach Strategy: Gradually approach the herd from the side by reducing altitude and horizontal distance.</li> <li>Monitoring: Continuously monitor animals for signs of vigilance.</li> </ul> <p>Species-Specific Considerations</p> <p>The vigilance exhibited by wildlife varies widely by species, habitat, sex, and the level to which animals may be habituated to anthropogenic noise. We recommend that you tailor your approach to your particular species and setting.</p>"},{"location":"pipeline/data-collection/#equipment-used","title":"Equipment Used","text":"<ul> <li>Drone: DJI Air 2S.</li> <li>Flight Mode: Manual control.</li> <li>Recording Settings: Standard video recording at highest available resolution.</li> </ul>"},{"location":"pipeline/data-collection/#data-collection-workflow","title":"Data Collection Workflow","text":"<ol> <li>Site Assessment: Scout the area and identify animal locations.</li> <li>Equipment Setup: Prepare drone and check battery levels.</li> <li>Launch: Deploy drone at safe distance from animals.</li> <li>Approach: Gradually move closer while monitoring animal behavior.</li> <li>Recording: Capture video footage of natural behaviors.</li> <li>Data Management: Safely store and backup all collected footage.</li> </ol>"},{"location":"pipeline/data-collection/#publications","title":"Publications","text":"<p>For detailed information on our data collection methodology, please refer to:</p> <ul> <li>KABR: In-Situ Dataset for Kenyan Animal Behavior Recognition from Drone Videos</li> <li>A Framework for Autonomic Computing for In Situ Imageomics</li> <li>Integrating Biological Data into Autonomous Remote Sensing Systems for In Situ Imageomics</li> </ul>"},{"location":"pipeline/data-collection/#next-steps","title":"Next Steps","text":"<p>Once you have collected your drone video footage, proceed to Step 2: Data Pre-processing to create mini-scenes from your videos.</p>"},{"location":"pipeline/optional-steps/","title":"Optional Steps","text":""},{"location":"pipeline/optional-steps/#optional-steps","title":"Optional Steps","text":""},{"location":"pipeline/optional-steps/#fine-tune-yolo-for-your-dataset","title":"Fine-tune YOLO for Your Dataset","text":"<p>If you wish to use YOLO to automatically generate detections, you may want to fine-tune your YOLO model for your dataset using the YOLO training notebook.</p>"},{"location":"pipeline/optional-steps/#cvat2ultralytics","title":"cvat2ultralytics","text":"<p>Convert CVAT annotations to Ultralytics YOLO dataset format for training custom models.</p> <p>Usage: </p><pre><code>cvat2ultralytics --video path_to_videos --annotation path_to_annotations --dataset dataset_name [--skip skip_frames]\n</code></pre><p></p> <p>Source: src/kabr_tools/cvat2ultralytics.py</p>"},{"location":"pipeline/optional-steps/#additional-utility-tools","title":"Additional Utility Tools","text":""},{"location":"pipeline/optional-steps/#player","title":"player","text":"<p>Interactive player for tracking and behavior observation with visualization capabilities.</p> <p>Usage: </p><pre><code>player --folder path_to_folder [--save] [--imshow]\n</code></pre><p></p> <p></p> <p>Figure: Example player.py output showing tracking visualization.</p> <p>Source: src/kabr_tools/player.py</p>"},{"location":"pipeline/optional-steps/#cvat2slowfast","title":"cvat2slowfast","text":"<p>Convert CVAT annotations to the dataset in Charades format for use with SlowFast video understanding models.</p> <p>Usage: </p><pre><code>cvat2slowfast --miniscene path_to_mini_scenes --dataset dataset_name --classes path_to_classes_json [--old2new path_to_old2new_json] [--no_images]\n</code></pre><p></p> <p>Source: src/kabr_tools/cvat2slowfast.py</p>"},{"location":"pipeline/optional-steps/#helper-scripts","title":"Helper Scripts","text":"<p>Several utility scripts are available in the <code>helper_scripts</code> directory:</p>"},{"location":"pipeline/optional-steps/#annotate-mini-scenes","title":"Annotate Mini-scenes","text":"<p>Scripts for batch processing and annotation of mini-scenes:</p> <ul> <li>launch_job.py - Job launcher for batch processing.</li> <li>run.sh - Shell script for running annotation tasks.</li> </ul> <p>See the README for detailed usage instructions.</p>"},{"location":"pipeline/optional-steps/#video-processing-utilities","title":"Video Processing Utilities","text":"<ul> <li>downgrade.sh - Reduce video file sizes for CVAT compatibility.</li> <li>rename.sh - Batch rename files with consistent naming conventions.</li> </ul>"},{"location":"pipeline/optional-steps/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"pipeline/optional-steps/#custom-model-training","title":"Custom Model Training","text":"<p>For training custom behavior recognition models, you'll need:</p> <ol> <li>Annotated mini-scenes from your specific species/environment.</li> <li>Behavior ethogram defining your classification categories.</li> <li>Training configuration adapted to your dataset size and complexity.</li> </ol>"},{"location":"pipeline/optional-steps/#gpu-requirements","title":"GPU Requirements","text":"<p>Most tools support both CPU and GPU processing:</p> <ul> <li>CPU mode: Slower but works on any system.</li> <li>GPU mode: Significantly faster, recommended for large datasets.</li> <li>Multi-GPU: Supported for distributed processing of large video collections.</li> </ul>"},{"location":"pipeline/optional-steps/#batch-processing","title":"Batch Processing","text":"<p>For processing large video collections:</p> <ol> <li>Use the provided shell scripts for batch operations.</li> <li>Consider using job scheduling systems (SLURM, PBS) for cluster environments.</li> <li>Monitor disk space requirements for intermediate files.</li> </ol>"},{"location":"pipeline/optional-steps/#customization-options","title":"Customization Options","text":"<p>The modular design allows for customization at multiple levels:</p> <ul> <li>Detection models: Swap YOLO versions or use custom trained models.</li> <li>Tracking algorithms: Modify tracking parameters for different scenarios.</li> <li>Behavior models: Train species-specific or behavior-specific classifiers.</li> <li>Analysis pipelines: Adapt visualization and metrics to research questions.</li> </ul>"},{"location":"pipeline/optional-steps/#performance-optimization","title":"Performance Optimization","text":"<p>Tips for optimizing performance:</p> <ul> <li>Use appropriate video resolution for your analysis needs.</li> <li>Batch process multiple videos simultaneously when possible.</li> <li>Utilize GPU acceleration for model inference.</li> <li>Consider video compression for storage efficiency.</li> </ul>"},{"location":"pipeline/overview/","title":"Overview","text":""},{"location":"pipeline/overview/#pipeline-overview","title":"Pipeline Overview","text":"<p>Figure: KABR tools pipeline for processing drone videos. The pipeline consists of four main steps: video data collection, data pre-processing, behavior labeling, and ecological analysis. Each step is modular and can be adapted to different species and study systems.</p>"},{"location":"pipeline/overview/#pipeline-steps","title":"Pipeline Steps","text":"<p>The KABR tools pipeline consists of four main sequential steps:</p>"},{"location":"pipeline/overview/#1-video-data-collection","title":"1. Video Data Collection","text":"<p>Collection of drone video footage following best practices for wildlife observation while minimizing disturbance to animals.</p>"},{"location":"pipeline/overview/#2-data-pre-processing-with-cvat","title":"2. Data Pre-processing with CVAT","text":"<p>Creation of mini-scenes focused on individual animals using detection and tracking, either manual or automated approaches.</p>"},{"location":"pipeline/overview/#3-behavior-labeling","title":"3. Behavior Labeling","text":"<p>Application of machine learning models to classify animal behaviors from the processed mini-scenes.</p>"},{"location":"pipeline/overview/#4-ecological-analysis","title":"4. Ecological Analysis","text":"<p>Generation of ecological insights including time budgets, behavioral transitions, social interactions, and spatial analysis.</p>"},{"location":"pipeline/overview/#key-features","title":"Key Features","text":"<ul> <li>Modular Design: Each step can be adapted and customized for different species and study systems.</li> <li>Multiple Detection Options: Support for both manual annotation and automated YOLO-based detection.</li> <li>Machine Learning Integration: Pre-trained models available with support for custom model training.</li> <li>Comprehensive Analytics: Generate multiple types of ecological metrics and visualizations.</li> </ul>"},{"location":"pipeline/overview/#getting-started","title":"Getting Started","text":"<p>Follow the pipeline steps in order:</p> <ol> <li>Data Collection</li> <li>Pre-processing </li> <li>Behavior Labeling</li> <li>Analysis</li> </ol> <p>Pre-processed example data for each step and pre-trained models are available on Hugging Face to help you get started quickly.</p> <p>For additional customization and advanced features, see Optional Steps.</p>"},{"location":"pipeline/preprocessing/","title":"Pre-processing with CVAT","text":""},{"location":"pipeline/preprocessing/#step-2-data-pre-processing-with-cvat","title":"Step 2: Data Pre-processing with CVAT","text":""},{"location":"pipeline/preprocessing/#overview","title":"Overview","text":"<p>In order to automatically label the animal videos with behavior, we must first create mini-scenes of each individual animal captured in the frame, as illustrated below.</p> <p></p> <p>Figure: A mini-scene is a sub-image cropped from the drone video footage centered on and surrounding a single animal. Mini-scenes simulate the camera as well-aligned with each animal in the frame, compensating for the drone's movement by focusing on just the animal and its immediate surroundings. The KABR dataset consists of mini-scenes and their frame-by-frame behavior annotation.</p>"},{"location":"pipeline/preprocessing/#resources","title":"Resources","text":"<ul> <li>See the CVAT User Guide and Data Management Tips for detailed instructions and recommendations.</li> <li>View example mini-scenes at data/mini_scenes on Hugging Face.</li> </ul>"},{"location":"pipeline/preprocessing/#step-2a-perform-detections-to-create-tracks","title":"Step 2A: Perform Detections to Create Tracks","text":"<p>To create mini-scenes, we first must perform the detection step by drawing bounding boxes around each animal in frame.</p>"},{"location":"pipeline/preprocessing/#option-1-manual-detections-in-cvat","title":"Option 1: Manual Detections in CVAT","text":"<p>Figure: Simplified CVAT annotation tool interface</p> <p>Upload your raw videos to CVAT and perform the detections by drawing bounding boxes manually. This can be quite time consuming, but has the advantage of generating highly accurate tracks.</p> <p>Video Size Considerations</p> <p>Depending on the resolution of your raw video, you may encounter out of space issues with CVAT. You can use helper_scripts/downgrade.sh to reduce the size of your videos.</p>"},{"location":"pipeline/preprocessing/#option-2-automatic-detections-with-yolo","title":"Option 2: Automatic Detections with YOLO","text":"<p>You may use YOLO to automatically perform detection on your videos. Use the script below to convert YOLO detections to CVAT format.</p> <p>detector2cvat: Detect objects with Ultralytics YOLO detections, apply SORT tracking and convert tracks to CVAT format.</p> <pre><code>detector2cvat --video path_to_videos --save path_to_save [--imshow]\n</code></pre>"},{"location":"pipeline/preprocessing/#step-2b-create-mini-scenes-from-tracks","title":"Step 2B: Create Mini-scenes from Tracks","text":"<p>Once you have your tracks generated, use them to create mini-scenes from your raw footage.</p> <p>tracks_extractor: Extract mini-scenes from CVAT tracks.</p> <pre><code>tracks_extractor --video path_to_videos --annotation path_to_annotations [--tracking] [--imshow]\n</code></pre>"},{"location":"pipeline/preprocessing/#tool-reference","title":"Tool Reference","text":""},{"location":"pipeline/preprocessing/#detector2cvat","title":"detector2cvat","text":"<p>Source: src/kabr_tools/detector2cvat.py</p> <p>Detect objects with Ultralytics YOLO detections, apply SORT tracking and convert tracks to CVAT format.</p> <p>Usage: </p><pre><code>detector2cvat --video path_to_videos --save path_to_save [--imshow]\n</code></pre><p></p>"},{"location":"pipeline/preprocessing/#tracks_extractor","title":"tracks_extractor","text":"<p>Source: src/kabr_tools/tracks_extractor.py</p> <p>Extract mini-scenes from CVAT tracks.</p> <p>Usage: </p><pre><code>tracks_extractor --video path_to_videos --annotation path_to_annotations [--tracking] [--imshow]\n</code></pre><p></p>"},{"location":"pipeline/preprocessing/#next-steps","title":"Next Steps","text":"<p>Once you have created your mini-scenes, proceed to Step 3: Behavior Labeling to classify behaviors using machine learning models.</p>"},{"location":"pipeline/worked-example/","title":"Worked Example","text":""},{"location":"pipeline/worked-example/#worked-example-for-grevys-zebras-time-budget-analysis","title":"Worked Example for Grevy's Zebras Time-Budget Analysis","text":"<p>This session includes two male Grevy's zebras travelling across an open plain on the 18th of January, 2023, between 12:45 and 13:00.</p> <p> Figure 1: Flight path (left) tracking 2 male Grevy's zebras observed on 01/18/23. Video clip (right) from KABR dataset.</p>"},{"location":"pipeline/worked-example/#step-1-download-raw-videos-from-session-7-on-the-18th-of-january-2023","title":"Step 1: Download raw videos from session 7 on the 18th of January, 2023","text":"<p>You can download the raw videos directly from the KABR Raw Videos dataset.</p> <p>The videos files are: \\ 18_01_18_DJI_0068_trimmed \\ 18_01_18_DJI_0069 \\ 18_01_18_DJI_0070 \\ 18_01_18_DJI_0071 </p> <pre><code>mkdir -p grevystimebudget/raw_videos\n\ncd grevystimebudget/raw_videos\n\nwget https://huggingface.co/datasets/imageomics/KABR-raw-videos/blob/main/18_01_2023_session_7/DJI_0068_trimmed.mp4\n\nwget https://huggingface.co/datasets/imageomics/KABR-raw-videos/blob/main/18_01_2023_session_7/DJI_0069.mp4\n\nwget https://huggingface.co/datasets/imageomics/KABR-raw-videos/blob/main/18_01_2023_session_7/DJI_0070.mp4\n\nwget https://huggingface.co/datasets/imageomics/KABR-raw-videos/blob/main/18_01_2023_session_7/DJI_0071.mp4\n\ncd ../..\n</code></pre>"},{"location":"pipeline/worked-example/#step-2-extract-mini-scenes-from-raw-videos-using-tracks_extractor","title":"Step 2: Extract mini-scenes from raw videos using <code>tracks_extractor</code>","text":"<p>You can download the CVAT annotations for these from the KABR Worked Examples dataset.</p> <p>The annotations files are:</p> <p>18_01_2023_session_7-DJI_0068.xml \\ 18_01_2023_session_7-DJI_0069.xml \\ 18_01_2023_session_7-DJI_0070.xml \\ 18_01_2023_session_7-DJI_0071.xml \\</p> <pre><code>mkdir -p grevystimebudget/annotations\n\ncd grevystimebudget/annotations\n\nwget https://huggingface.co/datasets/imageomics/kabr-worked-examples/blob/main/detections/18_01_2023_session_7-DJI_0068.xml\n\nwget https://huggingface.co/datasets/imageomics/kabr-worked-examples/blob/main/detections/18_01_2023_session_7-DJI_0069.xml\n\nwget https://huggingface.co/datasets/imageomics/kabr-worked-examples/blob/main/detections/18_01_2023_session_7-DJI_0070.xml\n\nwget https://huggingface.co/datasets/imageomics/kabr-worked-examples/blob/main/detections/18_01_2023_session_7-DJI_0071.xml\ncd ../..\n</code></pre> <p>Now you can use the <code>tracks_extractor</code> tool to extract mini-scenes from the raw videos using the CVAT annotations.</p> <p></p><pre><code>mkdir -p grevystimebudget/miniscenes\ntracks_extractor --video grevystimebudget/raw_videos --annotation grevystimebudget/annotations --imshow --tracking\n</code></pre> This will create a folder called <code>miniscenes</code> in the <code>grevystimebudget</code> directory with the extracted mini-scenes. The <code>--imshow</code> flag will display the mini-scenes as they are being extracted, and the <code>--tracking</code> flag will enable tracking of individuals across frames. This process may take a while depending on the number of videos and annotations. <pre><code># Example output:\nProcessing video: grevystimebudget/raw_videos/18_01_18_DJI_0068.mp4\nExtracted 150 mini-scenes from 18_01_18_DJI_0068.mp4\n</code></pre><p></p> <p>See mini-scenes extracted for this session here: grevystimebudget/miniscenes</p>"},{"location":"pipeline/worked-example/#step-3-label-mini-scenes-with-behavior-using-miniscene2behavior","title":"Step 3: Label mini-scenes with behavior using <code>miniscene2behavior</code>","text":"<p>You can use the <code>x3d_kabr_kinetics</code> tool to classify behaviors in the extracted mini-scenes.</p> <p>Download model weights from the X3D-KABR-Kinetics repo.</p> <p></p><pre><code>mkdir -p grevystimebudget/classified_behaviors\n\nminiscene2behavior --hub imageomics/x3d-kabr-kinetics --checkpoint x3d_kabr_kinetics.pyth --miniscene grevystimebudget/miniscenes/ --output grevystimebudget/mini_scene_behavior_annotations/DJI_0068_annotations.csv\n</code></pre> This will classify the behaviors in the mini-scenes and save the results in a CSV file called <code>DJI_0068_annotations.csv</code> in the <code>/mini_scene_behavior_annotations</code> directory.<p></p> <p>See behavior classifications extracted for this session here: grevystimebudget/mini_scene_behavior_annotations</p>"},{"location":"pipeline/worked-example/#step-4-perform-ecological-analysis","title":"Step 4: Perform Ecological Analysis","text":"<p>We can analyze the behavior annotations labeled in Step 3 to create time budgets for the individuals observed in this session.</p> <p>See the time budgets notebook for the code to create the visualizations.</p> <p>Key step: convert the behavior labels generated by the miniscene2behavior to labels using the ethogram used in the field observations.</p> <pre><code>label2number = {\n    \"Walk\": 0,\n    \"Graze\": 1,\n    \"Browse\": 2,\n    \"Head Up\": 3,\n    \"Auto-Groom\": 4,\n    \"Trot\": 5,\n    \"Run\": 6,\n    \"Occluded\": 7}\n</code></pre> <p> Figure 2: Overall time budget for duration of 10 minute observation</p> <p></p> <p> Figure 3: Gantt chart for each zebra generated from time budget data (3 minute duration)</p>"}]}